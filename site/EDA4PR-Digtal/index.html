<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>EDA4PR-Digtal - notebOOOOOOk</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "EDA4PR-Digtal";
        var mkdocs_page_input_path = "EDA4PR-Digtal.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> notebOOOOOOk
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">EDA</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../EDA4PR/">EDA4PR</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../EDA4PR-Analog/">EDA4PR-Analog</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">EDA4PR-Digtal</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#cross-stage-prediction">Cross-Stage Prediction</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#congestion">congestion</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#background">background</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#routenet-drc-hotspot-prediction-iccad-2018-cnn">RouteNet-DRC Hotspot Prediction-ICCAD-2018-CNN</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../EDA4PR-LCM/">EDA4PR-LCM</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../flow/">Flow</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Tools</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../Algorithms/">Algorithms</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Hardware/">Hardware</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../OS/">OS</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Program/">Program</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Tools/">Tools</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Other</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../Literature/">Good Things</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">notebOOOOOOk</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">EDA</li>
      <li class="breadcrumb-item active">EDA4PR-Digtal</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="eda4pr-digtal">EDA4PR-Digtal<a class="headerlink" href="#eda4pr-digtal" title="Permanent link">&para;</a></h1>
<h2 id="cross-stage-prediction">Cross-Stage Prediction<a class="headerlink" href="#cross-stage-prediction" title="Permanent link">&para;</a></h2>
<ul>
<li>Earlystage prediction can enhance design quality by proactively detecting potential design issues in advance  --cite--&gt;[cluster-net]</li>
<li><code>Shift left</code>出处：V. Bhardwaj, “Shift left trends for design convergence in soc: An eda perspective,” International Journal of Computer Applications, vol. 174, no. 16, pp. 22–27, Jan 2021  </li>
</ul>
<h3 id="congestion">congestion<a class="headerlink" href="#congestion" title="Permanent link">&para;</a></h3>
<h4 id="background">background<a class="headerlink" href="#background" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Routing congestion can overwhelm routing resources and lead to low cell utilization and routing detours  </p>
</li>
<li>
<p>congestion is not known accurately until late in the design cycle, after placement and routing.  </p>
</li>
<li>
<p>Many modern placement and synthesis tools leverage congestion estimation in their cost analysis in order to minimize the effects of congestion in the final physical design </p>
</li>
<li>
<p><img alt="image-20241101193119582" src="../assets/image-20241101193119582.png" /></p>
</li>
<li>
<p>It is known that the total net length can be a good proxy for congestion   </p>
</li>
<li>
<p>A simple approximation for congestion prediction is to use the size of the local neighborhood  </p>
</li>
<li>
<p><img alt="image-20241102170308031" src="../assets/image-20241102170308031.png" /></p>
</li>
<li>
<p>和 fan-in, fan-out 强相关</p>
</li>
<li>
<p>Precise congestion prediction from a placement solution plays a crucial role in circuit placement   </p>
</li>
<li>
<p>Multiple <strong>previous works</strong> have attempted to predict detailed routing congestion in the <strong>placement step</strong> in an effort to optimize routability of the placement solution: RUDY, POLAR 2.0. All these techniques are implemented  in the placement step and need the position information of cells .</p>
</li>
<li>
<p>To avoid the high computation cost of placement, it is more useful to be able to predict congestion in the logic synthesis phase.   </p>
</li>
<li>
<p>congestion prediction problem can be frame as <strong>node regression problem</strong>  </p>
</li>
<li>with the growth of circuit scale and complexity, time consumption
  tends to be unacceptable when utilizing a <strong>global router</strong> in the placement cycle to obtain the <strong>congestion map</strong>.  </li>
<li>Current machine learning models commonly follow a two-phase workflow. First, based on domain knowledge, human experts generate various local features on the circuit using predefined functions on netlist. Then, based on the generated features, a specific model, e.g. convolution neural network (CNN) model is designed to predict either the routing demand map or the congestion map  </li>
<li>the emergence of <strong>Graph Neural Network (GNN)</strong> triggered applications of undirected homogeneous graphs models on routing congestion prediction, since a VLSI circuit can be naturally represented by a graph  </li>
<li></li>
</ul>
<h4 id="routenet-drc-hotspot-prediction-iccad-2018-cnn"><a href="https://zhiyaoxie.com/files/ICCAD18_RouteNet.pdf">RouteNet-DRC Hotspot Prediction-ICCAD-2018-CNN</a><a class="headerlink" href="#routenet-drc-hotspot-prediction-iccad-2018-cnn" title="Permanent link">&para;</a></h4>
<h5 id="background_1">background<a class="headerlink" href="#background_1" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Every chip design project must complete routing <strong>without design rule violation</strong> before tapeout. However, this basic requirement is often difficult to be satisfied especially when routability is not adequately considered in early design stages.  </p>
</li>
<li>
<p>In light of this fact, routability prediction has received serious attention in both academic research and industrial tool development. Moreover, routability is widely recognized as a main objective for <strong>cell placement</strong>  </p>
</li>
<li>
<p>CNN and Transfer Learning  </p>
</li>
<li>
<p>CNN learns more abstract patterns from images  </p>
</li>
<li>Our RouteNet transfers such state-of-the-art ability in image pattern recognition to circuits for capturing the patterns about routability. RouteNet predicts routability based on a pretrained ResNet architecture  </li>
<li>
<p>Fully Convolutional Network (FCN): outputs an image with size equal to or smaller than input.   many FCNs have both deep and shallow paths in one network.   </p>
</li>
<li>
<p>RUDY(Rectangular Uniform wire DensitY)</p>
</li>
<li>
<p>它被用作我们 RouteNet 的输入特征，因为它与路由拥塞部分相关，获取速度快，可以直接表示为与 RouteNet 相吻合的图像</p>
</li>
<li>
<p>challenge of macros</p>
</li>
</ul>
<p><img alt="image-20250205214716706" src="../assets/image-20250205214716706.png" /></p>
<ul>
<li>The orange circles in Figure 3 indicate a strong tendency for hotspots to aggregate at the small gap between neighboring macros  </li>
<li>Blue dashed circles indicate the remaining sparsely distributed hotspots </li>
<li><img alt="image-20250205220737891" src="../assets/image-20250205220737891.png" /></li>
<li>有 macro，线性程度低</li>
</ul>
<h5 id="task">task<a class="headerlink" href="#task" title="Permanent link">&para;</a></h5>
<ul>
<li>predict overall routability (DRC count), 分类任务，预测总的#DRV</li>
<li>predict <code>DRC hotspot</code> locations.DRC hotspots mean the specific locations with high density of DRVs. like an end-to-end object detection task, which is more difficult to solve. GCell 内#DRV 超过设定值则为 <code>DRC hotspot</code></li>
</ul>
<h5 id="contribution">contribution:<a class="headerlink" href="#contribution" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250205210214325" src="../assets/image-20250205210214325.png" /></p>
<ul>
<li>mixed-size macros</li>
<li>first systematic study on CNN-based routability prediction  </li>
<li>high accuracy and high speed  </li>
<li></li>
</ul>
<h5 id="flow">flow<a class="headerlink" href="#flow" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250205222502598" src="../assets/image-20250205222502598.png" /></p>
<h5 id="model">model<a class="headerlink" href="#model" title="Permanent link">&para;</a></h5>
<ul>
<li>
<h1 id="drv-prediction">DRV prediction<a class="headerlink" href="#drv-prediction" title="Permanent link">&para;</a></h1>
</li>
</ul>
<p>ResNet18-based</p>
<p><img alt="image-20250205223554347" src="../assets/image-20250205223554347.png" /></p>
<p>preprocess</p>
<ul>
<li>
<p><img alt="image-20250205223153166" src="../assets/image-20250205223153166.png" /></p>
</li>
<li>
<p><img alt="image-20250205223742770" src="../assets/image-20250205223742770.png" /></p>
<p>ResNet 是一个固定输入（224*224）的模型，为了使用知识迁移，将输入 <img alt="image-20250205223849469" src="../assets/image-20250205223849469.png" /> 通过插值的方法变成 <img alt="image-20250205223907748" src="../assets/image-20250205223907748.png" />。具体怎么插？</p>
</li>
<li>
<p>hotspot prediction</p>
</li>
</ul>
<p><img alt="image-20250205224325007" src="../assets/image-20250205224325007.png" /></p>
<h5 id="data">data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h5>
<p>dataset:</p>
<p>ISPD 2015 benchmarks  </p>
<p><img alt="image-20250205225007139" src="../assets/image-20250205225007139.png" /></p>
<p>different placement made by “obstacle-aware macro placement " algorithm [5].  </p>
<p>each floorplan is placed and routed by Cadence Encounter v14.20 [2]  </p>
<h5 id="experiment">experiment<a class="headerlink" href="#experiment" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250205230614878" src="../assets/image-20250205230614878.png" /></p>
<p><img alt="image-20250205230628088" src="../assets/image-20250205230628088.png" /></p>
<p><img alt="image-20250205230725019" src="../assets/image-20250205230725019.png" /></p>
<p>we compare the TPR of all methods under the same FPR (error under 1%)</p>
<p><img alt="image-20250205230816030" src="../assets/image-20250205230816030.png" /></p>
<h4 id="congestionnet-predict-congestion-hotspots-ifip-2019-gnngat-nvidia"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8920342&amp;tag=1">CongestionNet-predict congestion hotspots-IFIP-2019-GNN(GAT)-nvidia</a><a class="headerlink" href="#congestionnet-predict-congestion-hotspots-ifip-2019-gnngat-nvidia" title="Permanent link">&para;</a></h4>
<p>a <strong>graph</strong>-based deep learning method for predicting <strong>routing congestion hotspots</strong> from a <strong>netlist</strong> before placement.  Predict the <mark>detail routed</mark> <strong>lower metal layer</strong> congestion values  </p>
<p><img alt="image-20241101192745004" src="../assets/image-20241101192745004.png" /></p>
<p>why low layer? 因为较低金属层上的拥塞主要是由局部逻辑结构驱动的，而不是由无关逻辑簇之间的较长互连驱动的，后者往往在较高金属层上运行. predicting lower metal layer congestion is not only more important for the underlying task of identifying congested logic structures, but also simplifies the task for our
graph based network  </p>
<h5 id="contribution_1">contribution<a class="headerlink" href="#contribution_1" title="Permanent link">&para;</a></h5>
<ul>
<li>阶段早, 只使用网表</li>
<li>由于该模型仅基于网表的逻辑结构而不是任何特定的单元布局进行预测，因此它消除了基于布局的方法中存在的次优布局的伪影 <img alt="image-20241101192504194" src="../assets/image-20241101192504194.png" /></li>
<li>can be done without any physical information  </li>
<li>GNN, 快</li>
<li>the first work exploring the use of graph based deep learning for physical design problems  </li>
</ul>
<p><strong>数据:</strong></p>
<p><img alt="image-20241101194746768" src="../assets/image-20241101194746768.png" /></p>
<p><img alt="image-20241101195219055" src="../assets/image-20241101195219055.png" /></p>
<p>roughly 5000 distinct cell types  </p>
<p>we project our per cell predictions back onto their respective 2D grid (using the <strong>final ground truth physical placement</strong>) and average all cells within each grid cell to come up with a predicted value that can be compared to the original ground truth grid value.  </p>
<p><strong>模型参数:</strong></p>
<p>an 8 layer Graph Attention Network (GAT) with size 16 intermediate (or hidden) state  </p>
<p>无向图, each node corresponds to a cell </p>
<p>节点特征: length 50 for each <strong>cell type</strong> and each cell’s <strong>logic description</strong> as well as the <strong>pin count</strong> and <strong>cell size</strong> of that cell</p>
<p><strong>实验:</strong></p>
<p>report correlation values using the <strong>Kendall ranking coefficient</strong>  </p>
<p>实际效果可视化</p>
<p><img alt="image-20241101211844804" src="../assets/image-20241101211844804.png" /></p>
<p><img alt="image-20241007114109425" src="../assets/image-20241007114109425.png" /></p>
<p>对比实验</p>
<p><img alt="image-20241101214611345" src="../assets/image-20241101214611345.png" /></p>
<p>消融实验</p>
<p><img alt="image-20241101214630174" src="../assets/image-20241101214630174.png" /></p>
<p>cell type or function is an essential part of our predictions.   </p>
<p>cell type 不是没起作用吗</p>
<p><strong>缺点:</strong> </p>
<ul>
<li>model needs to be <strong>retrained</strong> for every <strong>new process technology</strong>, since the embeddings are over cell types specific to a process technology.  </li>
<li>it occasionally over predicts congestion in areas of <strong>low to moderate</strong> congestion, such as in most failing parts of Partition A  </li>
<li>due to the <strong>graph based</strong> nature of the model, it sometimes makes <strong>overly soft decision</strong> boundaries  </li>
<li><img alt="image-20241102170708557" src="../assets/image-20241102170708557.png" /></li>
<li>the CongestionNet uses informative cell attributes (cell size and pin count) alone as the input to the GAT and does not use any embedding encoding the netlist structure  </li>
</ul>
<p><strong>可改进的点:</strong></p>
<p><img alt="image-20241101215450089" src="../assets/image-20241101215450089.png" /></p>
<h4 id="-congestion-prediction-embedding-matrix-factorization-partition-arxiv-2021-gnnsage-nal"><a href="">-Congestion prediction + embedding + matrix factorization + partition-arXiv-2021-GNN(Sage)-NAL+</a><a class="headerlink" href="#-congestion-prediction-embedding-matrix-factorization-partition-arxiv-2021-gnnsage-nal" title="Permanent link">&para;</a></h4>
<ul>
<li>a framework that can directly learn embeddings for the given netlist to enhance the quality of our node features  </li>
<li>目的是使用网表数据，减少 placement 迭代</li>
<li>The key difference between this work and <a href="">CongestionNet</a> model lies in our construction of an <mark>embedding</mark> pipeline for EDA netlists  </li>
</ul>
<h5 id="background_2">background<a class="headerlink" href="#background_2" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>predicting cell congestion due to improper logic combination can reduce the burden of subsequent physical implementations.  </p>
</li>
<li>
<p>previous work: require informative cell features </p>
</li>
<li>
<p>an awareness of high congestion areas at an early design stage is of great importance to provide fast feedback and shorten design cycles  </p>
</li>
<li>
<p>Although the global routing result provides a good estimation of routing congestion [6], [19], an awareness of high congestion areas at an <strong>early</strong> design stage is of great importance to provide fast feedback and shorten design cycles</p>
</li>
<li>
<p>Multiple works have attempted to predict detailed <strong>routing congestion</strong> in the placement step in an effort to optimize <strong>routability</strong> of the placement solution  </p>
</li>
<li>
<p>The process of node embedding involves learning a free vector ev for each node.   </p>
</li>
<li>
<p>Embedding learning has achieved great success in the field of Natural Language Processing (NLP), where methods such as Word2Vec   </p>
</li>
<li>
<p>Random-walk based embedding method  </p>
</li>
<li>
<p>Node2vec, LINE, DeepWalk</p>
</li>
<li>These methods are derived from the skip-gram encoding method Word2vec   </li>
<li>
<p>there are two aspects of EDA that pose difficulties for standard random-walk based methods  </p>
<ol>
<li>the typical circuit is extremely large   </li>
<li>in the congestion prediction context, the desired prediction is often on the unseen cells in a new circuit.   (像文本那种，应该是所有文本都作为训练集，所以和电路不一样)。training and testing on distinct graphs requires <mark>extra alignment post-processing</mark> [26], [27], which is both challenging and extremely time consuming.  </li>
</ol>
</li>
<li>
<p>Embedding <mark>alignment</mark>  </p>
</li>
</ul>
<p>Wasserstein-Procrustes alignment  </p>
<p>uses a 正交变换矩阵 $Q \in \mathbb{R}^{d \times d}$ 和排列（置换）矩阵 $P \in \mathbb{R}^{V \times V} $ to align two graphs G, G' with $X \in \mathbb{R}^{V \times d}$</p>
<p><img alt="image-20250301120251168" src="../assets/image-20250301120251168.png" /></p>
<p>最终目标：让两个图的节点坐标尽可能重合，即使它们最初看起来不一样。</p>
<p><img alt="image-20250301142650331" src="../assets/image-20250301142650331.png" /></p>
<blockquote>
<p>打个比方：假设你有一个班级的座位表，每个学生的位置用坐标（比如 x, y）表示。现在隔壁班也有一个座位表，座位形状和你们班完全一样，但可能：</p>
<ol>
<li>他们的座位整体旋转了某个角度（比如你们班正北方向是讲台，他们班正东方向是讲台）</li>
<li>学生的座位编号顺序被打乱了（比如你们班 1 号坐在前排左，他们班 1 号可能坐在后排右）</li>
</ol>
<h3 id="_1">对应到图中的概念：<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>图嵌入（Node Embedding）</strong>
    就像把每个学生用坐标表示，这里的 "坐标" 就是算法生成的 d 维向量 X。这些坐标要保留同学之间的关系（比如经常互动的同学坐标更接近）。</li>
<li><strong>正交变换矩阵 Q</strong>
    相当于旋转或镜像整个座位表（比如把整个班级的座位顺时针转 90 度）。这种变换不改变同学之间的相对距离——原本坐在一起的同学，旋转后还是坐在一起。</li>
<li><strong>排列矩阵 P</strong>
    相当于重新给座位编号。比如把原本 1 号同学的标签贴到 5 号座位上，但座位本身的位置没变。这就像洗牌一样打乱顺序，但实际座位布局不变。</li>
</ol>
<h3 id="_2">具体到你的问题：<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>第一步：对齐旋转/镜像（找 Q）</strong>
 假设两个班级座位布局完全一样，但方向不同。我们需要找到一个 "旋转角度" Q，让两个班级的座位表方向一致。</li>
</ul>
<p>比如你们班座位表是正常方向，隔壁班被旋转了 90 度。通过 Q 这个旋转矩阵，可以把他们的座位表转回来，这样两个班级的座位坐标就能对齐。</p>
<ul>
<li><strong>第二步：对齐编号顺序（找 P）</strong>
 即使座位方向对齐了，同学的编号可能还是乱的。比如你们班 1 号同学坐在(1,1)，而隔壁班 1 号可能坐在(1,1)的是他们班的 5 号同学。这时候需要一个 "编号重排" 矩阵 P，把他们的编号顺序调整到和你们班一致。</li>
</ul>
<h3 id="_3">实际应用场景：<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>假设淘宝和京东都有用户关系网图：</p>
<ol>
<li><strong>淘宝图</strong>：用户 A、B、C 的嵌入坐标是 X</li>
<li><strong>京东图</strong>：同样的用户被称作 X'、Y、Z，嵌入坐标是 X'</li>
</ol>
<p>即使两个平台的用户关系完全相同：</p>
<ul>
<li>京东可能用了不同的嵌入算法（导致需要旋转 Q）</li>
<li>用户的 ID 编号不同（导致需要重新排列 P）</li>
</ul>
<p>通过找到 Q 和 P，就能判断 "淘宝用户 A" 对应 "京东用户 X"，实现跨平台用户对齐。</p>
<h3 id="_4">再简化总结：<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>这个数学问题就像在做两件事：</p>
<ol>
<li><strong>纠正方向差异</strong>：用 Q 旋转/镜像，让两个图的方向一致</li>
<li><strong>纠正编号混乱</strong>：用 P 重新排列，让对应的节点找到彼此</li>
</ol>
<p>最终目标：让两个图的节点坐标尽可能重合，即使它们最初看起来不一样。</p>
<p><img alt="image-20250301142650331" src="../assets/image-20250301142650331.png" /></p>
</blockquote>
<ul>
<li>Pointwise Mutual Information (PMI) Matrices  </li>
</ul>
<p>PMI 矩阵是用来衡量图中任意两个节点之间相似度的工具。比如，它可以告诉你两个用户的关系有多紧密。</p>
<p>定义：</p>
<p><img alt="image-20250301145032148" src="../assets/image-20250301145032148.png" /></p>
<ul>
<li>
<p><img alt="image-20250301145239768" src="../assets/image-20250301145239768.png" /></p>
</li>
<li>
<p><img alt="image-20250301145259969" src="../assets/image-20250301145259969.png" /></p>
</li>
<li>
<p><img alt="image-20250301145536298" src="../assets/image-20250301145536298.png" /></p>
<p>推导：</p>
<p><img alt="image-20250301145951825" src="../assets/image-20250301145951825.png" /></p>
</li>
<li>
<blockquote>
<h3 id="_5"><strong>举个例子</strong><a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>&gt;假设你有一个社交网络，有 3 个用户：A、B、C。他们的嵌入向量如下：

&gt;- A 的嵌入向量：*X* 1 = [1,0]
&gt;- B 的嵌入向量：*X* 2 = [0,1]
&gt;- C 的嵌入向量：*X* 3 = [1,1]

&gt;也就是 $X \in \mathbb{R}^{3 \times 2}$

&gt;#### **1. 计算相似度**

&gt;- A 和 B 的相似度：⟨ *X* 1, *X* 2⟩ = 1×0+0×1 = 0
&gt;- A 和 C 的相似度：⟨ *X* 1, *X* 3⟩ = 1×1+0×1 = 1
&gt;- B 和 C 的相似度：⟨ *X* 2, *X* 3⟩ = 0×1+1×1 = 1

&gt;#### **2. 构建 PMI 矩阵**

&gt;PMI 矩阵就是：

&gt;![image-20250301145748553](assets/image-20250301145748553.png)

&gt;- 第 (1,2) 项是 0，表示 A 和 B 不相似。
&gt;- 第 (1,3) 项是 1，表示 A 和 C 相似。

&gt;#### **3. 正交矩阵的作用**

&gt;假设我们用一个正交矩阵 *Q* 旋转嵌入向量，比如：

&gt;*Q* = [0110]

&gt;新的嵌入矩阵 `X~=XQ` 就是：

&gt;- A 的新嵌入向量：*X*~1 = [0,1]
&gt;- B 的新嵌入向量：*X*~2 = [1,0]
&gt;- C 的新嵌入向量：*X*~3 = [1,1]

&gt;重新计算相似度：

&gt;- A 和 B 的相似度：⟨ *X*~1, *X*~2⟩ = 0×1+1×0 = 0
&gt;- A 和 C 的相似度：⟨ *X*~1, *X*~3⟩ = 0×1+1×1 = 1
&gt;- B 和 C 的相似度：⟨ *X*~2, *X*~3⟩ = 1×1+0×1 = 1

&gt;PMI 矩阵仍然是：

&gt;![image-20250301150907011](assets/image-20250301150907011.png)

&gt;也就是说，正交变换不会改变节点之间的相似度。
</code></pre></div>
</blockquote>
</li>
<li>
<p>PMI Matrix eigendecomposition for network embedding  </p>
</li>
<li>
<p>由于上一章已经证明：X 乘上 Q 以后， PMI 不变，所以不用找 Q 矩阵</p>
</li>
<li><img alt="image-20250301151036651" src="../assets/image-20250301151036651.png" /></li>
<li>后面关于特征向量没看明白</li>
<li>
<p>结论是 PMI 矩阵分解比随机游走快</p>
</li>
<li></li>
</ul>
<h5 id="contribution_2">contribution<a class="headerlink" href="#contribution_2" title="Permanent link">&para;</a></h5>
<ul>
<li>an efficient mini-batch training method at the sub-graph level</li>
<li>can guarantee parallel training and satisfy the memory restriction for large-scale netlists</li>
<li>Matrix-factorization based embedding learning  </li>
</ul>
<h5 id="data_1">data<a class="headerlink" href="#data_1" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250301151648940" src="../assets/image-20250301151648940.png" /></p>
<p><img alt="image-20250301151653817" src="../assets/image-20250301151653817.png" /></p>
<h5 id="task_1">task<a class="headerlink" href="#task_1" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241102170157570" src="../assets/image-20241102170157570.png" /></p>
<ul>
<li>
<p>during the logic synthesis stage  </p>
</li>
<li>
<p><img alt="image-20241102185917955" src="../assets/image-20241102185917955.png" /></p>
</li>
</ul>
<p>到底是什么时候的 congestion 数据? Routing 后的真实值还是预测 plcament 后的 congestion RUDY 预测值? 应该是 <strong>Global Routing</strong> 后的: 强调了 congestion value = wiring demand/routing capacity</p>
<p><img alt="image-20241102190757814" src="../assets/image-20241102190757814.png" /></p>
<p><strong>contrbution</strong></p>
<h5 id="data_2">data<a class="headerlink" href="#data_2" title="Permanent link">&para;</a></h5>
<p>DAC2012 contest benchmark</p>
<p>http://archive.sigda.org/dac2012/contest/dac2012_contest.html</p>
<p><img alt="image-20241102185210635" src="../assets/image-20241102185210635.png" /></p>
<p>OpenROAD dataset</p>
<p><img alt="image-20241102185314200" src="../assets/image-20241102185314200.png" /></p>
<ul>
<li>
<p>place via <strong>DREAMPLACE</strong>  </p>
</li>
<li>
<p><img alt="image-20241102185814366" src="../assets/image-20241102185814366.png" /></p>
</li>
<li>
<p>Macros and terminals are removed from the graph  </p>
</li>
<li>
<p>Nets with degree more than 10 are excluded from the final graph as they introduce cliques too large to work with efficiently.   </p>
</li>
<li>
<p>node features (pin number, cell size) , This follows the flow of CongestionNet</p>
</li>
<li>
<p><img alt="image-20241102190725383" src="../assets/image-20241102190725383.png" /></p>
</li>
</ul>
<h5 id="flow_1">flow<a class="headerlink" href="#flow_1" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241102193019887" src="../assets/image-20241102193019887.png" /></p>
<ul>
<li>
<p>congestion value for each grid cell computed as the wiring demand divided by the routing capacity , The output along the z-axis is reduced by a max function,   </p>
</li>
<li>
<p>Our focus is on predicting congestion due to local logic structure, which manifests itself on lower metal layers. Therefore, we use congestion labels from the lower half of the metal layers to train and evaluate the model  </p>
</li>
<li>
<p>推理的时候取所有 cell 的预测平均值</p>
</li>
</ul>
<p><strong>principle</strong></p>
<ul>
<li>
<p>提出相连越近的节点相似度越高,</p>
</li>
<li>
<p>提出 structural node similarity  </p>
</li>
</ul>
<p><img alt="image-20241102182916257" src="../assets/image-20241102182916257.png" /></p>
<ul>
<li>
<p>Sub-graph partition ? METIS? ClusterGCN?</p>
</li>
<li>
<p>Matrix Factorization  ?</p>
</li>
</ul>
<h5 id="model_1">model<a class="headerlink" href="#model_1" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>The key <strong>difference</strong> between this approach and <strong>CongestionNet</strong> lies in <strong>embedding</strong> pipeline </p>
</li>
<li>
<p>graph is undirected complete circuit is too <strong>large</strong> for direct matrix factorization and must be <strong>partitioned</strong> into clusters, use <strong>METIS</strong> partitioning tool   in <strong>ClusterGCN</strong></p>
</li>
<li>Sub-graph partition: clusters of ≈ 5000 nodes each</li>
<li>Matrix Factorization  ?</li>
<li></li>
</ul>
<h5 id="experiment_1">experiment<a class="headerlink" href="#experiment_1" title="Permanent link">&para;</a></h5>
<p>three metrics of correlation to measure performance:   <strong>Pearson, Spearman, Kendall</strong> </p>
<p>Before evaluation, both the prediction and the label have some (very low) <strong>noise</strong> added to them.   </p>
<p><img alt="image-20241102204924004" src="../assets/image-20241102204924004.png" /></p>
<p><img alt="image-20241102204932495" src="../assets/image-20241102204932495.png" /></p>
<p><img alt="image-20241102204956720" src="../assets/image-20241102204956720.png" /></p>
<p><img alt="image-20241102205029766" src="../assets/image-20241102205029766.png" /></p>
<h4 id="pgnn-drvs-predictionpin-proximity-graph-iccad-2022-gnnunetcnn-korea"><a href="">PGNN-DRVs prediction+Pin Proximity Graph-ICCAD-2022-GNN+UNet(CNN)-Korea</a><a class="headerlink" href="#pgnn-drvs-predictionpin-proximity-graph-iccad-2022-gnnunetcnn-korea" title="Permanent link">&para;</a></h4>
<h5 id="background_3">background<a class="headerlink" href="#background_3" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>(1) pin accessibility and (2) routing congestion are two major causes of DRVs (design rule violations)  </p>
</li>
<li>
<p>Particularly, the complex design rules put so much burden on physical design, demanding lots of iterations on the time-consuming process of cell placement and net routing to <strong>clean up all DRVs (design rule violations)</strong> before tapping out . Thus, at the placement stage, if we were able to identify, with high confidence, DRC (design rule check) hotspots that would be
  likely to occur at the routing stage, we can pay more attention  </p>
</li>
<li>
<p>shortcoming of <strong>image based</strong>:</p>
</li>
</ul>
<p>local pin accessibility cannot be accurately modeled by pin pattern <strong>image</strong> alone  </p>
<p>using high-resolution pin pattern images incur significant additional <strong>run-time</strong> as well as <strong>memory</strong> overhead to the prediction models  </p>
<ul>
<li>to optimize the placement before routing.  </li>
</ul>
<h5 id="task_2">task<a class="headerlink" href="#task_2" title="Permanent link">&para;</a></h5>
<p>a novel ML based DRC hotspot prediction technique,   </p>
<ul>
<li>GNN is used to embed pin accessibility information, <strong>U-net</strong> is used to extract routing congestion information from grid-based
  features  </li>
<li><img alt="image-20241108113804178" src="../assets/image-20241108113804178.png" /></li>
<li><img alt="image-20241108100942346" src="../assets/image-20241108100942346.png" /></li>
<li>placement 分割为 grid, 长宽 = G-Cell</li>
<li>DRVs are extracted as the ground-truth after <strong>detailed routing</strong>  </li>
</ul>
<h5 id="contribution_3">contribution<a class="headerlink" href="#contribution_3" title="Permanent link">&para;</a></h5>
<h2 id="-gnn-model-base-pin-proximity-graph">- GNN model, base pin proximity graph<a class="headerlink" href="#-gnn-model-base-pin-proximity-graph" title="Permanent link">&para;</a></h2>
<h5 id="model_2">model<a class="headerlink" href="#model_2" title="Permanent link">&para;</a></h5>
<p>PGNN can adopt pin proximity graph as well as grid-based feature map as input feature  </p>
<p>Pin Proximity Graph :</p>
<ul>
<li>无向图， 同构图</li>
</ul>
<p><img alt="image-20241108105308585" src="../assets/image-20241108105308585.png" /></p>
<p><img alt="image-20241108105400483" src="../assets/image-20241108105400483.png" /></p>
<p>U-Net:</p>
<p><img alt="image-20241108100615500" src="../assets/image-20241108100615500.png" /></p>
<p>featrue:</p>
<p><img alt="image-20241108111019050" src="../assets/image-20241108111019050.png" /></p>
<p><img alt="image-20241108111430728" src="../assets/image-20241108111430728.png" /></p>
<p>整体模型:</p>
<p><img alt="image-20241108110729825" src="../assets/image-20241108110729825.png" /></p>
<p><strong>数据集</strong>:</p>
<p><img alt="image-20241108111933323" src="../assets/image-20241108111933323.png" /></p>
<p>以后也可以这么做, 同一个 benchmark 不同的 config 参数就有不同的数据</p>
<h5 id="experiment_2">experiment<a class="headerlink" href="#experiment_2" title="Permanent link">&para;</a></h5>
<p>Nangate 15nm library  </p>
<p>9 groups are used for training and the remaining 1 group for test.   K 折验证</p>
<p><img alt="image-20241108112502662" src="../assets/image-20241108112502662.png" /></p>
<p>positive 和 negative 是什么意思?</p>
<p>可视化:</p>
<p><img alt="image-20241108102857037" src="../assets/image-20241108102857037.png" /></p>
<p>消融实验:</p>
<p><img alt="image-20241108112646099" src="../assets/image-20241108112646099.png" /></p>
<p>以后也可以这样用特征消融?</p>
<p>对比实验(F1-score):</p>
<p><img alt="image-20241108112751008" src="../assets/image-20241108112751008.png" /></p>
<p><img alt="image-20241108114209199" src="../assets/image-20241108114209199.png" /></p>
<ul>
<li>
<p>注意不需要 GR!</p>
</li>
<li>
<p><strong>GR-Cong</strong> is obtained from ICC2 after global routing stage, and grids with high routing congestion are classified as DRC hotspot. 商用  </p>
</li>
<li>RouteNet 和 J-Net 都是相关的学术工作</li>
</ul>
<p>时间对比:</p>
<p><img alt="image-20241108114501484" src="../assets/image-20241108114501484.png" /></p>
<h4 id="lhnn-congestionprediction-dac-2022-gnn-cuhkhuaweiyibolin"><a href="">LHNN-CongestionPrediction-DAC-2022-GNN-CUHK+Huawei+YiboLin</a><a class="headerlink" href="#lhnn-congestionprediction-dac-2022-gnn-cuhkhuaweiyibolin" title="Permanent link">&para;</a></h4>
<h5 id="background_4">background<a class="headerlink" href="#background_4" title="Permanent link">&para;</a></h5>
<ul>
<li>图的节点的设置很新颖</li>
<li>with the growth of circuit scale and complexity, time consumption
  tends to be unacceptable when utilizing a <strong>global router</strong> in the placement cycle to obtain the <strong>congestion map</strong>.  </li>
<li>due to the need for the <strong>"shift-left"</strong> in circuit design, researchers begin to seek alternative solutions in machine learning [4] [5] to achieve accurate and fast congestion map prediction  </li>
</ul>
<h5 id="task_3">task<a class="headerlink" href="#task_3" title="Permanent link">&para;</a></h5>
<ul>
<li>two related tasks, <strong>routing demand regression</strong> and <strong>congestion classification</strong>  </li>
</ul>
<h5 id="data_3">data<a class="headerlink" href="#data_3" title="Permanent link">&para;</a></h5>
<p>regard each <strong>G-cell</strong> <strong>as a node</strong> and add an edge between two nodes if the respective two G-cells are adjacent.  </p>
<p><strong>hypergraphs and heterogeneous  graph</strong> , 两种节点：G-cell 和 G-net</p>
<p><img alt="image-20241108141650136" src="../assets/image-20241108141650136.png" /></p>
<p><img alt="image-20241108142449292" src="../assets/image-20241108142449292.png" /></p>
<ul>
<li>feature：</li>
</ul>
<p><img alt="image-20241108142931213" src="../assets/image-20241108142931213.png" /></p>
<p><img alt="image-20241108145640376" src="../assets/image-20241108145640376.png" /></p>
<p>ISPD 2011 [16] and DAC 2012 [17] contest benchmarks , </p>
<h5 id="model_3">model<a class="headerlink" href="#model_3" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241219145252874" src="../assets/image-20241219145252874.png" /></p>
<p><img alt="image-20241108144617443" src="../assets/image-20241108144617443.png" /></p>
<p>他这里说 congestion map 是一个二值化(0/1?)的数据集， 所以是分类任务, 但是为了利用数据，同时防止 routing demand 的信息丢失， 还设置了一个预测 routing demand 的任务？</p>
<h5 id="experiment_3">experiment<a class="headerlink" href="#experiment_3" title="Permanent link">&para;</a></h5>
<p>15benchmarks: 10 for training and 5 for testing  </p>
<p>run <strong>DREAMPlace</strong> [18] on each of the designs to generate placement solutions </p>
<p><strong>NCTU-GR 2.0</strong> [2] to attain horizontal/vertical <strong>routing demand maps</strong>  , and set the <strong>congestion maps</strong> as a <strong>binary</strong> indicator according to whether the horizontal/vertical routing demand of the G-cell <strong>exceeds the circuit’s capacity</strong>  </p>
<p><img alt="image-20241108150810402" src="../assets/image-20241108150810402.png" /></p>
<p><img alt="image-20241108150803029" src="../assets/image-20241108150803029.png" /></p>
<p><img alt="image-20241108150837509" src="../assets/image-20241108150837509.png" /></p>
<p>对比实验：</p>
<p><img alt="image-20241108151611413" src="../assets/image-20241108151611413.png" /></p>
<p><img alt="image-20241108151757751" src="../assets/image-20241108151757751.png" /></p>
<p>可视化：</p>
<p><img alt="image-20241108150918563" src="../assets/image-20241108150918563.png" /></p>
<p>消融实验：</p>
<p><img alt="image-20241108152104185" src="../assets/image-20241108152104185.png" /></p>
<h4 id="clusternet-iccad-2023-korea"><a href="">ClusterNet- -ICCAD-2023--Korea</a><a class="headerlink" href="#clusternet-iccad-2023-korea" title="Permanent link">&para;</a></h4>
<ul>
<li>Netlist as input</li>
</ul>
<h4 id="medusa-2d3d-trans-2023-cnn-columbia"><a href="https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/3590768">MEDUSA-2D&amp;3D-Trans-2023-CNN-Columbia  </a><a class="headerlink" href="#medusa-2d3d-trans-2023-cnn-columbia" title="Permanent link">&para;</a></h4>
<ul>
<li>Routing congestion is one of the many factors that need to be minimized during the physical design phase of large integrated circuits. </li>
<li>compare with <code>c-DCGAN [33]</code> , which is GAN-based. One of the drawbacks of GANs, however, is that they are generally difficult to train and so the performance benefits that they may yield comes at a significant computing cost.  </li>
<li></li>
</ul>
<h5 id="background_5">background<a class="headerlink" href="#background_5" title="Permanent link">&para;</a></h5>
<ul>
<li>feature encoding algorithm.</li>
</ul>
<p>Features extracted from the routing topology are stored in a multi-layer hyper-image that preserves the circuit’s structural information</p>
<ul>
<li>
<p>a customized CNN   </p>
</li>
<li>
<p>takes our proposed hyper-image as inputs and produces congestion maps that are comparable to ground truth</p>
</li>
<li>
<p>simplified customized CNNs  </p>
</li>
<li>
<p>embedded them with two open source routers</p>
</li>
</ul>
<h5 id="contribution_4">contribution<a class="headerlink" href="#contribution_4" title="Permanent link">&para;</a></h5>
<ul>
<li></li>
</ul>
<h5 id="flow_2">flow<a class="headerlink" href="#flow_2" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250419181244276" src="../assets/image-20250419181244276.png" /></p>
<p><img alt="image-20250419181016015" src="../assets/image-20250419181016015.png" /></p>
<h5 id="model_4">model<a class="headerlink" href="#model_4" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250419174928184" src="../assets/image-20250419174928184.png" /></p>
<ul>
<li>In 3D routing m = 16;   </li>
<li>
<p>input feature:</p>
</li>
<li>
<p>Vertex related: Pin density and level-one pin density  </p>
</li>
<li>Vertex-east-edge related: Wire density, wire usage, and wire capacity  </li>
<li>Vertex-north-edge related: Wire density, wire usage, and wire capacity  </li>
<li>3D information: Via usage and capacity.  </li>
<li>Wire density是pattern routing的结果</li>
<li>pattern routing 具体是怎么做的？</li>
</ul>
<p><img alt="image-20250419174933984" src="../assets/image-20250419174933984.png" /></p>
<p><strong>CU-GR-M and UBC-Route</strong></p>
<ul>
<li>In the case of 2D routing, m = 2 ；</li>
<li>the via feature is not considered when using MEDUSA-2D  </li>
</ul>
<p><img alt="image-20250419181857247" src="../assets/image-20250419181857247.png" /></p>
<p>The cost functions of CU-GR [21] do not take into consideration the estimated via usage produced by MEDUSA-3D  </p>
<p><img alt="image-20250419181951737" src="../assets/image-20250419181951737.png" /></p>
<h5 id="data_4">data<a class="headerlink" href="#data_4" title="Permanent link">&para;</a></h5>
<p>developed MEDUSA-3D, which is used with <code>CU-GR [21]</code> for performing 3D routing on <code>ICCAD 2019 benchmarks</code>   </p>
<p>MEDUSA-2D, was also developed to be used for traditional 2D routing using <code>ISPD 2008 benchmarks</code>[1].   </p>
<h5 id="experiment_4">experiment<a class="headerlink" href="#experiment_4" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250419182310076" src="../assets/image-20250419182310076.png" /></p>
<p>PD, NP, ND, LN, GN, and C are abbreviations for pin density, neighborhood pin density, net density, local net, global net, and capacity (both pin capacity and via capacity if applicable), respectively  </p>
<p><img alt="image-20250419183118299" src="../assets/image-20250419183118299.png" /></p>
<p><img alt="" src="../assets/image-20250419183137781.png" /></p>
<p><img alt="image-20250419183649292" src="../assets/image-20250419183649292.png" /></p>
<p><img alt="image-20250419183658723" src="../assets/image-20250419183658723.png" /></p>
<h4 id="-nn-robustness-improve-arxiv-2024-uc-"><a href="">-NN Robustness improve-arXiv-2024- -UC-</a><a class="headerlink" href="#-nn-robustness-improve-arxiv-2024-uc-" title="Permanent link">&para;</a></h4>
<h5 id="background_6">background<a class="headerlink" href="#background_6" title="Permanent link">&para;</a></h5>
<ul>
<li>最近的工作已经证明神经网络通常是容易受到精心选择的输入小扰动的影响 </li>
<li>Our definition of <strong>imperceptibility</strong> is characterized by a guarantee that a perturbation to a layout will not alter its global routing  </li>
<li>recent work [10, 18] has demonstrated that image classifiers can be <strong>fooled</strong> by <strong>small, carefully chosen</strong> perturbations of their input  </li>
<li><img alt="image-20250102215202387" src="../assets/image-20250102215202387.png" /></li>
</ul>
<h5 id="task_4">task<a class="headerlink" href="#task_4" title="Permanent link">&para;</a></h5>
<ul>
<li>design two efficient methods for finding perturbations that demonstrate brittleness of recently proposed congestion predictors  </li>
<li>one potential approach to address the issues by modifying the training procedure to promote robustness</li>
</ul>
<h5 id="contribution_5">contribution<a class="headerlink" href="#contribution_5" title="Permanent link">&para;</a></h5>
<p><a href="https://ieeexplore.ieee.org/document/8807040">Painting on PIacement-predict the routing congestion-ACM-2019-GAN-</a></p>
<p><img alt="image-20241012153331855" src="../assets/image-20241012153331855.png" /></p>
<p><img alt="image-20241012153541960" src="../assets/image-20241012153541960.png" /></p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9401274">-DRC Hotspot Prediction-ISCAS-2021-CNN</a></p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9045178">-Routing Congestion Prediction-ASPDAC-2020-GAN</a></p>
<ul>
<li>slice <a href="https://yibolin.com/publications/papers/FPGA_ASPDAC2020_Alawieh.slides.pdf">FPGACong_ASPDAC20 (yibolin.com)</a></li>
</ul>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8715126">-predict #DRV, a macro placer-DATE-2019-CNN</a></p>
<h3 id="timing">Timing<a class="headerlink" href="#timing" title="Permanent link">&para;</a></h3>
<h4 id="background_7">background<a class="headerlink" href="#background_7" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241026164128136" src="../assets/image-20241026164128136.png" /></p>
<h4 id="timinggcn-sta-prediction-dac-2022-gnn"><a href="https://dl.acm.org/doi/abs/10.1145/3489517.3530597">TimingGCN-STA prediction-DAC-2022-GNN</a><a class="headerlink" href="#timinggcn-sta-prediction-dac-2022-gnn" title="Permanent link">&para;</a></h4>
<ul>
<li>the first work！</li>
<li>opensource</li>
<li>still relies on local net/cell delay prediction as auxiliary tasks  </li>
<li>no optimization, not fit the real-world scenario where timing <strong>optimization</strong> is taken into account  </li>
</ul>
<p><a href="https://github.com/Thinklab-SJTU/EDA-AI/tree/main/PreRoutGNN">PreRoutGNN-STA prediction-AAAI-2024-GNN</a></p>
<ul>
<li>opensource</li>
</ul>
<h4 id="multimodal-fusion-restructure-tolerantcnnendpoint-wise-masking4layout-dac-2023-gnncnn-7nm-riscv"><a href="D:\MyNotes\EDA\Timing\Multimodal Fusion-Pre Route Timing Prediction-DAC-2023-GNN-7nm RISCV.pdf">Multimodal Fusion-Restructure tolerant+CNN+Endpoint-wise Masking4Layout -DAC-2023-GNN+CNN-7nm RISCV</a><a class="headerlink" href="#multimodal-fusion-restructure-tolerantcnnendpoint-wise-masking4layout-dac-2023-gnncnn-7nm-riscv" title="Permanent link">&para;</a></h4>
<p><a href="https://www.cse.cuhk.edu.hk/~byu/papers/C167-DAC2023-PathPred-poster.pdf">slice</a></p>
<ul>
<li>
<p>Restructure：预测终点的延时，但是 Timing Opt 会改变网表结构(end point 不变）。对一个 Pre-routing 任务来说，输入的网表和最终的网表不一样</p>
</li>
<li>
<p>netlist <strong>restructuring</strong> causes a mismatch between local input features and ground-truth features in the restructured sub-regions  </p>
</li>
</ul>
<p><img alt="image-20241026173420844" src="../assets/image-20241026173420844.png" /></p>
<p>As a result, prior local-view models can only be trained on the unchanged regions in a <strong>semi-supervised manner</strong>.  </p>
<p>In other words, the better the models fit on labeled (unreplaced) net/cell delays, the worse they fit on replaced regions and eventually on endpoint arrival time  </p>
<ul>
<li>
<p>数据集：基本信息和 Timing 优化导致的网表变化</p>
</li>
<li>
<p>average 40% nets and 21% cells are replaced during timing optimization  </p>
</li>
<li>timing optimization brings an average change of 59.6% to net delays
    and 33.3% to cell delays  </li>
</ul>
<p><img alt="image-20241026170120254" src="../assets/image-20241026170120254.png" /></p>
<ul>
<li>
<p>为什么用 layout 信息：Since most timing optimization techniques include gate insertion or gate sizing, placement should reserve space for subsequent timing
  optimization. In other words, the timing optimizer’s efficacy is tied closely to global layout information. The layout information plays a dominant role in determining the timing optimizer’s impact since most optimization
  techniques need space to be applied  </p>
</li>
<li>
<p>整体模型</p>
</li>
</ul>
<p><img alt="image-20241026184138343" src="../assets/image-20241026184138343.png" /></p>
<p>组成：<strong>GNN+CNN+Endpoint-wise Masking</strong>  </p>
<ul>
<li>Netlist(GNN):</li>
</ul>
<p><img alt="image-20241026184646854" src="../assets/image-20241026184646854.png" /></p>
<p>和 <a href="https://dl.acm.org/doi/abs/10.1145/3489517.3530597">TimingGCN-STA prediction-DAC-2022-GNN</a> 很像(没发现不同)</p>
<ul>
<li>
<p>Layout(CNN+Endpoint-wise Masking)</p>
<p><img alt="image-20241026185621311" src="../assets/image-20241026185621311.png" /></p>
<p><img alt="image-20241026193815323" src="../assets/image-20241026193815323.png" /></p>
<p>三个特征：cell density, rectangular uniform wire density (RUDY), and macro cells region  </p>
<p><img alt="image-20241026190115449" src="../assets/image-20241026190115449.png" /></p>
<p><strong>Endpoint-wise Masking</strong>  </p>
<p><img alt="image-20241026194544366" src="../assets/image-20241026194544366.png" /></p>
</li>
<li>
<p>对比实验：</p>
</li>
</ul>
<p><img alt="image-20241026200330616" src="../assets/image-20241026200330616.png" /></p>
<p><img alt="image-20241026200838620" src="../assets/image-20241026200838620.png" /></p>
<ul>
<li>run time 实验</li>
</ul>
<p><img alt="image-20241026201203648" src="../assets/image-20241026201203648.png" /></p>
<h5 id="other">other<a class="headerlink" href="#other" title="Permanent link">&para;</a></h5>
<p><a href="file:///D:/MyNotes/EDA/Timing/aheadRCnetwork.pdf">Ahead RC network-STA prediction-DAC-2022-?</a></p>
<p><a href="https://ieeexplore.ieee.org/document/9643435">Doomed Run Prediction-TNS prediction-ACM-2021-GNN+RNN</a></p>
<p><img alt="image-20241007121002859" src="../assets/image-20241007121002859.png" /></p>
<h5 id="not-dl">not DL<a class="headerlink" href="#not-dl" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241026164603048" src="../assets/image-20241026164603048.png" /> The two-stage approaches [2], [3] first predict localnet/cell delays and then apply PERT traversals [5] to evaluate the global timing metrics, i.e., endpoint arrival time.  </p>
<h2 id="optimization">Optimization<a class="headerlink" href="#optimization" title="Permanent link">&para;</a></h2>
<h3 id="timing_1">Timing<a class="headerlink" href="#timing_1" title="Permanent link">&para;</a></h3>
<h4 id="tsteiner-steiner-points-opt-dac-2023-gnn-cuhk"><a href="">TSteiner - Steiner Points Opt-DAC-2023-GNN-CUHK</a><a class="headerlink" href="#tsteiner-steiner-points-opt-dac-2023-gnn-cuhk" title="Permanent link">&para;</a></h4>
<h5 id="background_8">background<a class="headerlink" href="#background_8" title="Permanent link">&para;</a></h5>
<p>对于 multi-pin net 需要构建 steiner tree 来进行 routing，故 steiner tree 中 steiner points 也会影响 routing</p>
<p>FLUTE [<a href="https://www.zhihu.com/question/579615273/answer/3154651342#ref_3">3]</a> 是常用的生成 steiner tree 的算法。在生成 steiner tree 后，我们可以通过近一步优化 steiner point 来优化 timing</p>
<p><img alt="image-20241102112154369" src="../assets/image-20241102112154369.png" /></p>
<p>the previous early-stage timing optimization works only focus on improving
early timing metrics. 提出了诸如 net 加权和可微分时间目标等策略来优化时间, only focus on improving pre-routing timing metrics, which may have a considerable gap to <strong>signoff</strong> timing performance. 斯坦那点更加靠近布线阶段(和布线更加相关)</p>
<p>all the aforementioned works are not directly targeted at sign-off timing performance due to its high acquisition cost  </p>
<p><strong>任务:</strong></p>
<p><img alt="image-20241102111709494" src="../assets/image-20241102111709494.png" /></p>
<p>In this paper, we focus on explicit sign-off timing optimization at the pre-routing stage to reduce the turnaround time</p>
<p>optimization framework is built to adjust Steiner point positions  for better sign-off timing performance iteratively  </p>
<p>The most popular Steiner minimum tree construction algorithms aim to <strong>minimize wirelength</strong>. Moreover, the Steiner point refinement is introduced to update the generated Steiner point positions for specific objectives, e.g., sign-off timing performance, while maintaining the two-pin net connections</p>
<p><strong>启发:</strong></p>
<p>we surprisingly find that the signoff timing performance could be significantly affected even by a <strong>random</strong> disturbance on Steiner point positions, as shown in Fig. 2.  </p>
<p><img alt="image-20241102114842155" src="../assets/image-20241102114842155.png" /></p>
<p>Nevertheless, the impact of random moving is considerately unstable, and its average performance is slight (with a ratio close to 1.0).  所以启发找到一个好的方法来更新斯坦纳点来降低 TNS</p>
<p>在最广泛使用的技术节点中，与 <strong>路径长度</strong> 最相关的定时度量——净延迟，并不能解释大部分的整体定时性能. 这里用的初始化斯泰纳树的方法的优化目标都是路径长度最短</p>
<h5 id="contribution_6">contribution:<a class="headerlink" href="#contribution_6" title="Permanent link">&para;</a></h5>
<ul>
<li>first  earlystage timing optimization framework   via Steiner point refinement</li>
<li>GNN</li>
<li>TSteiner framework is fully automated with an adaptive stepsize scheme and the auto-convergence scheme  </li>
<li>improves 11.2% and 7.1% on average (up to 45.8% and 43.9%) for WNS and TNS</li>
</ul>
<p><strong>模型:</strong></p>
<p>Steiner tree construction decomposes each multi-pin net into <strong>a set of two-pin</strong>
<strong>nets</strong> via additional Steiner points before global routing  to reduce the problem complexity</p>
<p>The proposed framework can be divided into two stages, <strong>sign-off timing gradient generation</strong> (Section III-A) and <strong>concurrent Steiner point refinement</strong> (Section III-B)  </p>
<p><img alt="image-20241102123009705" src="../assets/image-20241102123009705.png" /></p>
<p><img alt="image-20241102115937138" src="../assets/image-20241102115937138.png" /></p>
<p>和 TimingGCN 相比就是多了 Steiner 节点, 然后吧第一部分的的 node embedding 部分加上了 steiner 的部分</p>
<p><img alt="image-20241102121828217" src="../assets/image-20241102121828217.png" /></p>
<p>实际是: <img alt="image-20241102122509138" src="../assets/image-20241102122509138.png" /></p>
<p><img alt="image-20241102122552273" src="../assets/image-20241102122552273.png" /></p>
<p>优化的指标, WNS 和 TNS 的加权</p>
<p>根据优化指标对斯泰纳点坐标参数做梯度下降</p>
<p><img alt="image-20241102132825834" src="../assets/image-20241102132825834.png" /></p>
<p><img alt="image-20250102200912287" src="../assets/image-20250102200912287.png" /></p>
<p>相比简单的梯度下降，只是减小了对不同 benchmark 的手动学习率微调</p>
<p><strong>数据</strong></p>
<p><img alt="image-20241102132430596" src="../assets/image-20241102132430596.png" /></p>
<p><strong>实验</strong></p>
<p><img alt="image-20241102132506821" src="../assets/image-20241102132506821.png" /></p>
<p><img alt="image-20241102132555409" src="../assets/image-20241102132555409.png" /></p>
<p><img alt="image-20241102132646602" src="../assets/image-20241102132646602.png" /></p>
<p><img alt="image-20241102132734827" src="../assets/image-20241102132734827.png" /></p>
<h3 id="placement">Placement<a class="headerlink" href="#placement" title="Permanent link">&para;</a></h3>
<h4 id="-pin-accessibilitydrv-prediction-dac-2019-cnn-ntu"><a href="">-Pin Accessibility+DRV prediction-DAC-2019-CNN-NTU</a><a class="headerlink" href="#-pin-accessibilitydrv-prediction-dac-2019-cnn-ntu" title="Permanent link">&para;</a></h4>
<h5 id="background_9">background<a class="headerlink" href="#background_9" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Standard cells on the lower metal layers severely suffer from low routability due to high pin density, low pin accessibility, and limited routing resources.  </p>
</li>
<li>
<p><img alt="image-20250206153002501" src="../assets/image-20250206153002501.png" /></p>
</li>
</ul>
<p>It can be observed that the access points of pin B are blocked by the metal 2 (M2) routing segments routed from Pin A and Pin C, so an M2 short design rule violation (DRV) will be induced when dropping a via12 on Pin B. pin accessibility is not only determined by cell layout design but also strongly affected by adjacent cells    </p>
<ul>
<li>
<p>对于传统方法，两个缺点：</p>
</li>
<li>
<p>Cell libraries provided by foundries should not be considerably redesigned because the optimized cell performance and manufacturability may be highly sensitive to cell layouts  </p>
</li>
<li>
<p>Deterministic approaches based on <strong>human knowledge have been shown to be less effective in advanced nodes</strong> for optimization problems such as DRV prediction and minimization because of the extremely high complexity through the overall design flow  </p>
</li>
<li>
<p><img alt="image-20250206154744610" src="../assets/image-20250206154744610.png" /></p>
</li>
</ul>
<p>It can be observed that most of the congested regions in the layout do not have DRVs, while some regions with DRVs are not so congested. 但是我感觉还是有相关性的。他是想说明 congestion 出现的地方不一定有 DRV，但是没 congestion 的地方可能因为 poor pin accessibility 导致 DRV</p>
<ul>
<li>
<p><img alt="image-20250206154811206" src="../assets/image-20250206154811206.png" /></p>
</li>
<li>
<p>也是说明：congestion 出现的地方不一定有 DRV，但是没 congestion 的地方可能因为 poor pin accessibility 导致 DRV</p>
</li>
<li>the two M2 shorts occur at the locations having <strong>the same pin pattern</strong> in the top cell-row and mid cell-row  </li>
</ul>
<h5 id="task_5">task<a class="headerlink" href="#task_5" title="Permanent link">&para;</a></h5>
<ul>
<li>DRV prediction, 二分类</li>
</ul>
<p><img alt="image-20250206190055066" src="../assets/image-20250206190055066.png" /></p>
<ul>
<li>pin accessibility optimization, 给一个合法化后的布局结构，通过算法进行减少 bad pin accessibility 的 detailed placement</li>
</ul>
<p><img alt="image-20250206190225309" src="../assets/image-20250206190225309.png" /></p>
<ul>
<li>其实也是一个预测模型，一个优化模型</li>
</ul>
<h5 id="contribution_7">contribution<a class="headerlink" href="#contribution_7" title="Permanent link">&para;</a></h5>
<h2 id="-first-work-to-apply-pin-pattern-as-the-input-features-of-drv-prediction-models">- first work to apply pin pattern as the input features of <code>DRV prediction models</code>.<a class="headerlink" href="#-first-work-to-apply-pin-pattern-as-the-input-features-of-drv-prediction-models" title="Permanent link">&para;</a></h2>
<h5 id="flow_3">flow<a class="headerlink" href="#flow_3" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250206191224771" src="../assets/image-20250206191224771.png" /></p>
<p><strong>model:</strong></p>
<p>PPR&amp;DFPPR:</p>
<p><img alt="image-20250206192506245" src="../assets/image-20250206192506245.png" /></p>
<p>Model-guided Detailed Placement :</p>
<p><img alt="image-20250206195817013" src="../assets/image-20250206195817013.png" /></p>
<p><img alt="image-20250206202610856" src="../assets/image-20250206202610856.png" /></p>
<p>Dynamic Programming-based Placement Blockage Insertion  </p>
<p><img alt="image-20250206202803548" src="../assets/image-20250206202803548.png" /></p>
<ul>
<li>还会改方向？</li>
</ul>
<p>Cell Displacement Refinement</p>
<h5 id="data_5">data<a class="headerlink" href="#data_5" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250206192552413" src="../assets/image-20250206192552413.png" /></p>
<p>Both the width and height of each pixel are set as the <strong>minimum spacing of the M1 layer</strong> in order to prevent a pixel from being occupied by two different pins. </p>
<p>没看见关于 benchmark 的描述</p>
<h5 id="experiment_5">experiment<a class="headerlink" href="#experiment_5" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250206204743555" src="../assets/image-20250206204743555.png" /></p>
<p><img alt="image-20250206205223899" src="../assets/image-20250206205223899.png" /></p>
<p><strong>shortcoming:</strong></p>
<ul>
<li>flow need routed designs to train, time </li>
<li>The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries  </li>
<li>对于 VLSI，一行一行，一对一对进行，很慢？</li>
<li></li>
</ul>
<h4 id="-pin-accessibilityactiv-ispd-2020-ntusynopsys"><a href="https://pdfs.semanticscholar.org/47f1/5e9fa283faddb8a6853398145d33e2ba9ae1.pdf">-Pin Accessibility+activ-ISPD-2020- -NTU+Synopsys</a><a class="headerlink" href="#-pin-accessibilityactiv-ispd-2020-ntusynopsys" title="Permanent link">&para;</a></h4>
<h5 id="background_10">background<a class="headerlink" href="#background_10" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>With the development of advanced process nodes of semiconductor, the problem of <code>pin access</code> has become one of the major factors to impact the occurrences of design rule violations (DRVs) due to complex design rules and limited routing resource  </p>
</li>
<li>
<p><code>supervised learning</code> approaches extract the labels of training data by generating a great number of routed designs in advance, giving rise to large effort on training data preparation. the pre-trained model could hardly predict unseen data    </p>
</li>
<li>
<p>Unlike most of existing studies that aim at <code>design-specific</code> training, we propose a <code>library-based</code> model which can be applied to all designs referencing to the same standard cell library set.   </p>
</li>
<li>
<p>Due to the shrinking of modern process nodes of semiconductor, the <strong>pin access problem</strong> of standard cells has become more harder to be coped with, especially on the <strong>lower metal layers</strong>.  </p>
</li>
<li>
<p><img alt="image-20250206150405665" src="../assets/image-20250206150405665.png" /></p>
</li>
</ul>
<p>在这种 placement 下，Metal1 pin A/B 由于各自左右两边在 Metal2 有 pin，而且只能在黄色 track 下横向绕线，（Metal1 不能绕线？），那么 Pin A/B 通过 Via12 后必定会短路</p>
<ul>
<li>
<p>19 年工作 [5] 的两个缺点</p>
</li>
<li>
<p>flow need routed designs to train, time </p>
</li>
<li>
<p>The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries  </p>
</li>
<li></li>
</ul>
<h5 id="contribution_8">contribution<a class="headerlink" href="#contribution_8" title="Permanent link">&para;</a></h5>
<ul>
<li>first work of <code>cell library-based</code> pin accessibility prediction (PAP), which can be applied to predict other designs referencing to the same cell library set</li>
<li>applies <strong>active learning</strong> to train a PAP model  </li>
<li>the proposed cell library-based PAP model <strong>can be trained at the earlier stage</strong> in a process development flow: once the cell libraries are provided.  </li>
<li></li>
</ul>
<h4 id="placement-optimization-with-deep-reinforcement-learning-ispd-2020-rlgnn-google"><a href="[dl.acm.org/doi/pdf/10.1145/3372780.3378174](https://dl.acm.org/doi/pdf/10.1145/3372780.3378174)">Placement Optimization with Deep Reinforcement Learning- -ISPD-2020-RL+GNN-Google</a><a class="headerlink" href="#placement-optimization-with-deep-reinforcement-learning-ispd-2020-rlgnn-google" title="Permanent link">&para;</a></h4>
<h4 id="pl-gnn-affinity-aware-for-icc2-ispd-2021-gnn-atlanta"><a href="https://dl.acm.org/doi/pdf/10.1145/3439706.3447045">PL GNN-Affinity Aware for ICC2- ISPD-2021-GNN-Atlanta</a><a class="headerlink" href="#pl-gnn-affinity-aware-for-icc2-ispd-2021-gnn-atlanta" title="Permanent link">&para;</a></h4>
<h5 id="background_11">background:<a class="headerlink" href="#background_11" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Placement is one of the most <strong>crucial problems</strong>,  placement directly impacts the final quality of a full-chip design</p>
</li>
<li>
<p>multiple placement <strong>iterations</strong> to optimize key metrics(WL, timing), which is <strong>time-consuming</strong> and computationally inefficient, VLSI</p>
</li>
<li>
<p>the <code>logical affinity</code> among design instancesdominates the quality of the placement</p>
</li>
</ul>
<p><img alt="image-20241224115010379" src="../assets/image-20241224115010379.png" /></p>
<p><code>logical affinity</code> 源于这篇文章？</p>
<ul>
<li>
<p>performing <strong>placement guidance</strong> requires in-depth design-specific knowledge, which is only achievable by <strong>experienced designers</strong> who knows the underlying data flows in Register-Transistor Level (RTL) well  </p>
</li>
<li>
<p><img alt="image-20241224114254672" src="../assets/image-20241224114254672.png" /></p>
</li>
<li>
<p>K-means 基础：</p>
</li>
<li>
<p><img alt="image-20241224172053839" src="../assets/image-20241224172053839.png" /></p>
</li>
<li>
<p><img alt="image-20241224172022162" src="../assets/image-20241224172022162.png" /></p>
</li>
</ul>
<h5 id="task_6">task<a class="headerlink" href="#task_6" title="Permanent link">&para;</a></h5>
<ul>
<li>基于网表数据，和 floorplan 结果（marco 已经放好）</li>
<li><code>placement guidance</code>(grouping information) for commercial placers <code>ICC2</code>, by generating <strong>cell clusters</strong> based on <strong>logical affinity</strong> and manually defined attributes of design instances  </li>
<li>our framework will determine the <code>cell clusters</code> in an <strong>unsupervised</strong> manner which serve as placement guidance in order to guide commercial placers to optimize the key metrics such as <strong>wirelength, power, and timing</strong> by placing cells with a common <strong>cluster</strong> together</li>
</ul>
<h5 id="flow_4">flow<a class="headerlink" href="#flow_4" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241224111801884" src="../assets/image-20241224111801884.png" /></p>
<p><strong>Two stages:</strong></p>
<ol>
<li>
<p>GNN do unsupervised node representation learning, (it is generalizable to any design)</p>
</li>
<li>
<p><code>weighted K-means clustering algorithm [3]</code> to group instances into different clusters。To find the optimal number of groups for clustering, we introduce the <code>Silhouette score [19]</code> and perform sweeping experiments to find the sweet spot  </p>
</li>
</ol>
<p>K-means 算法的基本思想是：通过迭代的方式，将数据划分为 <strong>K 个不同的簇</strong>，并使得每个数据点与其所属簇的质心（或称为中心点、均值点）之间的 <strong>距离之和最小</strong>。</p>
<p><img alt="image-20241007102413593" src="../assets/image-20241007102413593.png" /></p>
<h5 id="data_6">data<a class="headerlink" href="#data_6" title="Permanent link">&para;</a></h5>
<p>two multi-core CPU designs：</p>
<p><img alt="image-20241224181733657" src="../assets/image-20241224181733657.png" /></p>
<p><strong>nf</strong></p>
<ul>
<li><strong>design hierarchy</strong> : 根据网表层级. top/inst1/sky130_INV/A. (同时 zero-padding)</li>
</ul>
<p><img alt="image-20241224160726962" src="../assets/image-20241224160726962.png" /></p>
<ul>
<li><strong>logical affinity of memory macros</strong> ：logical levels to memory macros 𝑀 as features. because the logic to memory paths are often the critical timing paths  </li>
</ul>
<p><img alt="image-20241224161329678" src="../assets/image-20241224161329678.png" /></p>
<p><strong>ef:</strong></p>
<p><img alt="image-20241224171228803" src="../assets/image-20241224171228803.png" /></p>
<h5 id="model_5">model<a class="headerlink" href="#model_5" title="Permanent link">&para;</a></h5>
<ul>
<li>GraphSAGE-based， two layers</li>
</ul>
<p><img alt="image-20241224161923488" src="../assets/image-20241224161923488.png" /></p>
<p><img alt="image-20241224162351812" src="../assets/image-20241224162351812.png" /></p>
<ul>
<li>Loss Function:</li>
</ul>
<p><img alt="image-20241224170359079" src="../assets/image-20241224170359079.png" /></p>
<p><img alt="image-20241224170818328" src="../assets/image-20241224170818328.png" /></p>
<p><img alt="image-20241224170824860" src="../assets/image-20241224170824860.png" /></p>
<p><strong>Silhouette score</strong>  </p>
<p>用于评估分类结果，扫描分类数目，选择最高的分的</p>
<p><img alt="image-20241224181002019" src="../assets/image-20241224181023453.png" /></p>
<p><img alt="image-20241224181044251" src="../assets/image-20241224181044251.png" /></p>
<p><img alt="image-20241224181052309" src="../assets/image-20241224181052309.png" /></p>
<p><img alt="image-20241224181116187" src="../assets/image-20241224181116187.png" /></p>
<h5 id="experiment_6">experiment<a class="headerlink" href="#experiment_6" title="Permanent link">&para;</a></h5>
<p><strong>env</strong>:</p>
<ul>
<li>2.40𝐺𝐻𝑍 CPU   </li>
<li>NVIDIA RTX 2070   </li>
<li>16𝐺𝐵 memory.  </li>
<li>PyTorch Geometric   </li>
</ul>
<p><strong>setting:</strong></p>
<ul>
<li>the placement of memory macros is achieved manually based on design manuals provided by the design-house  </li>
<li>Adam   </li>
</ul>
<p><strong>result</strong></p>
<p>Louvain：比较实验对比模型</p>
<p><img alt="image-20241224181627782" src="../assets/image-20241224181627782.png" /></p>
<p><strong>Question</strong>:</p>
<p>benchmark 少</p>
<p>扫描到的就适用所有？</p>
<p>开环？</p>
<h4 id="-innovus-ppa-placement-optimize-neurips-2021-rl"><a href="https://www.semanticscholar.org/paper/A-General-Framework-For-VLSI-Tool-Parameter-with-Agnesina-Pentapati/30c644ffa213418182e795ea5e8132cb15e891c2">-Innovus PPA placement optimize-Neurips-2021-RL </a><a class="headerlink" href="#-innovus-ppa-placement-optimize-neurips-2021-rl" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241007103637165" src="../assets/image-20241007103637165.png" /></p>
<p><img alt="image-20241007105134964" src="../assets/image-20241007105134964.png" /></p>
<h5 id="contribution_9">contribution:<a class="headerlink" href="#contribution_9" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241224114117771" src="../assets/image-20241224114117771.png" /></p>
<h4 id="-gp-routability-opt-dac-2021-fcn-cuhksitingliu-beiyuyibo-lin"><a href="">-GP Routability Opt-DAC-2021-FCN-CUHK(SitingLiu BeiYu)+Yibo Lin</a><a class="headerlink" href="#-gp-routability-opt-dac-2021-fcn-cuhksitingliu-beiyuyibo-lin" title="Permanent link">&para;</a></h4>
<h5 id="background_12">background<a class="headerlink" href="#background_12" title="Permanent link">&para;</a></h5>
<h5 id="flow_5">flow<a class="headerlink" href="#flow_5" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241226160945080" src="../assets/image-20241226160945080.png" /></p>
<ol>
<li>three input features are extracted from the cell placement solution  </li>
<li>Through the inference of the pre-trained routability prediction model, we get the predicted congestion map.  </li>
<li>take <code>mean squared Frobenius norm</code> of this congestion map as the congestion penalty</li>
<li></li>
</ol>
<p><img alt="image-20241226161200384" src="../assets/image-20241226161200384.png" /></p>
<h5 id="data_7">data<a class="headerlink" href="#data_7" title="Permanent link">&para;</a></h5>
<h5 id="model_6">model<a class="headerlink" href="#model_6" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241226161132128" src="../assets/image-20241226161132128.png" /></p>
<h4 id="lay-net-iccadtcad-20232025-gnnvit-cuhk-"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10323800">Lay-Net- -ICCAD/TCAD-2023/2025-GNN/ViT-CUHK-</a><a class="headerlink" href="#lay-net-iccadtcad-20232025-gnnvit-cuhk-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/lanchengzou/congPred#">OpenSource!</a></li>
<li>heterogeneous message-passing paradigm better embeds the routing demand into the model by considering both connections between cells and overlaps of nets  </li>
<li>TCAD 比 ICCAD 多了contrastive learning和miniGnet</li>
</ul>
<h5 id="background_13">background:<a class="headerlink" href="#background_13" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>To accurately model the congestion, placers commonly integrate routing processes [14]–[17] or analytical models [18]–[21] to estimate the congestion. However, the <code>routing-based methods</code> are plagued by considerable runtime overhead while the <code>model-based approaches</code> suffer from low accuracy</p>
</li>
<li>
<p>key module</p>
</li>
<li>
<p>Swin Transformer</p>
<ul>
<li>详情查看<a href="../NN/CNN/cnn.md">CNN</a></li>
</ul>
</li>
<li>
<p>UperNet[42]</p>
</li>
<li>
<p>feature pyramids[41] and Pyramid pooling module (PPM) [43]  </p>
</li>
<li>
<p>motivation:</p>
</li>
<li><mark>multimodal</mark> fusion of layout and netlist features has not been extensively. Existing models cannot effectively aggregate the information given by cell locations and net connectivity.   </li>
<li>most methods can only utilize <mark>local information</mark>  <ul>
<li><code>vision-based models</code> predict congestion by extracting local features with convolutional layers, which lacks a global view of the routing demand  </li>
<li><code>over-smoothing problem of GNN</code> [33] limits the collection of long-range information  </li>
</ul>
</li>
<li>existing GNN models(LHNN) overlook the routing demand arising from the <mark>overlaps of nets</mark>, which is a crucial factor contributing to routing congestion.  <ul>
<li>the <code>cell-to-cell</code> or <code>cell-to-net</code> links in existing approaches cannot directly model the physical routing demand in GNNs  </li>
</ul>
</li>
</ul>
<h5 id="contribution_10">contribution<a class="headerlink" href="#contribution_10" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>a <mark>multimodal</mark> congestion prediction model  </p>
</li>
<li>
<p>gathering diverse information that can indicate routing congestion</p>
</li>
<li>
<p><mark>hierarchical</mark> feature maps </p>
</li>
<li>
<p>address the limitation of local information  </p>
</li>
<li>
<p><mark>net-to-net</mark> message passing</p>
</li>
<li>
<p>Cell-to-cell and cell-to-netconnections can reflect the logical relationships betweenthe circuit components. Net-to-net connections can imply the physical relationships between the nets</p>
</li>
<li>
<p>first <mark>contrastive learning</mark> </p>
</li>
</ul>
<h5 id="flow_6">flow<a class="headerlink" href="#flow_6" title="Permanent link">&para;</a></h5>
<h5 id="model_7">model<a class="headerlink" href="#model_7" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250528222725294" src="../assets/image-20250528222725294.png" /></p>
<p><img src="assets/image-20250528222736374.png" alt="image-20250528222736374" style="zoom:50%;" /></p>
<h6 id="task_7">task:<a class="headerlink" href="#task_7" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250524150554089" src="../assets/image-20250524150554089.png" /></p>
<h6 id="multi-scale-feature-extraction">Multi-scale Feature Extraction<a class="headerlink" href="#multi-scale-feature-extraction" title="Permanent link">&para;</a></h6>
<p>Lay-Net extracts multi-scale features via <code>four stages</code>, which are based on Vision Transformer (ViT) [34] and Swin Transformer [35].   </p>
<p><img alt="image-20250524150633457" src="../assets/image-20250524150633457.png" /></p>
<h6 id="vit-and-swin-transformer"><code>ViT</code> and <code>Swin Transformer</code><a class="headerlink" href="#vit-and-swin-transformer" title="Permanent link">&para;</a></h6>
<p>capture <mark>global information</mark>  </p>
<h5 id="graph">graph<a class="headerlink" href="#graph" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250524150540133" src="../assets/image-20250524150540133.png" /></p>
<p><img alt="image-20250524152522701" src="../assets/image-20250524152522701.png" /></p>
<blockquote>
<p>边的数量级会很大吧？</p>
</blockquote>
<p><img alt="image-20250528220917995" src="../assets/image-20250528220917995.png" /></p>
<blockquote>
<p>少见的</p>
</blockquote>
<h5 id="feature">feature<a class="headerlink" href="#feature" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250524155310018" src="../assets/image-20250524155310018.png" /></p>
<p><img alt="image-20250524155445991" src="../assets/image-20250524155445991.png" /></p>
<h6 id="contrastive-learning">contrastive learning<a class="headerlink" href="#contrastive-learning" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250528213436733" src="../assets/image-20250528213436733.png" /></p>
<h6 id="experiment_7">experiment<a class="headerlink" href="#experiment_7" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250528223510181" src="../assets/image-20250528223510181.png" /></p>
<p><img alt="image-20250528223737824" src="../assets/image-20250528223737824.png" /></p>
<p><img alt="image-20250528223747317" src="../assets/image-20250528223747317.png" /></p>
<p><img alt="image-20250528223941835" src="../assets/image-20250528223941835.png" /></p>
<blockquote>
<p>怎么变少了</p>
</blockquote>
<p><img alt="image-20250524160945464" src="../assets/image-20250524160945464.png" /></p>
<h4 id="-congestionvitgnn-tcad-2025-southeast"><a href="">-Congestion+ViT+GNN-TCAD-2025--Southeast</a><a class="headerlink" href="#-congestionvitgnn-tcad-2025-southeast" title="Permanent link">&para;</a></h4>
<ul>
<li>congestion prediction model-based placer optimizer</li>
<li>和<code>Lay-Net</code>很像</li>
<li>HGCN+CNN</li>
</ul>
<h5 id="background_14">background<a class="headerlink" href="#background_14" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>previous way:</p>
</li>
<li>
<p>static-based  </p>
<p>directly estimate routing congestion based on placement attributes (such as pin density and net overlap) without performing actual routing  </p>
<p>such as <code>RUDY</code>  </p>
</li>
<li>
<p>probabilistic-based  </p>
<p>calculate the probability of routing topology of each net based on pattern routing (such as L-shaped or Z-shaped routing) to estimate the congestion  </p>
<p>such as <img src="assets/image-20250920212114822.png" alt="image-20250920212114822" style="zoom: 65%;" /></p>
</li>
<li>
<p>tool-based  </p>
<p>calling global routing tools  </p>
<p>congestion maps obtained by the first two categories of methods are often not accurate enough  </p>
<p>precise but time-consuming  </p>
</li>
<li>
<p>purely image-based models [4], [9], [13], [14] may fail to incorporate critical netlist information,   </p>
</li>
<li>
<p>there have been efforts to address the congestion prediction problem using graph neural network  [15], [16], [17]  </p>
</li>
<li>
<p>the homogeneous GNNs may exhibit poor performance when handling diverse netlists simultaneously  </p>
</li>
</ul>
<blockquote>
<p>[!WARNING]</p>
<p>他没解释这个是为什么，也没引用</p>
</blockquote>
<ul>
<li>
<p>Recently, <code>multimodal fusion-based models</code> have attracted much attention due to their ability to provide various perspectives [19], [20], and current multimodal fusion-based congestion prediction models have demonstrated notable performance [8], [12]. However, they still lack the deep multimodal fusion of placement and netlist features  </p>
</li>
<li>
<p><code>Lay-Net</code> may still fall short in extracting deep features and restoring congestion maps effectively.   </p>
</li>
</ul>
<p><code>Lay-Net</code> only utilizes MLP layers to simply connect transformer and HGNN layers, thus may fail to exploit the potential of deep multimodal feature fusion.  </p>
<ul>
<li>其他领域多模态融合的方法[19],[20]</li>
</ul>
<h5 id="contribution_11">contribution<a class="headerlink" href="#contribution_11" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250920212345656" src="../assets/image-20250920212345656.png" /></p>
<ul>
<li>dual multimodal fusions  </li>
<li>early <code>feature fusion (EFF)</code> method: merge <code>HGCN+CNN</code></li>
<li>deep <code>feature fusion (DFF)</code> method: self attention <code>(SA)</code> [22] cross-attention <code>(CA)</code> [23] to perform cross-modal feature fusion </li>
</ul>
<h5 id="flow_7">flow<a class="headerlink" href="#flow_7" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250921144622709" src="../assets/image-20250921144622709.png" /></p>
<p><img alt="image-20250921142344600" src="../assets/image-20250921142344600.png" /></p>
<h5 id="model_8">model<a class="headerlink" href="#model_8" title="Permanent link">&para;</a></h5>
<p><strong>CNN</strong> input</p>
<p><strong>ResNet50</strong>  </p>
<p><img alt="image-20250921142452461" src="../assets/image-20250921142452461.png" /></p>
<p><strong>Graph</strong></p>
<p><img alt="image-20250921142509379" src="../assets/image-20250921142509379.png" /></p>
<p><img alt="image-20250921144731784" src="../assets/image-20250921144731784.png" /></p>
<p><strong>GAT</strong>:</p>
<p>文章一堆相关公式</p>
<p><strong>EFF:</strong></p>
<p><img alt="image-20250921161038740" src="../assets/image-20250921161038740.png" /></p>
<p><strong>DFF:</strong></p>
<p>patch embedding</p>
<p>self attention <code>(SA)</code> [22] cross-attention <code>(CA)</code> [23]</p>
<p><img alt="image-20250921160831962" src="../assets/image-20250921160831962.png" /></p>
<p><img alt="image-20250921160838447" src="../assets/image-20250921160838447.png" /></p>
<p><strong>Cascaded Decoder:</strong></p>
<h5 id="data_8">data<a class="headerlink" href="#data_8" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250921142158045" src="../assets/image-20250921142158045.png" /></p>
<p>ISPD 2015 Contest</p>
<p><img alt="image-20250921151157723" src="../assets/image-20250921151157723.png" /></p>
<h5 id="experiment_8">experiment<a class="headerlink" href="#experiment_8" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>基于<code>DREAMPlace</code></p>
</li>
<li>
<p>还在<code>innovus</code>做了<code>routing</code></p>
</li>
<li>
<p>loss function: <code>MMD</code></p>
</li>
</ul>
<p><img alt="image-20250921161710434" src="../assets/image-20250921161710434.png" /></p>
<ul>
<li>
<p>dataset augmentation  </p>
</li>
<li>
<p>cross-validation</p>
</li>
</ul>
<p><img alt="image-20250921162747709" src="../assets/image-20250921162747709.png" /></p>
<p><img alt="image-20250921170409767" src="../assets/image-20250921170409767.png" /></p>
<p><img alt="image-20250921170418548" src="../assets/image-20250921170418548.png" /></p>
<h3 id="gate-sizing">Gate Sizing<a class="headerlink" href="#gate-sizing" title="Permanent link">&para;</a></h3>
<h4 id="-differentiable-fusion-gpgs-iccad-2024-pek-duguolin"><a href="">-Differentiable Fusion GP&amp;GS-ICCAD-2024--PEK-Du&amp;Guo&amp;Lin</a><a class="headerlink" href="#-differentiable-fusion-gpgs-iccad-2024-pek-duguolin" title="Permanent link">&para;</a></h4>
<ul>
<li>最佳论文提名</li>
</ul>
<h5 id="background_15">background<a class="headerlink" href="#background_15" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>之前是分开做的， current methodologies typically explore <code>gate sizing</code> after the <code>placement</code> or <code>routing</code> is fixed。</p>
</li>
<li>
<p>restricts the <mark>exploration space</mark> for <code>gate sizing</code>.  </p>
</li>
<li>Adjustments to gate sizes will sabotage the optimization efforts during earlier stages since the resized gates may not fit the original placement or routing layout.   </li>
<li>
<p><mark>time-consuming</mark>  </p>
</li>
<li>
<p><code>gate sizing</code> has become more challenging due to the <mark>NP-hard</mark> combinatorial optimization problem [1] for PPA trade-offs required in the large and discrete design space.  </p>
</li>
<li>
<p>Innovus and OpenROAD 都是分开做的</p>
</li>
<li>
<p>“shift-left” approach [4], suggesting that circuit constraints and performance should be considered in earlier stages of the design flow.   </p>
</li>
<li>
<p>难点：<code>gate sizing</code> is <mark>discrete</mark> in nature  </p>
</li>
<li>
<p><img alt="image-20250513222515966" src="../assets/image-20250513222515966.png" /></p>
</li>
<li>
<p><img alt="image-20250513223026186" src="../assets/image-20250513223026186.png" /></p>
</li>
<li>
<p>Previous timing-driven gate sizing methods works' category</p>
</li>
<li>
<p>Dynamic programming-based methods</p>
<ul>
<li>such as [21–23].   </li>
<li>only achieve optimal solutions for tree-structured circuit topologies and have limitations with reconvergent paths.  </li>
</ul>
</li>
<li>
<p>Sensitive-based methods.   </p>
<ul>
<li>Works like [24–26]   </li>
<li>entirely heuristic, with outcomes heavily reliant on the feasibility of the initial sensitivity knowledge  </li>
</ul>
</li>
<li>
<p>Learning-based methods.   </p>
<ul>
<li>
<p>reinforcement learningbased methods [27], generative AI-based methods [28], graph convolutional methods [29, 30], and deep learning-based methods [31]   </p>
</li>
<li>
<p>employ the prevailing learning tricks, the performance of these datadriven models may be compromised once they are applied to other cell and timing libraries. Also, a huge amount of retraining time is unbearable for current fast-paced commercial design cycles. </p>
</li>
<li>
<blockquote>
<p>感觉以后做非学习的模型都可以这么说？</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Heuristic methods improved by Lagrangian relaxation (LR)- based formulation </p>
<ul>
<li>[32–40]</li>
<li>achieved remarkable success in the past decade. By relaxing the timing constraints in the objective function and employing the Karush-KuhnTucker (KKT) optimality conditions, the search space can be greatly pruned.     </li>
<li>However, they still resort to heuristics and local search to derive a suboptimal solution, which can be <mark>slow</mark> on large designs due to the sequential nature of gate sizing adjustments.  </li>
<li>[39] introduced a learning-driven methodology that reduced the initial heuristic search space to accelerate the algorithm. [35, 37, 38] focused on enhancing the efficiency of these processes.  </li>
</ul>
</li>
</ul>
<h5 id="contribution_12">contribution<a class="headerlink" href="#contribution_12" title="Permanent link">&para;</a></h5>
<ul>
<li>the <mark>first</mark> framework that fuses the optimizations of gate positions and gate sizes with <mark>differentiable</mark> objectives</li>
<li>leverages <code>interpolation</code>, <code>gradient descent</code>, and <code>GPU-accelerated</code> computation to optimize <code>timing</code> and <code>power</code> objectives efficiently</li>
<li>making discrete gate sizes continuous </li>
</ul>
<h5 id="flow_8">flow<a class="headerlink" href="#flow_8" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250513221047598" src="../assets/image-20250513221047598.png" /></p>
<p><img alt="image-20250513231554361" src="../assets/image-20250513231554361.png" /></p>
<p><img alt="image-20250513223915400" src="../assets/image-20250513223915400.png" /></p>
<h5 id="model_9">model<a class="headerlink" href="#model_9" title="Permanent link">&para;</a></h5>
<h6 id="_6">优化任务：<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250513223757816" src="../assets/image-20250513223757816.png" /></p>
<p>minimize a design’s total <code>leakage power</code> while satisfying <code>timing</code> constraints  </p>
<ul>
<li>只有静态功耗？</li>
</ul>
<h6 id="problem-formulation">problem formulation<a class="headerlink" href="#problem-formulation" title="Permanent link">&para;</a></h6>
<p>Given a set of <code>gates</code> and an <code>initial placement layout</code>, the objective is to minimize total <mark>leakage power</mark> and the absolute values  of <mark>TNS and WNS</mark> by simultaneously determining gate positions <code>x, y</code> and gate sizes <code>s</code>.  </p>
<h6 id="key-novelty">key novelty<a class="headerlink" href="#key-novelty" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250513225118110" src="../assets/image-20250513225118110.png" /></p>
<p>加上了s</p>
<p><img alt="image-20250513225248733" src="../assets/image-20250513225248733.png" /></p>
<p><img alt="image-20250513230131079" src="../assets/image-20250513230131079.png" /></p>
<blockquote>
<p>线性的。这里感觉还有开发空间</p>
</blockquote>
<h6 id="differentiable-leakage-power">Differentiable Leakage Power<a class="headerlink" href="#differentiable-leakage-power" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250513225550438" src="../assets/image-20250513225550438.png" /></p>
<p><img alt="image-20250513225612522" src="../assets/image-20250513225612522.png" /></p>
<p><img alt="image-20250513225648916" src="../assets/image-20250513225648916.png" /></p>
<p><img alt="image-20250513225716542" src="../assets/image-20250513225716542.png" /></p>
<h6 id="differentiable-timing-objectives">Differentiable Timing Objectives<a class="headerlink" href="#differentiable-timing-objectives" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250513230732591" src="../assets/image-20250513230732591.png" /></p>
<p><img alt="image-20250513230759639" src="../assets/image-20250513230759639.png" /></p>
<p><img alt="image-20250513231256182" src="../assets/image-20250513231256182.png" /></p>
<p><img alt="image-20250513231306297" src="../assets/image-20250513231306297.png" /></p>
<p><img alt="image-20250513231314133" src="../assets/image-20250513231314133.png" /></p>
<p><img alt="image-20250513231324197" src="../assets/image-20250513231324197.png" /></p>
<p><img alt="image-20250513231344760" src="../assets/image-20250513231344760.png" /></p>
<p><img alt="image-20250513231356433" src="../assets/image-20250513231356433.png" /></p>
<h5 id="dataset">dataset<a class="headerlink" href="#dataset" title="Permanent link">&para;</a></h5>
<p>CircuitNet-N28  </p>
<p><img alt="image-20250513231954761" src="../assets/image-20250513231954761.png" /></p>
<h5 id="experiment_9">experiment<a class="headerlink" href="#experiment_9" title="Permanent link">&para;</a></h5>
<p>compare our newly developed flow with the open-source OpenROAD [3] flow  </p>
<p><img alt="image-20250513232210271" src="../assets/image-20250513232210271.png" /></p>
<p><img alt="image-20250513232246097" src="../assets/image-20250513232246097.png" /></p>
<p><img alt="image-20250513232257249" src="../assets/image-20250513232257249.png" /></p>
<h4 id="-gate-sizing-differentiable-iseda-2025-pek"><a href="">-Gate Sizing Differentiable-ISEDA-2025--PEK</a><a class="headerlink" href="#-gate-sizing-differentiable-iseda-2025-pek" title="Permanent link">&para;</a></h4>
<ul>
<li>2024 ICCAD CAD gate sizing contest  </li>
</ul>
<h5 id="background_16">background<a class="headerlink" href="#background_16" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p><code>continuity</code> and <code>expressivity</code> limitations  </p>
</li>
<li>
<p>continuity: as almost all core VLSI tasks—such as logic optimization, placement, and routing—require discrete solutions that conflict with the continuous nature of differentiable frameworks.  无法梯度下降</p>
</li>
<li></li>
<li>
<p>Prior research on gate sizing generally falls into the following categories:</p>
</li>
<li>
<p>Dynamic programming-based methods  </p>
<ul>
<li>[19]–[21]  </li>
<li>falter with general circuits containing reconvergent paths.  </li>
</ul>
</li>
<li>
<p>Sensitivity-based method  </p>
<ul>
<li>[22]–[24]  </li>
<li>based on initial sensitivity estimates</li>
<li>relies heavily on the quality of heuristics</li>
</ul>
</li>
<li>
<p>Learning-based methods  </p>
<ul>
<li>including RL [25], generative AI [26], and GCN [27]</li>
<li>incur time-consuming retraining when transferred to different technology libraries</li>
</ul>
</li>
<li>
<p>Heuristic methods with Lagrangian relaxation (LR)   </p>
<ul>
<li>[30]–[38]</li>
<li>reduce the search space using KKT conditions but often rely on slow, local searches and gate-by-gate iterations.</li>
</ul>
</li>
<li>
<p>differentiable methods [5]–[7]   </p>
<ul>
<li>their discrete size of gates mismatches with continuous gradient descent method  </li>
<li>only guarantee their optimization efforts in their own analyzing model outcomes  </li>
</ul>
</li>
</ul>
<h5 id="contribution_13">contribution<a class="headerlink" href="#contribution_13" title="Permanent link">&para;</a></h5>
<ul>
<li>a  <code>gradient clipping strategy</code> to tackle the <code>continuity limitation</code>  </li>
<li>a  <code>gradient calibration framework</code> to address the <code>expressivity limitation</code>  </li>
</ul>
<h5 id="flow_9">flow<a class="headerlink" href="#flow_9" title="Permanent link">&para;</a></h5>
<h6 id="problem-fomulation">problem fomulation<a class="headerlink" href="#problem-fomulation" title="Permanent link">&para;</a></h6>
<ul>
<li>a set of gates and detailed placement layout  </li>
<li>determine the size <code>s</code> of all gates in order to minimize total leakage power while eliminating DRVs and timing violations.   </li>
</ul>
<p><img alt="image-20250616152107048" src="../assets/image-20250616152107048.png" /></p>
<h5 id="model_10">model<a class="headerlink" href="#model_10" title="Permanent link">&para;</a></h5>
<h6 id="_7">优化目标：<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250514152212165" src="../assets/image-20250514152212165.png" /></p>
<h6 id="quality-score">quality score<a class="headerlink" href="#quality-score" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250616153226846" src="../assets/image-20250616153226846.png" /></p>
<h6 id="linear-interpolation">Linear interpolation<a class="headerlink" href="#linear-interpolation" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250617010201785" src="../assets/image-20250617010201785.png" /></p>
<blockquote>
<p>线性的。这里感觉还有开发空间</p>
</blockquote>
<h6 id="differentiable-power-and-area-objectives">Differentiable Power and Area Objectives<a class="headerlink" href="#differentiable-power-and-area-objectives" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250617010152468" src="../assets/image-20250617010152468.png" /></p>
<h6 id="differentiable-drv-and-timing-objectives">Differentiable DRV and Timing Objectives<a class="headerlink" href="#differentiable-drv-and-timing-objectives" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250617005926996" src="../assets/image-20250617005926996.png" /></p>
<h5 id="continuity-limitation">continuity limitation<a class="headerlink" href="#continuity-limitation" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250514152910399" src="../assets/image-20250514152910399.png" /></p>
<p>With a deeper circuit logic level, this inaccuracy would be amplified  </p>
<p><code>Gradient Clipping Solution</code>  </p>
<p>一个更直观的例子：如果全部gatesize都是四舍，那一定会有很大误差</p>
<ol>
<li>initially, all gate sizes are set to minimal. </li>
<li>In each iteration, we upsize the top k~1~% gates with the smallest gradients, as these gates will <mark>most likely benefit</mark> from adjustments；</li>
<li>Conversely, to mitigate unnecessary area and power consumption, our algorithm also downsizes the top k~2~% gates with the largest gradients, which are supposed to be oversized gates.   这是什么原理？</li>
</ol>
<blockquote>
<p>启发式人工超参数又出现了</p>
</blockquote>
<h6 id="expressivity-limitation">expressivity limitation<a class="headerlink" href="#expressivity-limitation" title="Permanent link">&para;</a></h6>
<p>gradient calibration  </p>
<p><img alt="image-20250514154700314" src="../assets/image-20250514154700314.png" /></p>
<blockquote>
<p>可以用到类似的其他工作中</p>
</blockquote>
<p>在第一次迭代的时候使用Reference Timer进行对齐一次，计算一个Calibrate比例参数。通过相乘而不是以前工作的相加，让参数传递，最后对齐商业工具，而不是简单的数学模型</p>
<blockquote>
<p>但是迭代越久会越不准？</p>
</blockquote>
<h6 id="data_9">data<a class="headerlink" href="#data_9" title="Permanent link">&para;</a></h6>
<p>2024 ICCAD CAD gate sizing contest  </p>
<p>post-placement 之后的数据</p>
<p><img alt="image-20250617101524760" src="../assets/image-20250617101524760.png" /></p>
<p>基于以上数据，进行detail placement 和global routing （使用OpenROAD）</p>
<h5 id="experiment_10">experiment<a class="headerlink" href="#experiment_10" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250514155419262" src="../assets/image-20250514155419262.png" /></p>
<p><img alt="image-20250617105745469" src="../assets/image-20250617105745469.png" /></p>
<p>在大规模电路上效果更好：For the first three cases, their smaller scale increases the variability in gate sizing optimization results, thus making it difficult to achieve consistently optimal outcomes  </p>
<h3 id="gr">GR<a class="headerlink" href="#gr" title="Permanent link">&para;</a></h3>
<h4 id="pros-routability-optimizatio">[PROS-Routability Optimizatio<a class="headerlink" href="#pros-routability-optimizatio" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241128091405687" src="../assets/image-20241128091405687.png" /></p>
<p><img alt="image-20241128091759855" src="../assets/image-20241128091759855.png" /></p>
<h5 id="task_8">task<a class="headerlink" href="#task_8" title="Permanent link">&para;</a></h5>
<ul>
<li>congestion <strong>predictor</strong> and parameter <strong>optimizer</strong></li>
<li>only the data from the placement  </li>
<li>it can optimize the cost parameters before the first routing iteration of GR and thus can give a better GR solution with less congestion.  </li>
</ul>
<h5 id="contribution_14">contribution<a class="headerlink" href="#contribution_14" title="Permanent link">&para;</a></h5>
<ul>
<li>with negligible runtime overhead  </li>
<li>plug-in</li>
<li>can be embedded into the state-of-the-art commercial EDA tool (Cadence Innovus v20.1)   </li>
</ul>
<h5 id="model_11">model<a class="headerlink" href="#model_11" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241219171627049" src="../assets/image-20241219171627049.png" /></p>
<h5 id="data_10">data<a class="headerlink" href="#data_10" title="Permanent link">&para;</a></h5>
<p>19 different industrial designs  </p>
<p><img alt="image-20241219165446998" src="../assets/image-20241219165446998.png" /></p>
<p>通过 <strong>不同的 placement 参数和旋转</strong>（CNN 原理），一共有 1664 design cases in total.  </p>
<p><strong>Feature Extraction</strong>  </p>
<ul>
<li>
<p>Horizontal/Vertical track capacity map  </p>
</li>
<li>
<p>Cell density map</p>
</li>
<li>
<p>Flip-flop cell density map  </p>
</li>
<li>
<p>Fixed cell density map  </p>
</li>
<li>
<p>Cell pin density map  </p>
</li>
<li>
<p>Pin accessibility map  </p>
</li>
</ul>
<p><img alt="image-20241219161307835" src="../assets/image-20241219161307835.png" /></p>
<ul>
<li>
<p>Horizontal/Vertical net density map  </p>
</li>
<li>
<p>Small/Large-net RUDY map  </p>
</li>
</ul>
<p><img alt="image-20241219161336920" src="../assets/image-20241219161336920.png" /></p>
<ul>
<li>Pin RUDY map</li>
</ul>
<p>a combination of cell pin density map and large-net RUDY
  map  </p>
<p><strong>Label Generation</strong>  </p>
<p><img alt="image-20241219162403381" src="../assets/image-20241219162403381.png" /> PROS does not need very detailed congestion map   </p>
<p>two-step smoothening process to convert raw data to desirable congestion labels  </p>
<p>help to make the prediction task easier  </p>
<p>if there are at least six congested G-cells out of the eight in the surrounding of a center G-cell д, д will be labeled as congested  </p>
<p><img alt="image-20241219162837909" src="../assets/image-20241219162837909.png" /></p>
<p><strong>优化原理</strong></p>
<p>这两个值在 cadence 怎么改的? cadence 企业内部自己弄的（这是 cadence 的文章）？</p>
<p><img alt="image-20241219165904742" src="../assets/image-20241219165904742.png" /></p>
<p><img alt="image-20241219165912121" src="../assets/image-20241219165912121.png" /></p>
<h5 id="model_12">model<a class="headerlink" href="#model_12" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241219163417043" src="../assets/image-20241219163417043.png" /></p>
<h5 id="experiment_11">experiment<a class="headerlink" href="#experiment_11" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241219172158774" src="../assets/image-20241219172158774.png" /></p>
<p><img alt="image-20241219172205431" src="../assets/image-20241219172205431.png" /></p>
<p><img alt="image-20241219172212018" src="../assets/image-20241219172212018.png" /></p>
<p><img alt="image-20241219172620444" src="../assets/image-20241219172620444.png" /></p>
<h4 id="pros-20-routability-optroute-wl-estimation-trans-2023-cnn-cnhkcadence"><a href="">PROS 2.0 - Routability Opt+Route WL estimation-Trans-2023-CNN-CNHK+Cadence</a><a class="headerlink" href="#pros-20-routability-optroute-wl-estimation-trans-2023-cnn-cnhkcadence" title="Permanent link">&para;</a></h4>
<h5 id="background_17">background<a class="headerlink" href="#background_17" title="Permanent link">&para;</a></h5>
<ul>
<li>the amount of routing resources on a design is limited.   </li>
<li>The quality of a GR solution has a great impact on that of the resulted DR routing solution  </li>
<li>Congestion in a GR solution is one of the major causes of DRC violations in the DR
  solution since most of DRC violations are due to overcrowded wires and vias [1], [2]  </li>
<li>a better GR solution with less congestion is needed to lower the probability of getting DRC violations in advance. </li>
<li>if the initial GR solution is not good and has a lot of congestion, the GR tool can hardly tackle the problem by rip-up and reroute.  </li>
<li>placement engines <strong>[3]–[5]</strong> which take routing congestion into consideration are applied  </li>
<li>FCN: FCN 常用于图像中的每像素分类问题。采用 <strong>任意输入大小</strong>，并产生大小完全相同的输出。GR 拥塞预测也可以被视为任意大小的芯片设计上的像素二进制分类问题（拥塞与否）。因此，基于 FCN 的预测器可以自然地应用于 PROS。</li>
</ul>
<h5 id="task_9">task<a class="headerlink" href="#task_9" title="Permanent link">&para;</a></h5>
<ul>
<li>stage: post-placement, pre-route</li>
<li>FCN based GR congestion <code>predictor</code>, use the predicted GR congestion to optimize the <strong>cost parameters</strong> of GR. </li>
<li>predictor based <code>parameter optimizer</code> to generate a better GR solution. GR tools are driven by the cost parameters stored in each G-cell. When arriving at a G-cell g, the tool will compute the cost, called <code>moving cost</code>, to move to each of its neighboring G-cells and push these costs into a heap. With optimized cost parameters in G-cells, the GR tool can find better paths and allocate the routing resources to each net more smartly. PROS optimizes two types of cost parameters <strong>based on the prediction result</strong>, including <code>overflow cost</code> and <code>wire/via cost</code>.  PROS will adjust the cost parameters in the projected congestion regions on <strong>all layers</strong>  </li>
<li>overflow cost</li>
<li>wire/via cost: divided into two groups (small/large) according to their BBox sizes. <ul>
<li>Increasing the wire/via cost for small nets may be <strong>useless</strong> for congestion reduction and it may even increase the wire length or create new congestion due to detours out of the potential congestion region.  </li>
<li>In contrast, increasing the wire/via cost for large nets can be helpful since
  they can select another route within its BBox to completely avoid the potential congestion region</li>
</ul>
</li>
<li>CNN based  <code>wirelength estimator</code>,  By <strong>multiplying</strong> the predicted wirelength ratio and the precomputed <code>FLUTE</code> wirelength  (训练一个系数). The lack of consideration of routing congestion in traditional methods is due to the dif ficulty of quickly obtaining accurate congestion estimation at the placement <strong>stage</strong></li>
</ul>
<h5 id="contribution_15">contribution<a class="headerlink" href="#contribution_15" title="Permanent link">&para;</a></h5>
<ul>
<li>plug-in for Innovus:  it can avoid extra runtime overhead of feature preparation  </li>
<li>industrial design suite   </li>
<li>advanced technology node  </li>
<li>SOTA</li>
<li>high accuracy</li>
<li>first work that </li>
<li>utilizes the information of GR congestion to estimate routed wirelength at the placement stage  </li>
<li>PROS does not change a lot for the original EDA steps  </li>
</ul>
<p><strong>Overall Flow</strong> :</p>
<p><img alt="image-20241225231457615" src="../assets/image-20241225231457615.png" /></p>
<p><img alt="image-20241225231740032" src="../assets/image-20241225231740032.png" /></p>
<p>分类和回归</p>
<p><img alt="image-20241225231939553" src="../assets/image-20241225231939553.png" /></p>
<ul>
<li>F is the feature number.  </li>
<li>X~WL~ has two features:  These two features will be resized to 128 × 128 before prediction  </li>
<li>the <strong>predicted</strong> congestion map </li>
<li>the cell pin density map   </li>
</ul>
<h5 id="data_11">data<a class="headerlink" href="#data_11" title="Permanent link">&para;</a></h5>
<p>feature F </p>
<ul>
<li>
<p>Horizontal/Vertical Track Capacity Map  </p>
</li>
<li>
<p>Cell Density Map  </p>
</li>
<li>
<p>Flip-Flop Cell Density Map</p>
</li>
<li>
<p>Fixed Cell Density Map  </p>
</li>
<li>
<p>Cell Pin Density Map  </p>
</li>
<li>
<p>Pin Accessibility Map  </p>
</li>
</ul>
<p><img alt="image-20241226095003879" src="../assets/image-20241226095003879.png" /></p>
<ul>
<li>Horizontal/Vertical Net Density Map</li>
</ul>
<p><img alt="image-20241226095234394" src="../assets/image-20241226095234394.png" /></p>
<ul>
<li>Small/Large-Net RUDY Map  </li>
</ul>
<p><img alt="image-20241226095702886" src="../assets/image-20241226095702886.png" /></p>
<ul>
<li>Pin RUDY Map ?</li>
</ul>
<p><strong>label</strong></p>
<p><strong>congestion label  pre-process</strong></p>
<p>PROS does not need a very detailed congestion map</p>
<p><img alt="image-20241226100513980" src="../assets/image-20241226100513980.png" /></p>
<p>最后还是为了优化服务的</p>
<h5 id="model_13">model<a class="headerlink" href="#model_13" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241226133238155" src="../assets/image-20241226133238155.png" /></p>
<ul>
<li>DC: get more local information, but more GPU usage(acceptable)</li>
<li>SUB: w*h*4c –&gt; 2w*2h*c.</li>
<li>Compared with bilinear upsampling which is not trainable, subpixel upsampling can learn to recover the local information.</li>
<li>Compared with deconvolution, subpixel upsampling is parameter free, so
    it will not significantly increase the training difficulty.  </li>
</ul>
<p><img alt="image-20241226133719030" src="../assets/image-20241226133719030.png" /></p>
<p><strong>dataset</strong></p>
<p>industrial benchmark suite and  DAC-2012  benchmark suite(19 个 benchmark)</p>
<p>industrial benchmark suite 通过 11 种不同布局参数，翻转和旋转，制造了一共有 1664 个(约等于 19*11*8)benchmark</p>
<p>DAC-2012 20 different placements  </p>
<p>(4, 4, 4, 4, 3)  5 折交叉验证</p>
<p><img alt="image-20241226134314062" src="../assets/image-20241226134314062.png" /></p>
<p><img alt="image-20241226134322968" src="../assets/image-20241226134322968.png" /></p>
<h5 id="experiment_12">experiment<a class="headerlink" href="#experiment_12" title="Permanent link">&para;</a></h5>
<p><strong>env</strong></p>
<ul>
<li>Tensorflow  </li>
<li>Intel Xeon CPUs at 2.2 GHz  </li>
<li>256 GB memory  </li>
<li>NVIDIA TITAN V GPU  </li>
</ul>
<p><strong>setting</strong></p>
<ul>
<li>
<p>Adam</p>
</li>
<li>
<p>One entire training process of the congestion predictor has 25 training epochs! 这么少（收敛好快）  </p>
</li>
</ul>
<p><img alt="image-20241226135108986" src="../assets/image-20241226135108986.png" /></p>
<p><strong>congestion classification prediction</strong></p>
<p><img alt="image-20241226135344696" src="../assets/image-20241226135344696.png" /></p>
<p><img alt="image-20241226135500109" src="../assets/image-20241226135500109.png" /></p>
<p>compare with PROBABILISTIC METHODS  </p>
<p><img alt="image-20241226135607227" src="../assets/image-20241226135607227.png" /></p>
<p><img alt="image-20241226135730697" src="../assets/image-20241226135730697.png" /></p>
<p><img alt="image-20241226135756327" src="../assets/image-20241226135756327.png" /></p>
<p><strong>DR 优化结果</strong></p>
<p><img alt="image-20241226140031433" src="../assets/image-20241226140031433.png" /></p>
<p><strong>线长估计</strong></p>
<p><img alt="image-20241226140057750" src="../assets/image-20241226140057750.png" /></p>
<p><img alt="image-20241226142425570" src="../assets/image-20241226142425570.png" /></p>
<p><img alt="image-20241226142433618" src="../assets/image-20241226142433618.png" /></p>
<p><strong>Runtime</strong></p>
<p><img alt="image-20241226142533340" src="../assets/image-20241226142533340.png" /></p>
<p><img alt="image-20241226142539173" src="../assets/image-20241226142539173.png" /></p>
<h4 id="dr">DR<a class="headerlink" href="#dr" title="Permanent link">&para;</a></h4>
<h4 id="-detailed-router-date-2021-rl"><a href="https://ieeexplore.ieee.org/document/9474007">-Detailed Router-DATE-2021-RL</a><a class="headerlink" href="#-detailed-router-date-2021-rl" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241012161419196" src="../assets/image-20241012161419196.png" /></p>
<h4 id="dprouter-detail-routingpackage-design-optnet-order-decision-aspadc-2023-rlmarl-diagonally-route"><a href="" title="D:\MyNotes\EDA\Routing\DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route.pdf">DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route</a><a class="headerlink" href="#dprouter-detail-routingpackage-design-optnet-order-decision-aspadc-2023-rlmarl-diagonally-route" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241027101634534" src="../assets/image-20241027101634534.png" /></p>
<ul>
<li>
<p>BackGround</p>
</li>
<li>
<p>most time-consuming stages in the <strong>package design</strong> flow  </p>
</li>
<li>
<p>package designs have fewer layers; thus, we need to prevent net crashing cautiously  </p>
</li>
<li>
<p>contrbution:</p>
</li>
<li>
<p>redefine the routing area and shrink the routing problem by dividing the entire design into <strong>non-overlapping boxes</strong>  </p>
</li>
<li>use DRL, not heuristic</li>
<li>
<p>prove the number of design rule violations (DRVs), wirelength and layout pattern.  </p>
</li>
<li>
<p>task</p>
</li>
<li>
<p>2-pin nets  </p>
</li>
</ul>
<p><img alt="image-20241027104527603" src="../assets/image-20241027104527603.png" /></p>
<p>Initial routing: ignores the number of bends and allows design rule violations  </p>
<p><img alt="image-20241027104906544" src="../assets/image-20241027104906544.png" /></p>
<ul>
<li>Model</li>
</ul>
<p>multi-agent deep reinforcement learning (<strong>MARL</strong>) task [15] for <strong>asynchronous</strong> routing planning between nets. We regard each net as an agent, which needs to consider the actions of other agents while making pathing decisions to avoid routing conflict  </p>
<p><img alt="image-20241027104558097" src="../assets/image-20241027104558097.png" /></p>
<p><img alt="image-20241027105909572" src="../assets/image-20241027105909572.png" /></p>
<p>route and slide the window repeatedly. advantage of box: process every box independently  </p>
<ul>
<li>
<p>sequential routing  </p>
<p><img alt="image-20241027134657161" src="../assets/image-20241027134657161.png" /></p>
<p><img alt="image-20241027133917659" src="../assets/image-20241027133917659.png" /></p>
<p><img alt="image-20241027133231542" src="../assets/image-20241027133231542.png" /></p>
<p><img alt="image-20241027133826865" src="../assets/image-20241027133826865.png" /></p>
<p>the repulsion point will be moved from the inner ring to the outer one until the box is successfully routed.   </p>
<p>具体算法：</p>
<p><img alt="image-20241027141238708" src="../assets/image-20241027141238708.png" /></p>
</li>
<li>
<p>sequential routing  </p>
<p><img alt="image-20241027142631796" src="../assets/image-20241027142631796.png" /></p>
<ul>
<li><img alt="image-20241027143243104" src="../assets/image-20241027143243104.png" /></li>
<li><img alt="image-20241027144931328" src="../assets/image-20241027144931328.png" /></li>
</ul>
</li>
<li>
<p>Refinement</p>
<p><img alt="image-20241027144108460" src="../assets/image-20241027144108460.png" /></p>
</li>
</ul>
<h4 id="-detail-routingmatchopt-ispd-2023-rlgnn-finfet"><a href="">-Detail routing+match+Opt-ISPD-2023-RL+GNN-FinFET </a><a class="headerlink" href="#-detail-routingmatchopt-ispd-2023-rlgnn-finfet" title="Permanent link">&para;</a></h4>
<h5 id="background_18">background:<a class="headerlink" href="#background_18" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>cutom circuits: a custom detailed router cannot adopt specialized layout strategies for specific circuit classes like human layout experts  </p>
</li>
<li>
<p><img alt="image-20241028221540078" src="../assets/image-20241028221540078.png" /></p>
</li>
<li>
<p><img alt="image-20241028224206180" src="../assets/image-20241028224206180.png" /></p>
</li>
<li>
<p><img alt="image-20241028222447134" src="../assets/image-20241028222447134.png" /></p>
</li>
<li>
<p>一直在强调 match 的问题：</p>
</li>
</ul>
<p><img alt="image-20241028224639124" src="../assets/image-20241028224639124.png" /></p>
<h5 id="contribution_16">contribution<a class="headerlink" href="#contribution_16" title="Permanent link">&para;</a></h5>
<ul>
<li>opt roouting, FinFET, sign-off solution</li>
<li>异构图</li>
<li>A rip-up and re-routing scheme  </li>
<li>can easily adapt to future design constraints  </li>
</ul>
<p><strong>three categories  of routing methodologies</strong>  </p>
<ol>
<li>Template-based methods </li>
<li>manual design  </li>
<li>suffers from scalability issues   </li>
<li>Simulation-based techniques  </li>
<li>provide accurate performance feedback and can be generalized to consider various performance metrics (e.g., phase
     margin, power dissipation) across circuit classes  </li>
<li>long execution time and resource-hungry computations  </li>
<li>Constraint-based approaches  </li>
<li>widely adopted in existing custom routing studies  </li>
</ol>
<h2 id="pr-tools">PR Tools<a class="headerlink" href="#pr-tools" title="Permanent link">&para;</a></h2>
<h3 id="gp_trad">GP_Trad<a class="headerlink" href="#gp_trad" title="Permanent link">&para;</a></h3>
<h4 id="ntuplace4h-tcad-2014-"><a href="">NTUplace4h- -TCAD-2014-</a><a class="headerlink" href="#ntuplace4h-tcad-2014-" title="Permanent link">&para;</a></h4>
<h4 id="eplace-todaes-2015-"><a href="">ePlace- -TODAES-2015- </a><a class="headerlink" href="#eplace-todaes-2015-" title="Permanent link">&para;</a></h4>
<h4 id="replace-tcad-2018-"><a href="">Replace- -TCAD-2018-</a><a class="headerlink" href="#replace-tcad-2018-" title="Permanent link">&para;</a></h4>
<h4 id="generalized-augmented-lagrangian-and-its-applications-to-vlsi-global-placement">Generalized augmented lagrangian and its applications to vlsi global placement<a class="headerlink" href="#generalized-augmented-lagrangian-and-its-applications-to-vlsi-global-placement" title="Permanent link">&para;</a></h4>
<h4 id="chip-placement-with-deep-reinforcement-learning-marcro-arxiv-2020-rl"><a href="https://arxiv.org/pdf/2004.10746">Chip Placement with Deep Reinforcement Learning-marcro-arXiv-2020-RL</a><a class="headerlink" href="#chip-placement-with-deep-reinforcement-learning-marcro-arxiv-2020-rl" title="Permanent link">&para;</a></h4>
<ul>
<li>first explores the application of artificial intelligence in solving placement with the attempt to ease the difficulties of manual effort, which may indicate a new development stage for physical design  </li>
</ul>
<h4 id="differentiable-timing-driven-global-placement-global-placement-dac-2022-gnn-"><a href="https://dl.acm.org/doi/pdf/10.1145/3489517.3530486">Differentiable-Timing-Driven Global Placement-global placement-DAC-2022-GNN-</a><a class="headerlink" href="#differentiable-timing-driven-global-placement-global-placement-dac-2022-gnn-" title="Permanent link">&para;</a></h4>
<h4 id="polar-20"><a href="https://ieeexplore.ieee.org/document/6881450">Polar 2.0</a><a class="headerlink" href="#polar-20" title="Permanent link">&para;</a></h4>
<p>An effective <strong>routability-driven</strong> placer</p>
<p>cells that are estimated to have high congestion are spread out and inflated to distribute routing demand more evenly.  </p>
<h4 id="ntuplace3">NTUPlace3<a class="headerlink" href="#ntuplace3" title="Permanent link">&para;</a></h4>
<h4 id="deepplace"><a href="https://github.com/PKUterran/DeepPlace">DeepPlace</a><a class="headerlink" href="#deepplace" title="Permanent link">&para;</a></h4>
<h5 id="flow_10">flow<a class="headerlink" href="#flow_10" title="Permanent link">&para;</a></h5>
<h4 id="replace-tcad-2018-_1"><a href="https://ieeexplore.ieee.org/abstract/document/8418790">RePlAce--TCAD-2018-</a><a class="headerlink" href="#replace-tcad-2018-_1" title="Permanent link">&para;</a></h4>
<h3 id="gp_adv">GP_Adv<a class="headerlink" href="#gp_adv" title="Permanent link">&para;</a></h3>
<h4 id="dreamplace-gpu-accelerate-dactcadiccaddate-20192023"><a href="https://github.com/limbo018/DREAMPlace">DREAMPlace-GPU Accelerate-DAC+TCAD+ICCAD+DATE-2019~2023</a><a class="headerlink" href="#dreamplace-gpu-accelerate-dactcadiccaddate-20192023" title="Permanent link">&para;</a></h4>
<h5 id="background_19">background<a class="headerlink" href="#background_19" title="Permanent link">&para;</a></h5>
<ul>
<li>open up new directions for  GP</li>
<li>current placement usually takes hours for large designs  </li>
<li>Although <code>analytical placement</code> can produce high-quality solutions, it is also known to be relatively slow  </li>
</ul>
<h5 id="contribution_17">contribution<a class="headerlink" href="#contribution_17" title="Permanent link">&para;</a></h5>
<ul>
<li>a totally new perspective of making analogy between placement and deep learning</li>
<li>Over <code>30X</code> speedup over the CPU implementation (<a href="https://doi.org/10.1109/TCAD.2018.2859220">RePlAce</a>) is achieved in global placement and legalization on ISPD 2005 contest benchmarks</li>
<li>DREAMPlace runs on both CPU and GPU. If it is installed on a machine without GPU, only CPU support will be enabled with multi-threading.</li>
<li>DREAMPlace also integrates a GPU-accelerated detailed placer, <code>ABCDPlace</code>, which can achieve around <code>16X</code> speedup on million-size benchmarks over the widely-adopted sequential placer <a href="https://doi.org/10.1109/TCAD.2008.923063">NTUPlace3</a> on CPU.</li>
</ul>
<p><strong>Publications</strong></p>
<ul>
<li><a href="http://yibolin.com/">Yibo Lin</a>, Shounak Dhar, <a href="http://wuxili.net/">Wuxi Li</a>, Haoxing Ren, Brucek Khailany and <a href="http://users.ece.utexas.edu/~dpan">David Z. Pan</a>, "<strong>DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement</strong>", ACM/IEEE Design Automation Conference (DAC), Las Vegas, NV, Jun 2-6, 2019 (<a href="http://yibolin.com/publications/papers/PLACE_DAC2019_Lin.pdf">preprint</a>) (<a href="http://yibolin.com/publications/papers/PLACE_DAC2019_Lin.slides.pptx">slides</a>)</li>
<li><a href="http://yibolin.com/">Yibo Lin</a>, Zixuan Jiang, <a href="https://jeremiemelo.github.io/">Jiaqi Gu</a>, <a href="http://wuxili.net/">Wuxi Li</a>, Shounak Dhar, Haoxing Ren, Brucek Khailany and <a href="http://users.ece.utexas.edu/~dpan">David Z. Pan</a>, "<strong>DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement</strong>", IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020</li>
<li><a href="http://yibolin.com/">Yibo Lin</a>, <a href="http://wuxili.net/">Wuxi Li</a>, <a href="https://jeremiemelo.github.io/">Jiaqi Gu</a>, Haoxing Ren, Brucek Khailany and <a href="http://users.ece.utexas.edu/~dpan">David Z. Pan</a>, "<strong>ABCDPlace: Accelerated Batch-based Concurrent Detailed Placement on Multi-threaded CPUs and GPUs</strong>", IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 (<a href="http://yibolin.com/publications/papers/ABCDPLACE_TCAD2020_Lin.pdf">preprint</a>)</li>
<li><a href="http://yibolin.com/">Yibo Lin</a>, <a href="http://users.ece.utexas.edu/~dpan">David Z. Pan</a>, Haoxing Ren and Brucek Khailany, "<strong>DREAMPlace 2.0: Open-Source GPU-Accelerated Global and Detailed Placement for Large-Scale VLSI Designs</strong>", China Semiconductor Technology International Conference (CSTIC), Shanghai, China, Jun, 2020 (<a href="http://yibolin.com/publications/papers/PLACE_CSTIC2020_Lin.pdf">preprint</a>)(Invited Paper)</li>
<li><a href="https://jeremiemelo.github.io/">Jiaqi Gu</a>, Zixuan Jiang, <a href="http://yibolin.com/">Yibo Lin</a> and <a href="http://users.ece.utexas.edu/~dpan">David Z. Pan</a>, "<strong>DREAMPlace 3.0: Multi-Electrostatics Based Robust VLSI Placement with Region Constraints</strong>", IEEE/ACM International Conference on Computer-Aided Design (ICCAD), Nov 2-5, 2020 (<a href="http://yibolin.com/publications/papers/PLACE_ICCAD2020_Gu.pdf">preprint</a>)</li>
<li><a href="https://enzoleo.github.io/">Peiyu Liao</a>, <a href="https://lusica1031.github.io/">Siting Liu</a>, Zhitang Chen, Wenlong Lv, <a href="http://yibolin.com/">Yibo Lin</a> and <a href="https://www.cse.cuhk.edu.hk/~byu/">Bei Yu</a>, "<strong>DREAMPlace 4.0: Timing-driven Global Placement with Momentum-based Net Weighting</strong>", IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), Antwerp, Belgium, Mar 14-23, 2022 (<a href="https://yibolin.com/publications/papers/PLACE_DATE2022_Liao.pdf">preprint</a>)</li>
<li>Yifan Chen, <a href="http://faculty.bicmr.pku.edu.cn/~wenzw/">Zaiwen Wen</a>, <a href="https://ericlyun.github.io/">Yun Liang</a>, <a href="http://yibolin.com/">Yibo Lin</a>, "<strong>Stronger Mixed-Size Placement Backbone Considering Second-Order Information</strong>", IEEE/ACM International Conference on Computer-Aided Design (ICCAD), San Francisco, CA, Oct, 2023 (<a href="https://yibolin.com/publications/papers/PLACE_ICCAD2023_Chen.pdf">preprint</a>)</li>
</ul>
<p><strong>Architecture</strong></p>
<p><img alt="image-20241211185233352" src="../assets/image-20241211185233352.png" /></p>
<p><img alt="image-20241211185244415" src="../assets/image-20241211185244415.png" /></p>
<h5 id="flow_11">flow<a class="headerlink" href="#flow_11" title="Permanent link">&para;</a></h5>
<ul>
<li></li>
</ul>
<h5 id="model_14">model<a class="headerlink" href="#model_14" title="Permanent link">&para;</a></h5>
<ul>
<li>优化目标</li>
</ul>
<p><img alt="image-20250323101317234" src="../assets/image-20250323101317234.png" /></p>
<p><img alt="image-20250323101815867" src="../assets/image-20250323101815867.png" /></p>
<ul>
<li></li>
</ul>
<h3 id="gr_tradictional_sequential">GR_Tradictional_sequential<a class="headerlink" href="#gr_tradictional_sequential" title="Permanent link">&para;</a></h3>
<h4 id="fastroute102006"><a href="">FastRoute1.0—2006</a><a class="headerlink" href="#fastroute102006" title="Permanent link">&para;</a></h4>
<ul>
<li>roposed a simple way to construct <strong>congestion driven Steiner tree</strong> and an edge shifting technique to further refine it  </li>
</ul>
<h4 id="fastroute-20-monotonic2007"><a href="">fastroute 2.0-Monotonic–2007</a><a class="headerlink" href="#fastroute-20-monotonic2007" title="Permanent link">&para;</a></h4>
<ul>
<li>monotonic routing to explore all shortest routing paths for two-pin connections.   </li>
</ul>
<h5 id="task_10">task<a class="headerlink" href="#task_10" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241114191327215" src="../assets/image-20241114191327215.png" /></p>
<h5 id="flow_12">flow<a class="headerlink" href="#flow_12" title="Permanent link">&para;</a></h5>
<p><strong><img alt="image-20241114205659503" src="../assets/image-20241114205659503.png" /></strong></p>
<p><img alt="image-20241115160208134" src="../assets/image-20241115160208134.png" /></p>
<h4 id="fastroute-30-virtual-capacity-iccad-2008-"><a href="">fastroute 3.0-virtual capacity-ICCAD-2008-</a><a class="headerlink" href="#fastroute-30-virtual-capacity-iccad-2008-" title="Permanent link">&para;</a></h4>
<h4 id="fastroute-40-via-min-tree3-bending-aspdac-2009-"><a href="">fastroute 4.0-via min tree+3 bending-ASPDAC-2009-</a><a class="headerlink" href="#fastroute-40-via-min-tree3-bending-aspdac-2009-" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241116121010565" src="../assets/image-20241116121010565.png" /></p>
<p><img alt="image-20241115160433890" src="../assets/image-20241115160433890.png" /></p>
<p><img alt="image-20241115160445784" src="../assets/image-20241115160445784.png" /></p>
<p><img alt="image-20241116105606149" src="../assets/image-20241116105606149.png" /></p>
<p><img alt="image-20241116121317660" src="../assets/image-20241116121317660.png" /></p>
<p><img alt="image-20241116121311506" src="../assets/image-20241116121311506.png" /></p>
<p><strong>层分配</strong></p>
<p><img alt="image-20241116124343911" src="../assets/image-20241116124343911.png" /></p>
<p>?</p>
<p><img alt="image-20241116125839541" src="../assets/image-20241116125839541.png" /></p>
<p><img alt="image-20241116125830996" src="../assets/image-20241116125830996.png" /></p>
<h4 id="maizerouter-"><a href="">MaizeRouter-</a><a class="headerlink" href="#maizerouter-" title="Permanent link">&para;</a></h4>
<ul>
<li>2nd place of ISPD 2007 contest 2D GR</li>
<li>1st place of ISPD 2007 contest 3D GR</li>
</ul>
<h4 id="fgr-3d-tcad-2008-"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4526750">FGR-3d-TCAD-2008-</a><a class="headerlink" href="#fgr-3d-tcad-2008-" title="Permanent link">&para;</a></h4>
<ul>
<li>1st place of ISPD 2007 contest 2D GR</li>
<li>3rd place of ISPD 2007 contest 3D GR</li>
<li>FGR [6] used maze routing to directly rip up &amp; reroute nets, based on the discrete Lagrangian cost framework.   </li>
<li></li>
</ul>
<h4 id="mgr">MGR<a class="headerlink" href="#mgr" title="Permanent link">&para;</a></h4>
<ul>
<li>MGR [8] used pattern routing and layer assignment to obtain a 3D initial solution, and then adopted 3D maze routing to rip up &amp; reroute the nets in congestion areas.   </li>
</ul>
<h4 id="-layer-assignmentvia-minization-trans-2008-dp-nthu"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083">-Layer assignment+Via minization-Trans-2008-DP-NTHU</a><a class="headerlink" href="#-layer-assignmentvia-minization-trans-2008-dp-nthu" title="Permanent link">&para;</a></h4>
<ul>
<li>Congestion-Constrained Layer Assignment for Via Minimization in Global Routing</li>
<li>CUGR’s rely work</li>
<li>ISPD07 contest 后的一个跟进工作</li>
<li>也没提到 maze routing</li>
<li>没定义 wire cost, 在每一对 GCell 之间 layer assignment, 慢？</li>
<li>第一次用 DP?</li>
</ul>
<h5 id="background_20">background<a class="headerlink" href="#background_20" title="Permanent link">&para;</a></h5>
<ul>
<li>there are two main approaches  </li>
</ul>
<p><img alt="image-20250208202630352" src="../assets/image-20250208202630352.png" /></p>
<ul>
<li>
<p><code>3D</code>: route all nets directly on the multilayer solution space. Because this approach directly generates a multilayer global routing result, <strong>it can take the via cost into account during construction</strong>. However, this method may cost <strong>too much CPU time</strong> with a large problem size. (现在都用 GPU 做并行了，这种方法就变多了)</p>
<ol>
<li>such as </li>
</ol>
<p><img alt="image-20250208201732440" src="../assets/image-20250208201732440.png" /></p>
</li>
<li>
<p><code>2D + layer assigment</code>: The other approach is to first <strong>compress</strong> a multilayer grid graph into a one-layer grid graph, then use a <strong>one-layer router</strong> to solve the one-layer global routing problem, and finally perform <strong>layer assignment</strong> to assign each wire in the multilayer grid graph</p>
<p><img alt="image-20250208202642473" src="../assets/image-20250208202642473.png" /></p>
<p>The edges corresponding to <strong>vias disappear</strong> in the one-layer grid graph. The capacity of each edge in the one-layer grid graph is obtained by <strong>accumulating</strong> the corresponding edge capacities in the three-layer grid graph</p>
<p>This approach can take advantage of many current full-fledged one-layer routers, e.g., [2]–[4], and use an affordable run time to generate an initial one-layer routing result. 本文主要针对 layer assignment. 注意 layer assignment 是对二维的所有边进行层分配。</p>
</li>
<li>
<p>vias not only degrade the reliability and the performance of a design but also increase the manufacturing cost.  </p>
</li>
<li>
<p>previous work’s layer assignment use greedy heuristics [8] or time-consuming integer linear programming methods [9]  to minimize the via cost.  </p>
</li>
<li>
<p>像这种串行的还是要考虑 net order, 越早布线的 net 越不会拥塞，net order 很重要</p>
</li>
</ul>
<p><strong>task and contribution:</strong></p>
<ul>
<li>这篇没有考虑优先方向（To simplify the presentation of our algorithm, we do not make any assumption about the preferred routing direction for each layer in the layer assignment problem.）不过也说明了这个工作能够很简单引用到考虑优先方向的情况</li>
<li>follow ISPD07 contest, 假设 via 的 capacity 是无限的（CUGR 中明确了不进行这种假设）</li>
<li>based on a one-layer routing result</li>
<li>minimize <code>via cost</code>, <code>WL</code> and <code>congestion overflow</code></li>
<li>propose a polynomial-time algorithm: first generate <code>net order</code> , then solves the layer assignment problem</li>
<li>can improve 3 winner of ISPD07 contest</li>
</ul>
<h5 id="model_15">model<a class="headerlink" href="#model_15" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>COngestion-constrained Layer Assignment (COLA)’s submodule</p>
</li>
<li>
<p>Net order generation</p>
<ol>
<li>
<p>The net order has a direct influence on the utilization of routing resources, so it is one of the key parts of COLA.   </p>
</li>
<li>
<p>对 net 进行打分决定 order</p>
</li>
</ol>
<p><img alt="image-20250208220017618" src="../assets/image-20250208220017618.png" /></p>
<p>注意，线长越短，分数越高，net 越应该先布线。解释：</p>
<p><img alt="image-20250208221143998" src="../assets/image-20250208221143998.png" /></p>
</li>
<li>
<p>Eemove Cycles</p>
<ol>
<li>
<p>Arbitrarily remove.</p>
</li>
<li>
<p>（为什么映射到第一层会有 cycles？初始是怎么连起来的？没说？FLUTE 算法是 08 年才出来，可能当时还没用上）</p>
</li>
</ol>
<p><img alt="image-20250208222041475" src="../assets/image-20250208222041475.png" /></p>
</li>
<li>
<p>Single-net layer assignment  （SOLA+APEC）</p>
<p><strong>SOLA</strong>(Singlenet Optimal Layer Assignment)  </p>
<ol>
<li>
<p>determines an optimal layer assignment result <strong>without considering congestion constraints</strong> for a given net  </p>
</li>
<li>
<p><strong>dynamic programming</strong> technique</p>
</li>
<li>
<p>不考虑拥塞，这个方法能得到最好质量</p>
</li>
<li>
<p>step:</p>
</li>
</ol>
<blockquote>
<p>01: for tree in layer 1, <strong>random</strong> select a pin as root, then use DFS or DFS to get a <strong>queue</strong>, so get the edge <strong>order</strong>. It become a <strong>DAG</strong></p>
<p><img alt="image-20250208223956201" src="../assets/image-20250208223956201.png" /></p>
<p>02: 定义图 5(c)中, a 的父节点是 p2，定义 mvc(v, r)（minimum via cost）</p>
<p><img alt="image-20250209140741895" src="../assets/image-20250209140741895.png" /></p>
<p>03: </p>
<p>​  for pins who have not child, mvc:</p>
<p><img alt="image-20250209143711603" src="../assets/image-20250209143711603.png" /></p>
<p>​  for pins who have child and not root:</p>
<p>​  这个公式其实就是为了确定下每个点下一步的 layer 在哪里。比如算出最小是 mvc(v, 1), 那么 e_(v, ch(e))就在第 r 层</p>
<p><img alt="image-20250209143753884" src="../assets/image-20250209143753884.png" /></p>
<p>​  for root:</p>
<p><img alt="image-20250209145157487" src="../assets/image-20250209145157487.png" /></p>
<ul>
<li>
<p>the difference is excluding r in ∆  </p>
</li>
<li>
<p>because mvc(v, r) does not depend on the value of r when v </p>
</li>
</ul>
<p>is the root, we have mvc (v, 1) = mvc(v, 2) = · · · = mvc(v, k)</p>
</blockquote>
<p><strong>APEC</strong>(Accurate and Predictable Examination for Congestion constraints)  </p>
<ol>
<li>
<p>can detect and prevent any <strong>congestion</strong> constraint violation in advance  </p>
</li>
<li>
<p>prevention condition:</p>
</li>
</ol>
<p><img alt="image-20250209153339230" src="../assets/image-20250209153339230.png" /></p>
<p>如果存在一个在 layer1 上压缩的边不满足这两个 condition，那么这条边的 layer assignment（SOLA）结果就不可能满足 congesion</p>
</li>
<li>
<p>SOLA+APEC always finds a layer assignment result satisfying both <strong>prevention conditions</strong> for each net  </p>
</li>
<li>
<p>COLA</p>
</li>
</ul>
<p><img alt="image-20250209153812734" src="../assets/image-20250209153812734.png" /></p>
<p>​   </p>
<h5 id="data_12">data<a class="headerlink" href="#data_12" title="Permanent link">&para;</a></h5>
<p>six-layer benchmarks from ISPD’07</p>
<h4 id="grip-3dip-dac-2009"><a href="https://dl.acm.org/doi/pdf/10.1145/1629911.1629999">GRIP-3d+IP-DAC-2009</a><a class="headerlink" href="#grip-3dip-dac-2009" title="Permanent link">&para;</a></h4>
<p>基于整数规划</p>
<p>3d: solve the 3D problem directly on the 3D routing grids,  </p>
<p>slow: Although theoretically the direct 3D technique should produce better solutions, in practice it is less successful in both solution quality and runtime than 2D routing with layer assignment  –cite–&gt; [Fastroute4.1]</p>
<p>slow: Although we see solutions with shorter wirelength generated by full-3D concurrent approach like GRIP [21], that solution quality is achieved by impractically long runtime   –cite–&gt; [Fastroute4.1]</p>
<h4 id="bfgr-3dlagrangian-ispd-2010-umichibm-"><a href="https://dl-acm-org-443.webvpn.scut.edu.cn/doi/10.1145/1735023.1735035">BFG~R-3d+Lagrangian-ISPD-2010--UMICH+IBM-</a><a class="headerlink" href="#bfgr-3dlagrangian-ispd-2010-umichibm-" title="Permanent link">&para;</a></h4>
<ul>
<li>有 net order</li>
</ul>
<h5 id="background_21">background<a class="headerlink" href="#background_21" title="Permanent link">&para;</a></h5>
<h5 id="contribution_18">contribution<a class="headerlink" href="#contribution_18" title="Permanent link">&para;</a></h5>
<ol>
<li>a novel branch-free representation (BFR) for routed nets  </li>
<li>a trigonometric penalty function (TPF)  </li>
<li>dynamic adjustment of Lagrange multipliers (DALM)  </li>
<li>cyclic net locking (CNL)  </li>
<li>aggressive lower-bound estimates (ALBE) for A*-search, resulting in faster routing.  </li>
</ol>
<h5 id="flow_13">flow<a class="headerlink" href="#flow_13" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328141308281" src="../assets/image-20250328141308281.png" /></p>
<h4 id="mgriccad-2011"><a href="https://ieeexplore.ieee.org/abstract/document/6105336">MGR–ICCAD-2011</a><a class="headerlink" href="#mgriccad-2011" title="Permanent link">&para;</a></h4>
<p>multi-level （coarsened  and fine-gained）</p>
<h4 id="fastroute41-an-efficient-and-high-quality-global-router-2012"><a href="https://home.engineering.iastate.edu/~cnchu/pubs/j52.pdf">FastRoute4.1-an efficient and high-quality global router-2012</a><a class="headerlink" href="#fastroute41-an-efficient-and-high-quality-global-router-2012" title="Permanent link">&para;</a></h4>
<p>https://dl.acm.org/doi/abs/10.1155/2012/608362</p>
<h5 id="background_22">background<a class="headerlink" href="#background_22" title="Permanent link">&para;</a></h5>
<p>FastRoute is a global routing tool for VLSI back-end design. It is based on sequential rip-up and re-route (RRR) and a lot of novel techniques. <a href="http://home.engineering.iastate.edu/~cnchu/pubs/c36.pdf">FastRoute 1.0</a> first uses <strong>FLUTE</strong> to construct <strong>congestion-driven Steiner trees</strong>, which will later undergo the <strong>edge shifting</strong> process to optimize tree structure to reduce congestion. It then uses <strong>pattern routing and maze routing</strong> with <strong>logistic function</strong> based cost function to solve the congestion problem. <a href="http://home.engineering.iastate.edu/~cnchu/pubs/c40.pdf">FastRoute 2.0</a> proposed <strong>monotonic routing</strong> and <strong>multi-source multi-sink maze routing</strong> techniques to enhance the capability to reduce congestion. <a href="http://home.engineering.iastate.edu/~cnchu/pubs/c51.pdf">FastRoute 3.0</a> introduced the <strong>virtual capacity</strong> technique to adaptively change the capacity associated with each global edge to divert wire usage from highly congested regions to less congested regions. <a href="http://home.engineering.iastate.edu/~cnchu/pubs/c52.pdf">FastRoute 4.0</a> proposed <strong>via-aware Steiner tree</strong>, <strong>3-bend routing</strong> and a <strong>delicate layer assignment algorithm</strong> to effectively reduce via count while maintaining outstanding congestion reduction capability. <a href="http://home.engineering.iastate.edu/~cnchu/pubs/j52.pdf">FastRoute 4.1</a> simplifies the way the <strong>virtual capacities</strong> are updated and applies a single set of tuning parameters to all benchmark circuits.</p>
<h5 id="model_16">model<a class="headerlink" href="#model_16" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241211103407310" src="../assets/image-20241211103407310.png" /></p>
<h5 id="flow_14">flow<a class="headerlink" href="#flow_14" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241211103347856" src="../assets/image-20241211103347856.png" /></p>
<h4 id="nthu-route-10-tvlsi-2010-"><a href="https://ieeexplore.ieee.org/document/5703167">NTHU Route 1.0- -TVLSI-2010-</a><a class="headerlink" href="#nthu-route-10-tvlsi-2010-" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241115155033412" src="../assets/image-20241115155033412.png" /></p>
<h4 id="nthu-route-20-tcad-2013"><a href="https://ieeexplore.ieee.org/document/6504553">NTHU Route 2.0- -TCAD-2013</a><a class="headerlink" href="#nthu-route-20-tcad-2013" title="Permanent link">&para;</a></h4>
<ul>
<li>2D</li>
<li>a history-based cost function.  </li>
</ul>
<h4 id="nctu-gr-10-3d-congestion-relaxed-layer-assignment-2011-"><a href="https://ieeexplore.ieee.org/document/5703167">NCTU GR 1.0-3D-congestion relaxed layer assignment- 2011-</a><a class="headerlink" href="#nctu-gr-10-3d-congestion-relaxed-layer-assignment-2011-" title="Permanent link">&para;</a></h4>
<h2 id="-it-improved-the-scheme-to-estimate-the-realtime-congestion-more-accurately-by-using-a-history-term-that-will-gradually-wear-off-as-the-number-of-iterations-increases-if-the-overflow-disappears">- it improved the scheme to estimate the realtime congestion more accurately by using a history term that will gradually wear off as the number of iterations  increases if the overflow disappears.<a class="headerlink" href="#-it-improved-the-scheme-to-estimate-the-realtime-congestion-more-accurately-by-using-a-history-term-that-will-gradually-wear-off-as-the-number-of-iterations-increases-if-the-overflow-disappears" title="Permanent link">&para;</a></h2>
<h4 id="nctu-gr-20-multithreaded-collision-aware-cad-2013-"><a href="https://ieeexplore.ieee.org/document/6504553">NCTU GR 2.0-Multithreaded Collision Aware- CAD-2013-</a><a class="headerlink" href="#nctu-gr-20-multithreaded-collision-aware-cad-2013-" title="Permanent link">&para;</a></h4>
<p><a href="https://people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm">people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm</a></p>
<p><a href="https://github.com/PengjuY/NCTU-GR2">PengjuY/NCTU-GR2: This is a binary file of NCTUgr2, which is a global router</a></p>
<ul>
<li>net-level parallel method </li>
<li>RSMT-aware routing scheme  </li>
<li></li>
</ul>
<h4 id="ogre-new-cost-function-2019-"><a href="https://woset-workshop.github.io/PDFs/2019/a18.pdf">OGRE- new cost function- -2019- -</a><a class="headerlink" href="#ogre-new-cost-function-2019-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/AUCOHL/OGRE">Open source!</a></li>
<li><strong>LEF/DEF-based</strong></li>
<li>3D</li>
<li>用的是老方法，不过解释的挺清楚的</li>
<li>components by a group of undergraduate students as a course project.</li>
</ul>
<h4 id="sproute-10-a-scalable-parallel-negotiation-based-global-router-iccad-2019"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8942105">SPRoute 1.0: A Scalable Parallel Negotiation-based Global Router-ICCAD-2019</a><a class="headerlink" href="#sproute-10-a-scalable-parallel-negotiation-based-global-router-iccad-2019" title="Permanent link">&para;</a></h4>
<ul>
<li>基于 <code>net-level</code> 多线程的并行加速 <code>迷宫算法</code></li>
<li><code>negotiation-based</code> rip-up and reroute two-phase maze routing</li>
<li>resolves livelock issue(CPU)</li>
<li>
<p>open source</p>
</li>
<li>
<p>introduced a concept called <code>soft capacity</code> to reserve routing space for detailed routing and explored <code>several parallelization strategies</code> to speed up global routing. </p>
</li>
<li>是 CPU 上的并行，讲了挺多关于锁的问题，没看懂，让我们看 2.0 吧</li>
<li>2D</li>
</ul>
<h5 id="background_23">background<a class="headerlink" href="#background_23" title="Permanent link">&para;</a></h5>
<p>总体</p>
<p><img alt="image-20241118140649906" src="../assets/image-20241118140649906.png" /></p>
<p>In many global routers, maze routing is the most time-consuming stage.  </p>
<p><img alt="image-20241118141048410" src="../assets/image-20241118141048410.png" /></p>
<p><strong>challenge</strong></p>
<p><img alt="image-20241118144548718" src="../assets/image-20241118144548718.png" /></p>
<p><img alt="image-20241118144701004" src="../assets/image-20241118144701004.png" /></p>
<p>因为这个现象，多线程反而慢了</p>
<p><img alt="image-20241118144924768" src="../assets/image-20241118144924768.png" /></p>
<p><strong>原理</strong></p>
<ul>
<li>Galois system  </li>
</ul>
<p><img alt="image-20241118150854386" src="../assets/image-20241118150854386.png" /></p>
<ul>
<li>
<p>Net-level Parallelism  </p>
</li>
<li>
<p>Fine-grain Parallelism  </p>
</li>
</ul>
<h5 id="data_13">data<a class="headerlink" href="#data_13" title="Permanent link">&para;</a></h5>
<p>ISPD 2008  contest</p>
<h4 id="cugr-3d-patternmulti-level-maze-routingpatching-dac-2020-cuhk"><a href="https://github.com/cuhk-eda/cu-gr">CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK</a><a class="headerlink" href="#cugr-3d-patternmulti-level-maze-routingpatching-dac-2020-cuhk" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>ICCAD 2019 Contest First Place</p>
</li>
<li>
<p><a href="https://github.com/cuhk-eda/cu-gr">open source!</a></p>
</li>
<li>
<p>3d+多线程+</p>
</li>
<li>
<p>这个文章没有讨论 prefer direction</p>
</li>
<li>
<p>多线程体现在哪里？</p>
</li>
<li>
<p>will take more runtime than 2D initial routing  </p>
</li>
<li>
<p>注意：这种格式的 GR 输出可以适配 Innovus</p>
</li>
<li>
<p>A probability-based cost scheme   </p>
</li>
<li>
<p>CUGR [9] used 3D pattern routing based on dynamic programming to obtain an initial routing, and used multi-level 3D maze routing for rip-up and rerouting to obtain a final global routing solution  </p>
</li>
<li>
<p>time-complexity of 3D pattern routing is $\mathcal{O}(L^4|V|)$</p>
</li>
</ul>
<p>compare with <a href="# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083)">Trans-2008</a>, CUGR reduces the complexity to $\mathcal{O}(L^4|V|)$ by selecting the root carefully so that each vertex will have at most three preceding vertices instead of four.  ~~注意，这里说 相比 <a href="# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083)">Trans-2008</a>的 $\mathcal{O}(L^5|V|)$ ，它的复杂度是 $\mathcal{O}(L^4|V|)$ ，感觉是放在了 <a href="# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083)">Trans-2008</a>进行不转弯的 DP-based layer assignment 方法上了，实际上按照本文说的方法，理论上是 $L * L^{2<em>3}|V|$，因为 CUGR 每次是对一个 L pattern 为单位计算 <code>mvc</code>, 时间复杂度是 $2</em>L<em>L$~~.确实是 $L^4$, CUGR 对一个 L pattern 分了两部分计算 <code>mvc</code> 没一部分时间复杂度是 $L</em>2$</p>
<h5 id="background_24">background<a class="headerlink" href="#background_24" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241122110742970" src="../assets/image-20241122110742970.png" /></p>
<ul>
<li>A common strategy of doing 3D global routing, as adopted by NCTU-GR 2.0 [5], NTHU-Route 2.0 [6], NTUgr [7] and FastRoute 4.0 [8], is to <strong>first compress the 3D grid graph into a 2D grid graph and perform 2D global routing</strong>.   </li>
<li>directly route the nets in a 3D grid graph：FGR [10] , GRIP [11] , MGR [12]  </li>
<li>Traditional pattern routing generates 2D topologies only, while <strong>our</strong> proposed 3D pattern routing directly generates 3D topologies without the need of an extra layer assignment stage</li>
<li>使用 DR 结果进行多角度 metrics 评估：</li>
</ul>
<p><img alt="image-20241122113634633" src="../assets/image-20241122113634633.png" /></p>
<h5 id="task_11">task<a class="headerlink" href="#task_11" title="Permanent link">&para;</a></h5>
<ul>
<li>detailed-routability-driven  directly-3d multi thread GR</li>
</ul>
<h5 id="contibution">contibution<a class="headerlink" href="#contibution" title="Permanent link">&para;</a></h5>
<ul>
<li>probability-based cost scheme</li>
<li>minimizing the possibility of overflow after detailed routing</li>
<li><code>3D pattern routing</code> technique (2D pattern routing + layer assignment)(前面又说 directly in the 3D space?)</li>
<li>without overflow even only L shape patten routing</li>
<li>pre-work [15] 是先在 2d 上进行 pattern routing, 然后进行 layer assignment, 这里是直接在 3d 进行 pattern routing. 3d pattern routing can avoid loss of accuracy caused by compressing 3D grid graph to 2D  </li>
<li><code>multi-level maze routing</code>:</li>
<li>coarsened level –&gt; searches for a region with the <strong>best routability</strong>. <strong>first</strong> narrows the search space to a smaller region  </li>
<li>fine-grained level –&gt; searches for a <strong>lowest cost</strong> solution within the region</li>
<li>patching mechanism</li>
<li>further improve the detailed routability</li>
</ul>
<h5 id="flow_15">flow<a class="headerlink" href="#flow_15" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241122123825463" src="../assets/image-20241122123825463.png" /></p>
<p>In <code>3D pattern routing</code> (<code>inital routing</code>), the nets are broken down into two-pin nets, and a <code>dynamic programming</code> based algorithm will route the two pin nets sequentially using Lshape patterns and <code>stacking vias</code> at the turns.  </p>
<p>In the <code>multi-level 3D maze routing</code> phase, the grid graph is <code>coarsened</code> to shrink the routing space, and maze routing is first performed in the coarsened space with an objective to find a routing region with the <strong>highest routability</strong>.   A <code>fine-grained maze routing</code> will then search for a lowest cost path within the region.  use its <code>patching</code> mechanism here.</p>
<h5 id="model_17">model<a class="headerlink" href="#model_17" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Gcell 之间的容量等于 track，一般 GR 表征 via 的容量是无限的，但是在本文中不是</p>
</li>
<li>
<p><strong>three base definition:</strong></p>
</li>
<li>resource = capacity - demand</li>
<li>这三个变量在 GCell 和 wire_edge 上都有特征，也就是说有 6 个值</li>
<li>resource 能够直接表示拥程度</li>
<li><img alt="image-20241122130729921" src="../assets/image-20241122130729921.png" /></li>
<li>
<p><img alt="image-20241122130736928" src="../assets/image-20241122130736928.png" /></p>
</li>
<li>
<p><strong>cost scheme</strong></p>
</li>
<li>
<p>主要分成 wire 和 via 两部分：</p>
<p><img alt="image-20241122130626631" src="../assets/image-20241122130626631.png" /></p>
</li>
<li>
<p>wire cost:</p>
<p><img alt="image-20241122130653693" src="../assets/image-20241122130653693.png" /></p>
<ol>
<li>
<p><em><code>wl</code></em> is wire lenght cost</p>
</li>
<li>
<p><em><code>eo</code></em> is expected overflow cost, where <em><code>uoc</code></em> is hyper parameter, The larger  <em><code>d(u, v)</code></em> is, the more likely it is to be congested. is accurate if the <strong>DR</strong> adopts the simplest strategy of picking a track <strong>randomly</strong> to route. However, most well designed detailed routers will do much better than random selection.  </p>
</li>
<li>
<p><em><code>lg(u,v)</code></em> is a variable to refine <em><code>d(u, v)</code></em>. “+1” 是为了值域在（0，1）表示概率。 <em><code>slope</code></em> is hyper parameter. When the resources are abundant, there is almost <strong>no congestion cost</strong>, but the cost will increase rapidly as the resources are being used up and will keep increasing almost <strong>linearly</strong> after all the resources are used  </p>
</li>
</ol>
<p><img alt="image-20241122130807532" src="../assets/image-20241122130807532.png" /></p>
</li>
<li>
<p>via cost:</p>
<ol>
<li>thanks to our <strong>3D pattern routing strategy</strong>, a via cost scheme can be embedded to reflect the impact.  </li>
<li><img alt="image-20241122130701652" src="../assets/image-20241122130701652.png" /></li>
<li><em><code>uvc</code></em> is hyper parameter. </li>
<li>公式（5a）为什么要“+1”</li>
</ol>
</li>
<li>
<p>Initial Routing / 3D Pattern Routing</p>
</li>
<li>
<p>use <code>FLUTE</code> first (not congestion awared)</p>
</li>
<li>
<p>use <code>edge shifting</code> (described in <a href="#[FastRoute1.0—2006]()">FastRoute</a>) to alleviate  congestion.</p>
</li>
<li>
<p><strong>randomly</strong> choose one node in net, use DFS to get a queue and then get a DAG</p>
</li>
<li>
<p>类似 [15]，动态规划选择 cost 最小的 3d L pattern，每个 L pattern 有(2 * L * L)种可能</p>
<p><img alt="image-20250209165125803" src="../assets/image-20250209165125803.png" /></p>
<p>最后在 root 处得到最终的结果</p>
</li>
<li>
<p>Multi-level 3D Maze Routing  </p>
</li>
<li>
<p>maze route planing</p>
<p>aims at finding a smaller but highly routable search space</p>
<ol>
<li>
<p>compress a block of G-cells (5x5 in our implementation), use avg to descripe <code>capacity, demand, resource</code></p>
</li>
<li>
<p>cost function:</p>
</li>
</ol>
<p><img alt="image-20250209172954350" src="../assets/image-20250209172954350.png" /></p>
<ol>
<li>得到灰色粗网格：</li>
</ol>
<p><img alt="image-20250209173822187" src="../assets/image-20250209173822187.png" /></p>
<ol>
<li>之后会在这几个 BBox 中分别进行计算 <code>cost scheme</code>，得到上图黑色实线</li>
</ol>
</li>
<li>
<p>fine-grained maze routing within guides</p>
</li>
<li>
<p>Postprocessing / Guide Patching  </p>
</li>
<li>
<p>we can add new guides to improve detailed routability. adding new stand-alone guides to alleviate routing hot spots.  </p>
</li>
<li>
<p>three kind of patching:</p>
<ol>
<li>
<p>Pin Region Patching  </p>
</li>
<li>
<p>most effective  </p>
</li>
<li>
<p>the ideal way of improving pin accessibility is to identify those hard-to-access pins and assign more resources to them  </p>
<p><img alt="image-20250209191227014" src="../assets/image-20250209191227014.png" /></p>
</li>
<li>
<p>Our global router will check the upper (or lower) two layers of a pin, which are vital for accessing the pin. use 3 × 3 patching guides. </p>
</li>
<li>
<p>没写判断 <code>hard-to-access pins</code> 的具体的方法</p>
</li>
<li>
<p>Long Segment Patching:  </p>
</li>
<li>
<p>a longer routing segment often means more wrong way wires and causing more congestion.  </p>
</li>
<li>If a guide is longer than a specified length I, we’ll consider long segment patching.  </li>
</ol>
<p><img alt="image-20250209191725644" src="../assets/image-20250209191725644.png" /></p>
<ul>
<li>
<p>if a G-cell with resource below a threshold T is encountered, a single G-cell route guide will be patched above or below it, depending on which of them has sufficient resource  </p>
</li>
<li>
<p>Violation Patching:  </p>
</li>
<li>
<p>For G-cell with inevitable violations, patching will be used again to enable the detailed router to search with more flexibility.   </p>
<p><img alt="image-20250209192310471" src="../assets/image-20250209192310471.png" /></p>
</li>
<li></li>
</ul>
</li>
</ul>
<h5 id="data_14">data<a class="headerlink" href="#data_14" title="Permanent link">&para;</a></h5>
<p>iccad 2019 dataset</p>
<h5 id="experiment_13">experiment<a class="headerlink" href="#experiment_13" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241122113716242" src="../assets/image-20241122113716242.png" /></p>
<p><img alt="image-20250209192916035" src="../assets/image-20250209192916035.png" /></p>
<ul>
<li>
<p>他自己又比赛后改进了</p>
</li>
<li>
<p><img alt="image-20250209195431218" src="../assets/image-20250209195431218.png" /></p>
</li>
<li>
<p>our algorithm’s peak memory is close to the first place and is 1.83 times of that of the second place on average (ours is 8.22 GB on average and is <strong>19.8 GB</strong> for the biggest design)</p>
</li>
</ul>
<h4 id="vgr-3dvia-mini-aspdac-2024-fzuieda"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/10473939">VGR-3D+via mini-ASPDAC-2024- -FZU+iEDA</a><a class="headerlink" href="#vgr-3dvia-mini-aspdac-2024-fzuieda" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>a 3D global router with via minimization and multi-strategy <mark>rip-up and rerouting</mark>  </p>
</li>
<li>
<p>CPU-based</p>
</li>
</ul>
<h5 id="background_25">background<a class="headerlink" href="#background_25" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p><mark>Vias</mark> are interconnections between different routing metal layers. A large number of vias can reduce manufacturing yield, cause circuit performance degradation, and increase layout area required for interconnections [1], [2]  In VLSI physical design, meeting the DFM (Design for Manufacturability) constraints is essential, and these constraints often include strict requirements regarding vias.  </p>
</li>
<li>
<p>Most academic global routers use pattern routing to obtain initial solution quickly. However, the lack of candidate scheme for pattern routing results in significantly high overflow for the initial solution.  </p>
</li>
<li>
<p>However, existing rip-up and rerouting techniques do not fully consider via minimization.  </p>
</li>
<li>
<p>为什么要 3D，3D 的优势：</p>
</li>
</ul>
<p><img alt="image-20250310112711168" src="../assets/image-20250310112711168.png" /></p>
<h5 id="contribution_19">contribution<a class="headerlink" href="#contribution_19" title="Permanent link">&para;</a></h5>
<ul>
<li>a novel multi-strategy rip-up &amp; rerouting framework  </li>
<li>first leverages two proprietary routing techniques  </li>
<li>via-aware routing cost function  </li>
<li>3D monotonic routing   </li>
<li>3D 3-via-stack routing  </li>
<li>an RSMT-aware expanded source 3D maze routing algorithm  </li>
</ul>
<h5 id="flow_16">flow<a class="headerlink" href="#flow_16" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250310140059564" src="../assets/image-20250310140059564.png" /></p>
<h5 id="model_18">model<a class="headerlink" href="#model_18" title="Permanent link">&para;</a></h5>
<h6 id="modified-via-aware-routing-cost-function">Modified Via-Aware Routing Cost Function<a class="headerlink" href="#modified-via-aware-routing-cost-function" title="Permanent link">&para;</a></h6>
<ul>
<li>
<p>previous works' via penalties are based on a constant cost function, or, the cost of via may decrease over time.  </p>
</li>
<li>
<p>RUDY-based</p>
</li>
</ul>
<p><img alt="image-20250310150030680" src="../assets/image-20250310150030680.png" /></p>
<ul>
<li>CUGR:</li>
</ul>
<p><img alt="image-20250310150007361" src="../assets/image-20250310150007361.png" /></p>
<ul>
<li>Ours:</li>
</ul>
<p><img alt="image-20250310150038994" src="../assets/image-20250310150038994.png" /></p>
<h6 id="local-rip-up-rerouting">Local Rip-up &amp; Rerouting<a class="headerlink" href="#local-rip-up-rerouting" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250310150116571" src="../assets/image-20250310150116571.png" /></p>
<p><img alt="image-20250310150130359" src="../assets/image-20250310150130359.png" /></p>
<h6 id="global-rip-up-rerouting">Global Rip-Up &amp; Rerouting<a class="headerlink" href="#global-rip-up-rerouting" title="Permanent link">&para;</a></h6>
<ol>
<li>
<p>3D 3-via-stack routing</p>
</li>
<li>
<p>focuses on adding as few vias as possible  </p>
<p><img alt="image-20250310151014205" src="../assets/image-20250310151014205.png" /></p>
</li>
<li>
<p>A 3D 3-via-stack path consists of three parts:   </p>
<ul>
<li>two 3D Lshape paths</li>
<li>a stack of vias  </li>
</ul>
</li>
<li>
<p>The 3D 3-via-stack routing is faster than 3D maze routing and offers good congestion reduction. We use it before 3D maze routing to reduce the number of overflowed nets, resulting in lower total overflow and via counts  </p>
</li>
<li>
<p>RSMT-aware ESMR(expanded source 3D maze routing ).  </p>
</li>
<li>
<p>increases wire length as less as possible</p>
</li>
<li>After completing the 3D 3-via-stack routing algorithm, only a small number of nets have congestion, and we need to use 3D maze routing to process these nets  </li>
<li><img alt="image-20250310153555924" src="../assets/image-20250310153555924.png" /></li>
<li><img alt="image-20250310160008974" src="../assets/image-20250310160008974.png" /></li>
<li></li>
</ol>
<h5 id="experiment_14">experiment<a class="headerlink" href="#experiment_14" title="Permanent link">&para;</a></h5>
<ol>
<li>Effectiveness of 3D Monotonic Routing and 3D 3-Via-Stack Routing  </li>
</ol>
<p>one using 3D monotonic routing, 3D 3-viastack routing and the RSMT-aware ESMR, and another using only the RSMT-aware ESMR  </p>
<p><img alt="image-20250310161001286" src="../assets/image-20250310161001286.png" /></p>
<ol>
<li>Effectiveness of RSMT-Aware ESMR  </li>
</ol>
<p><img alt="image-20250310161128720" src="../assets/image-20250310161128720.png" /></p>
<ol>
<li>Comparison with the State-of-the-Art  </li>
</ol>
<p><img alt="image-20250310161315484" src="../assets/image-20250310161315484.png" /></p>
<p><img alt="image-20250310161303747" src="../assets/image-20250310161303747.png" /></p>
<ol>
<li>detailed results of all components of the ‘DR Score’  </li>
</ol>
<p><img alt="image-20250310161451514" src="../assets/image-20250310161451514.png" /></p>
<p>This demonstrates that V-GR can find a routing scheme with fewer vias and less overflow while maintaining almost the same wire length.  </p>
<h3 id="gr_concurrent">GR_Concurrent<a class="headerlink" href="#gr_concurrent" title="Permanent link">&para;</a></h3>
<h4 id="-multicommodity-flow-trans-2001-"><a href="https://janders.eecg.utoronto.ca/1387/readings/global_routing.pdf">-Multicommodity Flow-Trans-2001-</a><a class="headerlink" href="#-multicommodity-flow-trans-2001-" title="Permanent link">&para;</a></h4>
<ul>
<li>first Multicommodity Flow?</li>
</ul>
<h4 id="boxrouter-10-dac-2006-ilp-"><a href="https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/1146909.1147009">BoxRouter 1.0- -DAC-2006-ILP- -</a><a class="headerlink" href="#boxrouter-10-dac-2006-ilp-" title="Permanent link">&para;</a></h4>
<ul>
<li>3rd place of ISPD 2007 contest 2D GR</li>
<li>2nd place of ISPD 2007 contest 3D GR</li>
<li>integer linear programming (ILP)  based</li>
</ul>
<h5 id="background_26">background<a class="headerlink" href="#background_26" title="Permanent link">&para;</a></h5>
<h5 id="contribution_20">contribution<a class="headerlink" href="#contribution_20" title="Permanent link">&para;</a></h5>
<ul>
<li>PreRouting step can capture the most <mark>congested</mark> regions with reasonable accuracy</li>
<li>key <code>BoxRouting</code> idea   </li>
<li>BoxRouter progressively expands the routing box and performs routing within each expanded box (BoxRouting), until the expanded box covers the whole circuit (all the wires are routed)  </li>
<li>efficient progressive integer linear programming  <mark>(ILP)</mark>   </li>
<li>In our ILP, only wires between two successive boxes are considered with L-shape patterns. Thus even with ILP, our runtime is still much faster than existing global routers [1] [2] [16]</li>
<li>without rip-up  </li>
</ul>
<h5 id="flow_17">flow<a class="headerlink" href="#flow_17" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250317113717747" src="../assets/image-20250317113717747.png" /></p>
<h4 id="sidewinder-scalable-ilp-slip-2008-ilp-"><a href="">sidewinder-scalable ILP-SLIP-2008-ILP- -</a><a class="headerlink" href="#sidewinder-scalable-ilp-slip-2008-ilp-" title="Permanent link">&para;</a></h4>
<ul>
<li>只有 10^4^数量级的 net 数据</li>
</ul>
<h5 id="background_27">background<a class="headerlink" href="#background_27" title="Permanent link">&para;</a></h5>
<h5 id="contribution_21">contribution<a class="headerlink" href="#contribution_21" title="Permanent link">&para;</a></h5>
<h2 id="-dynamically-updated-congestion-map">- dynamically-updated congestion map<a class="headerlink" href="#-dynamically-updated-congestion-map" title="Permanent link">&para;</a></h2>
<h5 id="flow_18">flow<a class="headerlink" href="#flow_18" title="Permanent link">&para;</a></h5>
<h4 id="boxrouter-20-2008-ilp-"><a href="">BoxRouter 2.0- - -2008-ILP- -</a><a class="headerlink" href="#boxrouter-20-2008-ilp-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/Apodead/BoxRouter">OpenSource!</a></li>
<li><img alt="image-20250317123459126" src="../assets/image-20250317123459126.png" /></li>
<li>github 上有两个版本, 貌似都不是作者的</li>
<li>是一个 2d 的 GR</li>
<li>concurrent: 整数线性规划（ILP）</li>
</ul>
<p><img alt="image-20241115155857782" src="../assets/image-20241115155857782.png" /></p>
<h5 id="background_28">background<a class="headerlink" href="#background_28" title="Permanent link">&para;</a></h5>
<h5 id="contribution_22">contribution<a class="headerlink" href="#contribution_22" title="Permanent link">&para;</a></h5>
<ul>
<li>dynamic scaling for robust <code>negotiation-based</code> A* search</li>
<li>topology-aware wire ripup </li>
<li>which rips up some wires in the congested regions without changing the net topology.</li>
<li>integer linear programming (ILP) for via/blockage-aware layer assignment</li>
</ul>
<h5 id="flow_19">flow<a class="headerlink" href="#flow_19" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250317113738643" src="../assets/image-20250317113738643.png" /></p>
<p>​                               </p>
<h4 id="grip-combination-opt-trans-2009-dp-ntu"><a href="https://jlinderoth.github.io/papers/Wu-Davoodi-Linderoth-10-PP.pdf">GRIP-combination opt-Trans-2009-DP- -NTU</a><a class="headerlink" href="#grip-combination-opt-trans-2009-dp-ntu" title="Permanent link">&para;</a></h4>
<ul>
<li>这个有会议和期刊两个版本</li>
<li>GRIP [7] determined 3D routing candidate patterns for each net in advance, and then used ILP for optimal selection.   </li>
<li>基于组合优化</li>
<li></li>
</ul>
<h4 id="coala-concurrent-layer-assignment-tcad-2022-"><a href="">COALA-concurrent layer assignment -TCAD-2022-</a><a class="headerlink" href="#coala-concurrent-layer-assignment-tcad-2022-" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>2d</p>
</li>
<li>
<p>capacity 放到了 gcell</p>
</li>
</ul>
<p><img alt="image-20250328171500477" src="../assets/image-20250328171500477.png" /></p>
<ul>
<li>
<p>M1 is congested and leaves not much routing resource  </p>
</li>
<li>
<p><img alt="image-20250328174737057" src="../assets/image-20250328174737057.png" /></p>
</li>
</ul>
<p>他的 concurrent 是 net 不是 sequencial 进行布线了，但其实还是有进行启发式 sequencial 的部分</p>
<p>原文还说：<code>The candidate segments in Sseg of the current layer are sorted according to three criteria and are sequentially assigned.</code></p>
<ul>
<li></li>
</ul>
<h5 id="background_29">background<a class="headerlink" href="#background_29" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Two-dimensional (2-D) global routing followed by layer assignment is a common and popular strategy to obtain a good tradeoff between runtime and routing performance.   </p>
</li>
<li>
<p>State-of-the-art (SOTA) studies on layer assignment usually adopt <code>dynamic programming-based approaches</code> to <code>sequentially</code> find an optimal solution for each net in terms of overflow or/and the number of vias.  However, a fixed assignment ordering severely restricts the solution space, and the distributed overflows can hardly be resolved with any existing refinement approach  </p>
</li>
<li>
<p>rip-up and rerouting  spends most of the runtime in the whole global routing process   </p>
</li>
<li>
<p>existing layer assignment approaches suffer from two common drawbacks  </p>
</li>
<li>
<p>First, most of the above works sequentially perform layer assignment for each net based on dynamic programming (DP)-based algorithms. In spite of the <mark>optimality</mark> of a DP-based method that minimizes the overflow increment and the number of vias for each net, the <mark>assignment ordering</mark> of all nets severely restricts the solution space, making the overall assignment result <mark>far from optimal</mark>. </p>
</li>
<li>Second, the DP-based approaches cause difficulties in the assignment refinement process. For a tile with a large overflow, <mark>deciding or iteratively trying which segments should be ripped up and reassigned/shifted</mark> critically determines the final solution quality and becomes another complicated optimization problem.  </li>
<li>
<p>In addition, the resulting overflows are randomly scattered on segments, and thus the existing refinement techniques are only performed on each individual wire segment suffering from overflow, limiting the effectiveness in overflow reduction.  (没看懂)</p>
</li>
<li>
<p><img alt="image-20250328164946356" src="../assets/image-20250328164946356.png" /></p>
</li>
</ul>
<p>This overflow can be resolved if the ordering of the blue net and the red net is reversed, while an optimal ordering can hardly be found by using simple heuristics adopted by the above existing works  </p>
<ul>
<li>
<p>there exist some studies proposing Lagrangian relaxation or integer programming-based approaches to consider the layer assignments of multiple nets  </p>
</li>
<li>
<p>sequential layer assignment approaches suffer from limited solution quality  </p>
</li>
<li></li>
</ul>
<h5 id="contribution_23">contribution<a class="headerlink" href="#contribution_23" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328165901489" src="../assets/image-20250328165901489.png" /></p>
<p>一层一层 assign</p>
<h2 id="-capacity-of-a-tile">- capacity of a tile<a class="headerlink" href="#-capacity-of-a-tile" title="Permanent link">&para;</a></h2>
<h5 id="flow_20">flow<a class="headerlink" href="#flow_20" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328173807513" src="../assets/image-20250328173807513.png" /></p>
<p><img alt="image-20250328194952939" src="../assets/image-20250328194952939.png" /></p>
<h5 id="model_19">model<a class="headerlink" href="#model_19" title="Permanent link">&para;</a></h5>
<h6 id="capacity-and-demand-gcell">本文定义的 capacity and demand(都在 GCell 上)<a class="headerlink" href="#capacity-and-demand-gcell" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250328171752900" src="../assets/image-20250328171752900.png" /></p>
<p><img alt="image-20250328172800671" src="../assets/image-20250328172800671.png" /></p>
<h6 id="demand-congestion-map">demand congestion map<a class="headerlink" href="#demand-congestion-map" title="Permanent link">&para;</a></h6>
<p>用 2d 的 routing 预测 3d demand</p>
<p><img alt="image-20250328173211326" src="../assets/image-20250328173211326.png" /></p>
<h6 id="complete-segment-assignment">Complete Segment Assignment<a class="headerlink" href="#complete-segment-assignment" title="Permanent link">&para;</a></h6>
<p>The complete segments are <mark>sorted</mark> according to the following three criteria.  </p>
<ol>
<li>
<p>Residual Parts of Fragmented Segments：highest priority  </p>
</li>
<li>
<p>The Degree of Net Completeness  </p>
</li>
</ol>
<p>$Completeness = N_{assigned}/N_{total}$</p>
<ol>
<li>Segment Length: assign the shorter segment prior to the longer one</li>
</ol>
<p>can result in fewer number of vias  </p>
<h6 id="fragmented-segment-assignment">Fragmented Segment Assignment<a class="headerlink" href="#fragmented-segment-assignment" title="Permanent link">&para;</a></h6>
<p>1) Prediction Map Update for Fragmented Segments  </p>
<p>2) Fragmented Segment Ordering and Assignment:  </p>
<p>A candidate segment can be fragmented and assigned for a subcolumn if the following two conditions are satisfied:  </p>
<ul>
<li>its connected via to the lower layer lies in the subcolumn </li>
<li>its fragmented subpart (blue part) has to overlap the subcolumn with more than one tile.  </li>
<li><img alt="image-20250328201342596" src="../assets/image-20250328201342596.png" /></li>
<li><img alt="image-20250328203232933" src="../assets/image-20250328203232933.png" /></li>
</ul>
<h6 id="3-d-endpoint-rerouting">3-D Endpoint Rerouting<a class="headerlink" href="#3-d-endpoint-rerouting" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250328203521908" src="../assets/image-20250328203521908.png" /></p>
<p>After assigning wire segments for the topmost layer, some segments may still be left unassigned  because of an inaccurate 2-D capacity and demand model.  </p>
<p>four steps：</p>
<ol>
<li>Redundant Via and Partially Fragmented Segment Removal</li>
<li>3-D Multiendpoint Decomposition  </li>
<li>3-D Net Ordering  </li>
<li>3-D Endpoint Rerouting</li>
</ol>
<h6 id="obstacle-aware-strategy">OBSTACLE-AWARE STRATEGY<a class="headerlink" href="#obstacle-aware-strategy" title="Permanent link">&para;</a></h6>
<h5 id="data_15">data<a class="headerlink" href="#data_15" title="Permanent link">&para;</a></h5>
<p>ISPD18 和 ISPD19</p>
<h5 id="experiment_15">experiment<a class="headerlink" href="#experiment_15" title="Permanent link">&para;</a></h5>
<p>对比的模型 CUGR</p>
<h4 id="-lagrangian-based-dac-2023-fzu-ilp-"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10247969">-Lagrangian based- DAC-2023-FZU-ILP-</a><a class="headerlink" href="#-lagrangian-based-dac-2023-fzu-ilp-" title="Permanent link">&para;</a></h4>
<ul>
<li>integer linear programming   </li>
<li>Lagrangian relaxation method  </li>
<li>direction-aware weighted A*-algorithm </li>
</ul>
<h5 id="background_30">background<a class="headerlink" href="#background_30" title="Permanent link">&para;</a></h5>
<ul>
<li>combine the advantages of the two classes of algorithms  （串并行）</li>
<li><code>BoxRouter 2.0 [5] and Sidewinder [9]</code> propose a <mark>maximum routable</mark> <mark>ILP model</mark>, which routes as many nets as possible without congestion by <mark>using several routing patterns.</mark>   Due to limited routing patterns for each net, the two routers may cause some nets <mark>disconnected</mark>, requiring <mark>post-processing</mark> to produce a legal final result.   <code>GRIP [6]</code> proposes an <mark>ILP formulation</mark> that minimizes the total wire length and the number of vias, which <mark>includes many routing patterns</mark> . For their ILP, the LP relaxation is <mark>restricted to a small number of routing patterns</mark> and is solved by the <code>column generation method</code>, and then the obtained solution is optimized <mark>using a local improvement procedure to consider other patterns</mark>.  </li>
</ul>
<h5 id="contricbution">contricbution<a class="headerlink" href="#contricbution" title="Permanent link">&para;</a></h5>
<ul>
<li>a novel <code>ILP based pathfinding model</code> which does not need to generate candidate routing patterns of nets prior</li>
<li>We propose a <code>Lagrangian relaxation method</code> combined with a <code>gradient ascent method</code> to update the multipliers, in which <code>direction-aware weighted A*-algorithm</code> is used to quickly solve a subproblem  </li>
<li>a multi-stage rip-up &amp; rerouting algorithm to optimize the initial routing result, in which each stage uses different routing algorithms and cost functions</li>
</ul>
<h5 id="flow_21">flow<a class="headerlink" href="#flow_21" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328105529319" src="../assets/image-20250328105529319.png" /></p>
<ol>
<li>FLUTE   </li>
<li>Integer Linear Programming (ILP)   </li>
<li>Lagrangian relaxation method combining with a direction-aware weighted A* algorithm   </li>
<li>monotonic routing and maze routing  </li>
</ol>
<h5 id="model_20">model<a class="headerlink" href="#model_20" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328114329898" src="../assets/image-20250328114329898.png" /></p>
<h6 id="ilp-based-pathfinding-model">ILP Based Pathfinding Model<a class="headerlink" href="#ilp-based-pathfinding-model" title="Permanent link">&para;</a></h6>
<p>没看懂 <code>ILP Pathfinding model</code></p>
<ul>
<li>
<p>an ILP based pathfinding model without considering routing patterns  </p>
</li>
<li>
<p><img alt="image-20250328114337684" src="../assets/image-20250328114337684.png" /></p>
</li>
</ul>
<p><img alt="image-20250328114346493" src="../assets/image-20250328114346493.png" /></p>
<p><img alt="image-20250328114353126" src="../assets/image-20250328114353126.png" /></p>
<p><img alt="image-20250328114400547" src="../assets/image-20250328114400547.png" /></p>
<p><img alt="image-20250328114411949" src="../assets/image-20250328114411949.png" /></p>
<p><img alt="image-20250328114420408" src="../assets/image-20250328114420408.png" /></p>
<h6 id="lagrangian-relaxation-method-and-initial-routing">Lagrangian Relaxation Method and Initial Routing<a class="headerlink" href="#lagrangian-relaxation-method-and-initial-routing" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250328144717218" src="../assets/image-20250328144717218.png" /></p>
<p><img alt="image-20250328144955900" src="../assets/image-20250328144955900.png" /></p>
<h6 id="direction-aware-weighted-a-algorithm">Direction-aware Weighted A*-Algorithm<a class="headerlink" href="#direction-aware-weighted-a-algorithm" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250328145457020" src="../assets/image-20250328145457020.png" /></p>
<h5 id="multi-stage-rip-up-rerouting">Multi-stage Rip-up &amp; Rerouting<a class="headerlink" href="#multi-stage-rip-up-rerouting" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250328160555252" src="../assets/image-20250328160555252.png" /></p>
<p><img alt="image-20250328160637121" src="../assets/image-20250328160637121.png" /></p>
<h5 id="data_16">data<a class="headerlink" href="#data_16" title="Permanent link">&para;</a></h5>
<p>ISPD18</p>
<h5 id="experiment_16">experiment<a class="headerlink" href="#experiment_16" title="Permanent link">&para;</a></h5>
<h4 id="dgr-dag-routing-forest2d-dac-2024-dp-cmunvida"><a href="https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/3649329.3656530">DGR-DAG Routing Forest+2D-DAC-2024-DP-CMU+NVIDA</a><a class="headerlink" href="#dgr-dag-routing-forest2d-dac-2024-dp-cmunvida" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="">OpenSource!</a></p>
</li>
<li>
<p>Directed Acyclic Graph (DAG)-based  </p>
</li>
<li>
<p>2D</p>
</li>
<li>
<p>基于 DP 的 Layer assignment</p>
</li>
<li>
<p>只是选择了更优的 Tree? 并且只是在这部分是 concurrent 的？通过牺牲额外的时间获取更好的 tree</p>
</li>
</ul>
<h5 id="backgroun">backgroun<a class="headerlink" href="#backgroun" title="Permanent link">&para;</a></h5>
<ul>
<li>sequential algorithms do not guarantee optimal solution among all nets because of its sequential heuristic. Moreover, its sequential heuristic falls short in addressing routing congestion from a global perspective, possibly leading to unnecessary iterations of rip-up and reroutes.   </li>
<li><mark>Combinatorial optimization techniques [4, 5]</mark> could concurrently optimize multiple nets. But they are often <mark>too slow</mark> for modern VLSI circuits  </li>
<li>concurrent 相比 sequencial 方法 在布线质量的优越性</li>
<li>以往 GPU-accelerate 工作其实本质还是 sequencial</li>
<li>1.Steiner tree 相同最短长度有多重拓扑</li>
</ul>
<h5 id="contribution_24">contribution<a class="headerlink" href="#contribution_24" title="Permanent link">&para;</a></h5>
<ul>
<li><code>concurrent optimization</code>  for hundreds of thousands of nets  </li>
<li>a routing DAG forest to represent the search space  </li>
<li>a GPU-accelerated  differentiable algorithm for scalable and efficient search within the DAG forest.   </li>
<li><code>Gumbel-Softmax</code> technique with <mark>temperature annealing</mark> and <mark>top-p selection</mark>  </li>
</ul>
<h5 id="flow_22">flow<a class="headerlink" href="#flow_22" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250310174115344" src="../assets/image-20250310174115344.png" /></p>
<h5 id="model_21">model<a class="headerlink" href="#model_21" title="Permanent link">&para;</a></h5>
<p>routing DAG forest  </p>
<p><img alt="image-20250310190910290" src="../assets/image-20250310190910290.png" /></p>
<p><img alt="image-20250310192646124" src="../assets/image-20250310192646124.png" /></p>
<p>updated through <code>back-propagation</code></p>
<h6 id="routing-dag-forest">Routing DAG Forest<a class="headerlink" href="#routing-dag-forest" title="Permanent link">&para;</a></h6>
<ul>
<li>a mathematical structure to systematically describe the 2D pattern routing space for all the nets.   </li>
<li>In contrast to CUGR2 [2], (which addresses one net at a time and focuses on a single Steiner tree topology in each instance,) our routing DAG forest allows <mark>multiple DAGs for each net</mark> and facilitates the coordination of DAG and DAG edge selection across all nets in a <mark>global view</mark>.  </li>
<li>The construction of the DAG forest has a direct impact on the runtime and quality of DGR outcome  </li>
<li>
<p>作为未来的一个方向，我们计划在必要时为拥挤地区的网络引入新的 DAG 和 DAG 边，探索森林的适应性扩展</p>
</li>
<li>
<p>Pattern Routing</p>
</li>
<li>
<p>The dynamic programming-based layer assignment  </p>
</li>
<li>
<p>he objective of 2D pattern routing is to select the best routing DAGs (routing trees) and DAG edges (2-pin paths) for all the nets such that the total wire length, number of vias, and routing overflow are minimized</p>
<p><img alt="image-20250310193043799" src="../assets/image-20250310193043799.png" /></p>
<p><img alt="image-20250310193049521" src="../assets/image-20250310193049521.png" /></p>
<p><img alt="image-20250310193100653" src="../assets/image-20250310193100653.png" /></p>
</li>
<li>
<p>Routing DAG Forest Construction  </p>
</li>
<li>
<p>Initially, multiple routing tree candidates are formulated for each net using <code>FLUTE</code>. Then, all L-shape pattern paths are enumerated for each 2-pin sub-net and incorporated into the pool as 2-pin path candidates. In the final step, each candidate will be associated with a probability, which is initialized <mark>randomly</mark>.  </p>
</li>
<li>its <mark>fine-tuned version</mark> by CUGR2, which <mark>moves Steiner points based on congestion</mark>.  </li>
<li>
<p>It’s worth noting that this is not restricted to just these two techniques; alternative routing tree generation algorithms, such as <code>SALT [15]</code> and <code>TreeNet [16]</code>, can seamlessly integrate their resulting trees as additional candidates.   </p>
</li>
<li>
<p>Continuous Relaxation and Cost Calculation</p>
</li>
</ul>
<p>cost = 500 × overflow_cost + 4 × via_cost + 0.5 × wirelength_cost  </p>
<p><img alt="image-20250310202209692" src="../assets/image-20250310202209692.png" /></p>
<p><img alt="image-20250310202234130" src="../assets/image-20250310202234130.png" /></p>
<ol>
<li>Differentiable Optimization  </li>
</ol>
<p><img alt="image-20250310203121207" src="../assets/image-20250310203121207.png" /></p>
<ul>
<li>
<p>gumbel_softmax function   </p>
<ul>
<li><img alt="image-20250310204941750" src="../assets/image-20250310204941750.png" /></li>
</ul>
<p><img alt="image-20250310204950851" src="../assets/image-20250310204950851.png" /></p>
<ol>
<li>
<p>Gumbel noise (𝑔𝑖)  </p>
<p>如果只是使用简单的 softmax 比如， softmax deterministically samples a probability distribution. This <mark>deterministic</mark> nature can inadvertently lead to <mark>local optima</mark>, especially when the probabilities have <mark>a bad initialization</mark>. <img alt="image-20250310205049767" src="../assets/image-20250310205049767.png" /></p>
<p>Gumbel 分布 <img alt="image-20250310204727025" src="../assets/image-20250310204727025.png" /> <img alt="image-20250310204734834" src="../assets/image-20250310204734834.png" /></p>
</li>
<li>
<p>temperature (𝑡)  </p>
<p>temperature annealing. It ensures that the final probabilities associated with routing tree candidates closely approximate either <mark>0 or 1</mark>  </p>
</li>
</ol>
</li>
<li>
<p>Deriving Discrete Selection  </p>
</li>
</ul>
<p>top-p sampling [18]  （什么东西？）</p>
<h5 id="data_17">data<a class="headerlink" href="#data_17" title="Permanent link">&para;</a></h5>
<p>Synthetic data is utilized for this experiment since the ISPD’18 and ISPD’19 benchmarks are too large for ILP  </p>
<p><img alt="image-20250310212008063" src="../assets/image-20250310212008063.png" /></p>
<h5 id="experiment_17">experiment<a class="headerlink" href="#experiment_17" title="Permanent link">&para;</a></h5>
<h6 id="ilp">与 ILP 方法的对比<a class="headerlink" href="#ilp" title="Permanent link">&para;</a></h6>
<p>见上图（data 中）</p>
<ol>
<li>compare result with CUGR2</li>
</ol>
<p><img alt="image-20250310212843028" src="../assets/image-20250310212843028.png" /></p>
<p>shows a superior routing quality on all testcases   </p>
<ol>
<li>compare result with other </li>
</ol>
<p><img alt="image-20250310213413575" src="../assets/image-20250310213413575.png" /></p>
<ol>
<li>cost function </li>
</ol>
<p><img alt="image-20250310213752149" src="../assets/image-20250310213752149.png" /></p>
<p>We can see that the selection of 𝑓 influences the result, especially overflow, significantly, and sigmoid is the best choice, which outperforms CUGR2  </p>
<p><img alt="image-20250310214059794" src="../assets/image-20250310214059794.png" /></p>
<p>DGR has slightly more runtime overhead than CUGR2 when the number of nets is less than one million, when the design complexity continues increasing, <mark>DGR becomes more efficient than CUGR2</mark>  </p>
<p>The memory result is given in Figure 5b, which shows that both CPU and GPU memory overhead is almost <mark>linear</mark> with the number of nets.  </p>
<h3 id="gr_adv_rl">GR_Adv_RL<a class="headerlink" href="#gr_adv_rl" title="Permanent link">&para;</a></h3>
<h4 id="-drl-method-2019-drl-"><a href="https://arxiv.org/pdf/1906.08809">-DRL method-2019-DRL-</a><a class="headerlink" href="#-drl-method-2019-drl-" title="Permanent link">&para;</a></h4>
<ul>
<li>first DRL related work?</li>
<li>RL framework: <code>DQN</code> </li>
<li>proves its overall performance is better than the sequential A∗ algorithm.   </li>
<li>This method falls short of practical benchmarks that can involve over 100,000 nets [26] </li>
<li>3D </li>
<li>have not use real world design</li>
</ul>
<h5 id="background_31">background<a class="headerlink" href="#background_31" title="Permanent link">&para;</a></h5>
<ul>
<li>Existing solutions typically consist of <code>greedy algorithms</code> and <code>hard-coded heuristics</code>.   </li>
<li>As such, existing approaches suffer from a <code>lack of model flexibility</code> and <code>non-optimum solutions</code></li>
<li>current solutions rely primarily on <mark>heuristically driven</mark> greedy methods  </li>
<li></li>
</ul>
<h5 id="contribution_25">contribution<a class="headerlink" href="#contribution_25" title="Permanent link">&para;</a></h5>
<ul>
<li>该生成器能够生成具有不同大小和约束的参数化全局路由问题集中，从而能够评估不同的路由算法，并为未来的数据驱动路由方法生成训练数据集。</li>
<li><mark>the first</mark> attempt to formulate and solve global routing as a deep reinforcement learning problem.   </li>
<li>It is noted however that our approach, similar to previous approaches, <mark>does not guarantee global optimum</mark>  </li>
<li>RL for a <mark>closed loop</mark> global routing solution  </li>
</ul>
<h5 id="flow_23">flow<a class="headerlink" href="#flow_23" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241114192055104" src="../assets/image-20241114192055104.png" /></p>
<p>A* is executed first in order to provide <code>burn-in memory</code> for the DQN solver  </p>
<p>using A* as burn-in for DRL allows DRL to converge much faster  </p>
<h5 id="model_22">model<a class="headerlink" href="#model_22" title="Permanent link">&para;</a></h5>
<p>example:</p>
<p>​   from A to B</p>
<p>​   read means over flow</p>
<p><img alt="image-20241114192638647" src="../assets/image-20241114192638647.png" /></p>
<p>Bold edges have zero capacity  </p>
<p><img alt="image-20241114193438871" src="../assets/image-20241114193438871.png" /></p>
<p><strong>state</strong>:</p>
<ul>
<li>(pos_x/y/z, distance_x/y/z, 周围的 capacity,  )这种编码方案可以被视为当前状态、导航和本地容量信息的混合</li>
</ul>
<p><strong>action</strong></p>
<p>上下左右前后</p>
<p><strong>reward</strong></p>
<p><img alt="image-20241114200225347" src="../assets/image-20241114200225347.png" /></p>
<p><img alt="image-20241114200512353" src="../assets/image-20241114200512353.png" /></p>
<h5 id="experiment_18">experiment<a class="headerlink" href="#experiment_18" title="Permanent link">&para;</a></h5>
<h6 id="env">env<a class="headerlink" href="#env" title="Permanent link">&para;</a></h6>
<ul>
<li>python</li>
</ul>
<h6 id="result">RESULT<a class="headerlink" href="#result" title="Permanent link">&para;</a></h6>
<p>参数选择也许可以借鉴一下大概量级</p>
<p><img alt="image-20250424174857561" src="../assets/image-20250424174857561.png" /></p>
<h4 id="alpha-pd-router-mcts-mlcad-2019-canada-ucalgary-gandhi"><a href="https://ieeexplore.ieee.org/document/9142109">Alpha PD Router-MCTS-MLCAD-2019- -Canada Ucalgary Gandhi</a><a class="headerlink" href="#alpha-pd-router-mcts-mlcad-2019-canada-ucalgary-gandhi" title="Permanent link">&para;</a></h4>
<ul>
<li>A Reinforcement Learning-Based Framework for Solving Physical Design Routing Problem in the Absence of Large Test Sets</li>
<li>相关硕士论文：<a href="https://ucalgary.scholaris.ca/server/api/core/bitstreams/870e141b-ac3f-4125-8b8a-f5f125bbcc52/content#page=102.20">Reinforcement Learning-Based Framework to Generate Routing Solutions and Correct Violations in VLSI Physical Design</a></li>
<li>based on a two-player collaborative game model  </li>
<li>The proposed model has the potential to be used as a framework to develop RL based routing techniques untethered by the scarce availability of large routing data samples or designer expertise.  </li>
<li><mark>two-player collaborative</mark> game rather than a multiplayer game problem  </li>
<li>inspired by <code>Alpha-Go Zero</code></li>
<li></li>
</ul>
<h5 id="background_32">background<a class="headerlink" href="#background_32" title="Permanent link">&para;</a></h5>
<h2 id="-the-lack-of-a-large-number-of-test-cases-has-been-a-significant-hindrance-to-obtaining-high-quality-results-the-only-design-benchmark-test-sets-that-are-available-to-academics-are-the-ispd-2018-and-ispd-2019-benchmarks-which-in-total-have-27-circuits-21-22">- the lack of a large number of test cases has been a significant hindrance to obtaining high-quality results, the only design benchmark test sets that are available to academics are the ISPD 2018 and ISPD 2019 benchmarks which in total have 27 circuits [21] [22]<a class="headerlink" href="#-the-lack-of-a-large-number-of-test-cases-has-been-a-significant-hindrance-to-obtaining-high-quality-results-the-only-design-benchmark-test-sets-that-are-available-to-academics-are-the-ispd-2018-and-ispd-2019-benchmarks-which-in-total-have-27-circuits-21-22" title="Permanent link">&para;</a></h2>
<h5 id="contribution_26">contribution<a class="headerlink" href="#contribution_26" title="Permanent link">&para;</a></h5>
<ul>
<li>Development of a reinforcement model for routing  and RRR</li>
<li>Designing a collaborative game-theory model  </li>
</ul>
<h5 id="flow_24">flow<a class="headerlink" href="#flow_24" title="Permanent link">&para;</a></h5>
<h5 id="model_23">model<a class="headerlink" href="#model_23" title="Permanent link">&para;</a></h5>
<h6 id="two-player">two-player<a class="headerlink" href="#two-player" title="Permanent link">&para;</a></h6>
<p>two players have different strategies and reward    </p>
<ul>
<li>
<p><code>Cleaner</code> </p>
</li>
<li>
<p>which detects design rule violations, selects the best net to rip to fix the violation and rips it  </p>
</li>
<li><img alt="image-20250424125223907" src="../assets/image-20250424125223907.png" /></li>
<li><img alt="image-20250424125230654" src="../assets/image-20250424125230654.png" /></li>
<li>The Cleaner rips all the possible net candidates <mark>one by one</mark> and sends them to be re-routed by the Router.   (那就慢了)</li>
<li>
<p>With each re-route, the Router issues a reward to inform Cleaner how good its job was from the Router’s perspective. Cleaner aims to maximize these rewards by ripping the nets that make the Router’s job easier.   </p>
</li>
<li>
<p><code>Router</code> </p>
</li>
<li>
<p>who performs routing. Router employs a path search algorithm such as A-star  </p>
</li>
<li>
<p>is responsible for re-routing the ripped nets without producing any new violations  </p>
</li>
<li>
<p>The solution from the Cleaner is given to the Router. This solution is a partially routed circuit. </p>
<p><img alt="image-20250424125149440" src="../assets/image-20250424125149440.png" /></p>
</li>
<li>
<p>The move prediction in Router is optimized by the feedback from the MCTS algorithm to the neural network (NNET) architecture.   </p>
</li>
</ul>
<p>If no violations exists and all the nets are routed, both Router and Cleaner win and a design rule violation free solution is produced.   </p>
<h6 id="min-max-game-framework">Min-max Game Framework<a class="headerlink" href="#min-max-game-framework" title="Permanent link">&para;</a></h6>
<p>这个是什么？不清楚[34-36]</p>
<p>this formulation allows us to cast the routing problem into a potentially tractable two-player game rather than a huge multiplayer game where the players count equals the number of nets (e.g. millions).  </p>
<h6 id="experiment_19">experiment<a class="headerlink" href="#experiment_19" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250424130402737" src="../assets/image-20250424130402737.png" /></p>
<h4 id="-quasi-newton-method-arxiv-2021-double-dqn-jp"><a href="https://arxiv.org/pdf/2010.09465">-quasi-Newton method  -arxiv-2021-Double DQN-JP</a><a class="headerlink" href="#-quasi-newton-method-arxiv-2021-double-dqn-jp" title="Permanent link">&para;</a></h4>
<ul>
<li>accelerate the training of deep Q-networks  by introducing a second order Nesterov’s accelerated quasi-Newton method</li>
<li>这篇可以说是一个二阶优化器在GR上的应用</li>
<li>基于<a href="">arxiv-2019</a>那篇</li>
</ul>
<h5 id="background_33">background<a class="headerlink" href="#background_33" title="Permanent link">&para;</a></h5>
<ul>
<li>why DRL: As the state and action space of the problem increases, the estimation of the state-action value can be slow and time consuming and hence estimated as a function approximation.   These function approximations can be represented as a non-convex, non-linear unconstrained optimization problem and can be solved using deep neural networks (known as deep Q-networks).  </li>
<li>Using <mark>second order curvature information</mark> have shown to improve the performance and convergence speed for non convex optimization problems   </li>
<li>Adam, RMSprop 都是一阶的</li>
<li>BFGS  是一阶的</li>
<li>Nesterov’s accelerated quasi-Newton (NAQ) method [5] was shown to accelerate the BFGS method using the Nesterov’s accelerated gradient term.  </li>
<li>Why RL: Conventional routing automation tools are usually based on analytical and path search algorithms which are NP complete. Hence a machine learning approach would be more suitable for this kind of automation problem.  Studies that propose AI techniques such as machine learning, deep learning, genetic algorithms deal with only prediction of routability, short violations, pin-access violations, etc. Moreover, the nonavailability of large labelled training datasets for a supervised learning model is another challenge.  </li>
</ul>
<h4 id="-steiner-point-ispd-2022-monte-carlo-nymctu-"><a href="">-Steiner point-ISPD-2022-Monte Carlo-NYMCTU-</a><a class="headerlink" href="#-steiner-point-ispd-2022-monte-carlo-nymctu-" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>这篇感觉没有在GR上的应用场景</p>
</li>
<li>
<p>OARSMT(Obstacle-Avoiding Rectilinear Steiner Tree)</p>
</li>
</ul>
<p>The input of the OARSMT problem is a set of pins and a set of obstacles on a routing plane. The objective of the OARSMT problem is to find a minimum-length Steiner tree  that connects all the pins following the grids of the routing plane while not crossing any obstacle  </p>
<ul>
<li>
<p>an OARSMT algorithm represented by an agent can be automatically developed and continually improved by itself  </p>
</li>
<li>
<p>basicline: RL framework:<code>[13]</code>  (policy-based ), trained by Monte Carlo tree search (MCTS) [14] + UCT formula [15]</p>
</li>
<li>
<p>state-of-the-art OARSMT algorithm [7], [8]  </p>
</li>
<li>
<p>our developed OARSMT router can be viewed as a policy neural network that can keep on <mark>evolving</mark> by applying itself to more unseen layouts, as opposed to a conventional OARSMT algorithm built with <mark>fixed rules predetermined by humans.</mark>  </p>
</li>
<li>
<p>Curriculum learning [16]: the convergence of the agent can be speeded up and the quality of selected Steiner points can be improved  </p>
</li>
<li>
<p>Sequence version: for a layout with n pins, the policy neural network needs to be inferenced for <mark>n-2 times</mark> sequentially to obtain all <mark>n-2 Steiner points.</mark> In our framework, once the initial sequential agent is trained  </p>
</li>
</ul>
<h5 id="background_34">background<a class="headerlink" href="#background_34" title="Permanent link">&para;</a></h5>
<ul>
<li>Recent related works on OARSMT [2-11] can be classified into the following four types of methods:   </li>
<li><mark>spanning-graph-based</mark> method [2-5], which builds a routing tree based on a spanning graph containing all pins and corners of obstacles;   </li>
<li><mark>Steiner point-based</mark> method [6-8], which focuses on selecting proper Steiner points</li>
<li><mark>lookup-table-based</mark> method [9], which extends the lookup-table method for rectilinear Steiner tree to further handle obstacles    </li>
<li><mark>exact-algorithm-based</mark> method [10,11], which applies the concept of <code>GeoSteiner</code> [12] and further reduce the numbers of full Steiner trees and obstacles to be handled</li>
<li>a layout with n pins needs at most n-2 Steiner points  </li>
</ul>
<h5 id="flow_25">flow<a class="headerlink" href="#flow_25" title="Permanent link">&para;</a></h5>
<p>this work focus on first step, step 2 use [8]</p>
<ul>
<li>two-stage process  </li>
<li>selecting an optimal set of Steiner points, which is still NP-complete  </li>
<li>constructing the actual routing tree by finding an obstacle-avoiding rectilinear minimum spanning tree (OARMST) connecting all the pins and selected Steiner points, which can be done in <mark>polynomial time</mark> as shown in [6-8]  <ul>
<li>The job of the agent here is to find an optimal set of Steiner points, which is done by iteratively selecting the best next Steiner point based on the current state, i.e., the layout of the pins, obstacles and already selected Steiner points. </li>
</ul>
</li>
</ul>
<h5 id="model_24">model<a class="headerlink" href="#model_24" title="Permanent link">&para;</a></h5>
<h6 id="state">state<a class="headerlink" href="#state" title="Permanent link">&para;</a></h6>
<p>$H \times V \times 3$ binary array in grid graph</p>
<ul>
<li>whether the vertex is a pin  </li>
<li>a selected Steiner point </li>
<li>covered by an obstacle   </li>
</ul>
<p>The input of our policy agent</p>
<h6 id="action">action<a class="headerlink" href="#action" title="Permanent link">&para;</a></h6>
<p>add a Steiner point at a vertex  </p>
<h6 id="reward">reward<a class="headerlink" href="#reward" title="Permanent link">&para;</a></h6>
<h6 id="mcts">MCTS<a class="headerlink" href="#mcts" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250424101448483" src="../assets/image-20250424101448483.png" /></p>
<p><img alt="image-20250424101517025" src="../assets/image-20250424101517025.png" /></p>
<h5 id="data_18">data<a class="headerlink" href="#data_18" title="Permanent link">&para;</a></h5>
<p>15x15 and 30x30 grids,  </p>
<h5 id="experiment_20">experiment<a class="headerlink" href="#experiment_20" title="Permanent link">&para;</a></h5>
<h4 id="-wcmc-2023-drl-fuzhouu-genggeng-liu"><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1155/2023/6593938">- -WCMC-2023-DRL-FuZhouU-Genggeng Liu</a><a class="headerlink" href="#-wcmc-2023-drl-fuzhouu-genggeng-liu" title="Permanent link">&para;</a></h4>
<ul>
<li>most of the existing methods are heuristic algorithms, which cannot conjointly optimize the subproblems of global routing, resulting in congestion and overflow  </li>
<li>DRL 和 RL 的区别：RL often faces the problem of the excessive number of states when dealing with high-dimensional spaces. With the development of deep learning, the Deep Reinforcement Learning (DRL) algorithm is developed by combining artificial neural networks with RL [10], which makes it possible for RL to solve the policy decision in a high-dimensional space   </li>
<li></li>
</ul>
<h5 id="background_35">background<a class="headerlink" href="#background_35" title="Permanent link">&para;</a></h5>
<ul>
<li>this paper takes the overflow as the main design goal and optimizes the wire length and congestion based on the overflow as 0.  </li>
<li><code>Serial routing</code> usually sorts nets in a specific order and routes them one by one; <mark>this method is fast</mark>（相对并行组合优化的方法？）. However, there is an unfair phenomenon: the routing difficulty of the earlier nets has sufficient routing resources (meaning that the capacity of each edge in the routing area is large), while most of the later nets have tight routing resources, so the serial routing method usually rips up part of the nets and reroutes them  </li>
<li>The <code>parallel method</code> routes multiple nets at the same time [21], solving the unfairness of routing resources in a serial method, but it is <mark>often very time-consuming and even impossible to solve</mark>, mainly based on the commodity flow model [22] and <mark>integer linear programming</mark> model [23]  </li>
</ul>
<h5 id="contribution_27">contribution<a class="headerlink" href="#contribution_27" title="Permanent link">&para;</a></h5>
<ul>
<li>use DDQN instead of DQN</li>
<li>an action reduction method  </li>
<li>a concurrent training method   </li>
<li>solve the unfair resource allocation problem  </li>
<li>a new reward function  </li>
</ul>
<h5 id="model_25">model<a class="headerlink" href="#model_25" title="Permanent link">&para;</a></h5>
<p>输入 state：a 15-bit code is used; the starting point, the ending point, and the agent’s position are all represented by a 3-bit code; and a 6-bit code represents the edge capacities in six directions  </p>
<p>输出 action：action-value of 6 directions. 但是由于每层有优先方向，所以实际上最多 4 个。需要在代理选择动作时，首先消除无法执行的动作，以防止代理在训练过程中执行冗余动作，存储冗余经验，然后学习冗余信息。</p>
<p>reward:</p>
<p><img alt="image-20250224230102150" src="../assets/image-20250224230102150.png" /></p>
<p>If ed is higher than ec/2, a reward r &lt; 0  is given; otherwise, a reward  r ≥ 0 will be given.  （他公式是不是错了？）</p>
<p>uses a heuristic algorithm to search for the path in advance and burn it into the experience replay buffer  （类似预训练）convergence speedup</p>
<p><img alt="image-20250224224528028" src="../assets/image-20250224224528028.png" /></p>
<h4 id="-drlsegment-based-iseda-2023-drlgnn-pek"><a href="https://ieeexplore.ieee.org/abstract/document/10218371">-DRL+segment based-ISEDA-2023-DRL+GNN-PEK</a><a class="headerlink" href="#-drlsegment-based-iseda-2023-drlgnn-pek" title="Permanent link">&para;</a></h4>
<ul>
<li>DRL(GAT)</li>
<li>segment-based feature extraction  </li>
<li>pattern routing  enhance</li>
<li></li>
</ul>
<p><strong>enhance:</strong></p>
<ul>
<li>3d?</li>
<li>加上 GCELL 之间的连接？</li>
<li>像 InstantGR 做一些水平垂直分层的操作？</li>
<li>capacity 放边上</li>
</ul>
<h5 id="background_36">background<a class="headerlink" href="#background_36" title="Permanent link">&para;</a></h5>
<ul>
<li>many traditional global routing methods lack learning ability.  </li>
<li>more and more problems in physical design are searching for automated solutions based on machine learning. One popular application is to adopt machine learning to help early prediction  </li>
<li></li>
</ul>
<h5 id="contribution_28">contribution<a class="headerlink" href="#contribution_28" title="Permanent link">&para;</a></h5>
<ul>
<li>congestion-aware reinforcement learning model  </li>
<li>Integrating pattern routing with reinforcement learning  </li>
<li>Proposing a net segment mode  </li>
</ul>
<h5 id="flow_26">flow<a class="headerlink" href="#flow_26" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250221235557954" src="../assets/image-20250221235557954.png" /></p>
<p><strong>model:</strong></p>
<ul>
<li>GNN feature</li>
<li>Node embedding.  </li>
<li>Pin number.</li>
<li>Fly line number.  </li>
<li>Capacity value</li>
<li>Bounding box number.   </li>
<li>
<p>Position correlation.  </p>
</li>
<li>
<p>DRL(A3C)</p>
</li>
<li>We set the policy network as a fully connected layer with 200 neurons and the value network as a fully connected layer with 100 neurons.</li>
<li>Feature  of net segments<ul>
<li>Net density value</li>
<li>Congestion prediction value</li>
<li>Capacity ratio value</li>
</ul>
</li>
</ul>
<h5 id="data_19">data<a class="headerlink" href="#data_19" title="Permanent link">&para;</a></h5>
<p>ISPD18 benchmark  </p>
<h5 id="experiment_21">experiment<a class="headerlink" href="#experiment_21" title="Permanent link">&para;</a></h5>
<p><strong>question:</strong></p>
<ul>
<li>原文没说 prediction model 的 label 是什么</li>
<li>RL 怎么做并行？具体是怎么样的，不熟</li>
</ul>
<h4 id="-apccas-2024-drlddqn-cycu"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10808325">- -APCCAS-2024-DRL(DDQN)-CYCU</a><a class="headerlink" href="#-apccas-2024-drlddqn-cycu" title="Permanent link">&para;</a></h4>
<ul>
<li>DRL-based A* search algorithm</li>
<li>没有 pattern routing 的环节</li>
<li>就是 19 年那一篇，把 DQN 改成 DDQN</li>
<li>俗文</li>
</ul>
<h5 id="background_37">background<a class="headerlink" href="#background_37" title="Permanent link">&para;</a></h5>
<ul>
<li>aim to find better solutions to minimize total wire length (WL) and edge overflow (OF)  </li>
<li>current solutions mainly rely on heuristic-driven greedy methods, which primarily address situations with strict constraints on the problems to be solved, such as sequential network routing after network sorting [2].   </li>
<li>The A* algorithm is based on heuristic search, using a heuristic function to estimate the minimum cost from the current node to the target node. It can be used to find the shortest path from the starting point to the target pin.   </li>
<li></li>
</ul>
<h4 id="rl-ripper-rrr-glsvlsi-2023-canada-ucalgary-gandhi"><a href="">RL Ripper-RRR-GLSVLSI-2023- -Canada Ucalgary Gandhi</a><a class="headerlink" href="#rl-ripper-rrr-glsvlsi-2023-canada-ucalgary-gandhi" title="Permanent link">&para;</a></h4>
<ul>
<li>In this work[8], an RL agent to rip up nets was trained. The benchmark circuits used in this work were taken from the International Conference on Computer-aided Design [33]. However, only training results were provided, highlighting a gap in the literature regarding the scale of benchmarks and the specific problems addressed in proof-of-concept scenarios.  --cite--&gt; <a href="">RL Ripper 2.0</a></li>
</ul>
<h4 id="rl-ripper-20-rrrvios-opt-transtodaes-2024-canada-ucalgary-gandhi"><a href="">RL Ripper 2.0-RRR&amp;VIOs Opt-Trans(TODAES)-2024- -Canada Ucalgary Gandhi</a><a class="headerlink" href="#rl-ripper-20-rrrvios-opt-transtodaes-2024-canada-ucalgary-gandhi" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>incorporates a self-learning model called <code>RL-Ripper</code>  </p>
</li>
<li>
<p><a href="https://doi.org/10.1145/3583781.3590312">previous work</a> </p>
</li>
<li>
<p>compared to the state-of-the-art global router <code>CUGR</code>  </p>
</li>
<li>
<p>Key point: reduce short violations  </p>
</li>
<li>
<p>can be replicated for newer technologies  </p>
</li>
<li>
<p>用了大电路</p>
</li>
<li>
<p>没开源, 可太可惜了</p>
</li>
<li>
<p>感觉只能算一个CUGR的优化</p>
</li>
<li>
<p>RL model:<code>A2C</code> and <code>DQN</code>, </p>
</li>
<li>
<p>有一个发现：复杂的大电路要用DQN<img alt="image-20250424193153789" src="../assets/image-20250424193153789.png" /></p>
</li>
<li><img src="assets/image-20250424195605026.png" alt="image-20250424195605026" style="zoom: 67%;" /><img src="assets/image-20250424195614246.png" alt="image-20250424195614246" style="zoom:67%;" /></li>
<li>基于<code>OpenAI Gym</code>库</li>
</ul>
<h5 id="background_38">background<a class="headerlink" href="#background_38" title="Permanent link">&para;</a></h5>
<ul>
<li>Why RL: heuristic solutions are not adaptable to the ever-changing fabrication demands, and the experience and creativity of designers can limit their effectiveness.   Reinforcement learning (RL) is an effective method to tackle sequential optimization problems due to its ability to adapt and learn through <code>trial and error</code>.   </li>
<li>for net with overflow, the most generic RRR method is to rip all nets with short violations and reroute them. However, this heuristic is not the most efficient way since short violations can highly depend on the respective net routes and the order in which they are ripped and rerouted.  </li>
<li>After the first iteration of sequential routing, all the nets causing violations are ripped and re-routed. This can result in several RRR iterations. Furthermore, ripping all the nets can be unnecessary if a net’s route is already optimized. Hence, an intelligent ripping algorithm that pairs well with the order of nets and helps to reduce overall RRR cost is needed.  </li>
</ul>
<h5 id="contribution_29">contribution<a class="headerlink" href="#contribution_29" title="Permanent link">&para;</a></h5>
<ul>
<li>RL-Ripper Framework  </li>
<li>a self-learning Ripper agent that relies <mark>solely on net features</mark>  </li>
<li>
<p>eliminating the need for externally labeled data  </p>
</li>
<li>
<p>Evaluation on Large-scale Academic Benchmarks  </p>
</li>
<li>
<p>以前的RLGR确实都是实验性质的小电路</p>
</li>
<li>
<p>Pervasive AI Framework</p>
</li>
<li>
<p>fosters collaboration between traditional physical design algorithms (typically coded in <code>C++</code>) and machine learning algorithms developed in <code>Python</code>.  </p>
</li>
<li>
<p>enabling real-time feature extraction without the overhead associated with file read-write operations, such as pickle data exchange</p>
</li>
<li>
<p>基于<code>Gym</code>  的<code>ZMQ client</code>  interface  </p>
<p><img alt="image-20250424194943213" src="../assets/image-20250424194943213.png" /></p>
</li>
</ul>
<h5 id="flow_27">flow<a class="headerlink" href="#flow_27" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250424185400749" src="../assets/image-20250424185400749.png" /></p>
<p>(1) We set the number of total training episodes as N , and the current episode, n, is initialized to 0. </p>
<p>(2) We obtain initial routing, using the pattern routing generated by CUGR [24]. </p>
<p>(3) We save the routes under the name <code>route-Orig</code>.</p>
<p>(4) We calculate the number of violations from the routed nets and store the results as <code>cur_V</code>  </p>
<p>(5), nets that are <mark>predicted</mark> to have routing violations due to congestion are sorted in a particular sequence. We will elaborate on this sequence in Section 3.2.</p>
<p>(6), we select the top net in the ordered list of nets with violations <code>xi</code>, where i indexes the nets with violations.</p>
<p>(7), the RL engine generated <mark>one of the two possible actions</mark> <code>Rip</code> or <code>NotRip</code> based on the features of the nets  </p>
<p>(8), the Net <code>xi</code> goes through RRR. </p>
<p>(9), the total number of nets with violations is recalculated (<code>new_V</code>). </p>
<p>(10), an <code>“if”</code> condition is processed to examine if the action a is <code>Rip</code>  </p>
<p>(11), if the action is a <code>Rip</code> action, the net is ripped and re-routed. Based on the new route, a reward is calculated based on <code>Algorithm 1</code>.</p>
<p>(12), if the action is <code>NotRip</code>, the net is still ripped and re-routed. The reward is recalculated based on the <code>NotRip</code> action from <code>Algorithm 1</code>. </p>
<p>(13), we set the routing of xi to that of the initial routing of <code>route-Orig</code>. </p>
<p>(14), the weights of the neural networks are updated. </p>
<p>(15), the condition is checked to see if all the nets are considered </p>
<p>(16), to process the next net. </p>
<p>(17), Otherwise, the flow goes to the next <code>episode</code></p>
<h5 id="model_26">model<a class="headerlink" href="#model_26" title="Permanent link">&para;</a></h5>
<h6 id="state-five-net-feature">State： five net feature:<a class="headerlink" href="#state-five-net-feature" title="Permanent link">&para;</a></h6>
<ol>
<li>HPWL</li>
<li>VIOs </li>
<li>calculated by CUGR's pattern routing</li>
<li>VIAs</li>
<li>calculated by CUGR's pattern routing</li>
<li>
<h1 id="pins">Pins<a class="headerlink" href="#pins" title="Permanent link">&para;</a></h1>
</li>
<li>WL</li>
<li>calculated by CUGR's pattern routing</li>
</ol>
<h6 id="action_1">Action<a class="headerlink" href="#action_1" title="Permanent link">&para;</a></h6>
<ul>
<li><code>Rip</code></li>
<li><code>NotRip</code>  </li>
</ul>
<h6 id="reward_1">Reward<a class="headerlink" href="#reward_1" title="Permanent link">&para;</a></h6>
<ul>
<li>based on the number of violations resolved by ripping and re-routing nets  </li>
</ul>
<p><img alt="image-20250424194258453" src="../assets/image-20250424194258453.png" /></p>
<h5 id="data_20">data<a class="headerlink" href="#data_20" title="Permanent link">&para;</a></h5>
<p>ISPD'18</p>
<ul>
<li>S-set: fewer than 100k cell, (design 1-5)</li>
<li>L-set: otherwise</li>
</ul>
<p><img alt="image-20250424195239651" src="../assets/image-20250424195239651.png" /></p>
<h5 id="experiment_22">experiment<a class="headerlink" href="#experiment_22" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250424195528062" src="../assets/image-20250424195528062.png" /></p>
<blockquote>
<p>全都只是3次迭代？多一些可能更能让人信服</p>
</blockquote>
<p>主要工作：</p>
<p><img alt="image-20250424200750987" src="../assets/image-20250424200750987.png" /></p>
<blockquote>
<p>这里的violation指的是overflow吗？</p>
</blockquote>
<p>效果明显！</p>
<p><img alt="image-20250424200718389" src="../assets/image-20250424200718389.png" /></p>
<p>可视化:</p>
<p><img src="assets/image-20250424202040169.png" alt="image-20250424202040169" style="zoom:50%;" /><img src="assets/image-20250424202103782.png" alt="image-20250424202103782" style="zoom:50%;" /></p>
<p>Detailed Routing.</p>
<p><img alt="image-20250424201637529" src="../assets/image-20250424201637529.png" /></p>
<p><img alt="image-20250424201916241" src="../assets/image-20250424201916241.png" /></p>
<p><img alt="image-20250424202124557" src="../assets/image-20250424202124557.png" /></p>
<h3 id="gr_adv_gen">GR_Adv_Gen<a class="headerlink" href="#gr_adv_gen" title="Permanent link">&para;</a></h3>
<h4 id="-generative-arxiv-2019-cnn-"><a href="https://arxiv.org/pdf/1706.08948">-generative-arXiv-2019-CNN-</a><a class="headerlink" href="#-generative-arxiv-2019-cnn-" title="Permanent link">&para;</a></h4>
<ul>
<li>first CNN</li>
</ul>
<h4 id="-only-cnn-dac-2020-cnnvae-"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=9218598">-only CNN-DAC-2020-CNN(VAE)-</a><a class="headerlink" href="#-only-cnn-dac-2020-cnnvae-" title="Permanent link">&para;</a></h4>
<ul>
<li>no experiment!</li>
<li>只用 CNN 分类结果不会好吧</li>
<li>不知道是什么类型的文章，只用了两页</li>
<li>evaluates its router on parts of the nets from a public benchmark layout and achieves 96.8% of routability  </li>
<li>it seems that the router can only route two- and three-pin nets, which may have some limitations for application.   </li>
</ul>
<h5 id="background_39">background<a class="headerlink" href="#background_39" title="Permanent link">&para;</a></h5>
<h2 id="-is-approach-treats-the-global-routing-problem-as-an-image-processing-problem-and-solves-it-with-a-deep-learning-system">- is approach treats the global routing problem as an <strong>image processing</strong> problem and solves it with a deep learning system<a class="headerlink" href="#-is-approach-treats-the-global-routing-problem-as-an-image-processing-problem-and-solves-it-with-a-deep-learning-system" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241114161657070" src="../assets/image-20241114161657070.png" /></p>
<h5 id="data_21">data<a class="headerlink" href="#data_21" title="Permanent link">&para;</a></h5>
<p>ISPD’98 ibm01 64x64 circuit  </p>
<h5 id="model_27">model<a class="headerlink" href="#model_27" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241114162111775" src="../assets/image-20241114162111775.png" /></p>
<h4 id="prnet-neurips-2022-sjtunoahs-ark"><a href="">PRNet- -NeurIPS-2022- -SJTU+Noah’s Ark</a><a class="headerlink" href="#prnet-neurips-2022-sjtunoahs-ark" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>PRNet can generate each route in <code>one-shot</code> but <strong>cannot guarantee connectivity</strong> which requires considerable <code>post-processing</code> for failed routes </p>
</li>
<li>
<p>HubRouter 是两阶段框架，PRNet 是端到端框架。 </p>
</li>
<li>
<p>the shortest RST like Fig. 1f generated by HubRouter [8] is not practically usable  --cite--&gt; NeuralSteiner  </p>
</li>
</ul>
<p><img alt="image-20250324192922713" src="../assets/image-20250324192922713.png" /></p>
<ul>
<li></li>
</ul>
<h4 id="hubrouter-generative-model-neurips-2023-ganrl-sjtu"><a href="">HubRouter-generative model-NeurIPS-2023-GAN+RL-SJTU</a><a class="headerlink" href="#hubrouter-generative-model-neurips-2023-ganrl-sjtu" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/Thinklab-SJTU/EDA-AI/tree/main/HubRouter">open source!</a></li>
<li><a href="https://picrew.github.io/2024/03/10/HubRouter/">a chinese interpretation</a></li>
<li>a global routing solver that includes a two-phase learning framework</li>
<li>HubRouter 是两阶段框架，PRNet 是端到端框架。</li>
<li>对比 PRNet 生成模型，PRNet 在 CGAN 中使用双向映射将连接约束注入训练目标，将准确率提高了 10%，但在复杂情况下几乎无效。</li>
<li>clipping all images to the same scale 64 × 64  </li>
</ul>
<h5 id="background_40">background<a class="headerlink" href="#background_40" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250210234157942" src="../assets/image-20250210234157942.png" /></p>
<ul>
<li>全局布线(Global Routing - GR)是 VLSI 设计中最复杂且最耗时的组合问题之一。GR 目标是总线长最小，同时避免拥塞(Congestion)，是个 NP 问题。</li>
</ul>
<p>传统采用启发式算法，多样性和规模问题对传统算法有了挑战，机器学习(ML)已经用于全局布线，在芯片设计中从逻辑合成到布局</p>
<ul>
<li>
<p>深度强化学习(Deep Reinforcement Learning - DRL )和生成式模型(Generative model)已经被用来解决全局布线。问题在于，<strong>DRL 很受状态空间(State Space)影响，随着网格空间增大，需要花费大量时间生成</strong>。However, DRL methods suffer from large state space and often need to spend enormous time on generating routes as the scale of grids increases on the test instance, i.e., the netlist, which is practically intimidating for real-world global routing  </p>
</li>
<li>
<p>相反，生成式模型有 <strong>一次性生成能力</strong>，在计算上更容易处理。</p>
</li>
<li>
<p>生成式方法在训练时候考虑连通性限制，确保布线满足电路连通性要求。但是问题在于，如果初始生成路径不满足连通性要求时候，后处理阶段会变成一种穷举搜索过程。</p>
</li>
<li>
<p><img alt="image-20250210231714841" src="../assets/image-20250210231714841.png" /></p>
</li>
<li>
<p>图一这里上图表示原始布线，下图表示算法生成的布线，生成布线没有正确连接所有应该连接的点(pin)，对于这样的情况，平均连通率很低，低于 20%，意味着超过 80%的生成布线需要经过耗时的后处理才能达到要求。显著的缺点。其实就和 <a href="# [-only CNN-DAC-2020-CNN(VAE)-](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp =&amp;arnumber = 9218598)">CNN-based</a>这篇一样</p>
</li>
<li>
<p><img alt="image-20250210233812834" src="../assets/image-20250210233812834.png" /></p>
</li>
</ul>
<h5 id="contribution_30">contribution<a class="headerlink" href="#contribution_30" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>为了解决上述问题，定义了一个新的概念，叫 <code>hub</code>。将 pin - pin 问题 --&gt; hub - pin 问题 。</p>
</li>
<li>
<p>提出了一种新的两阶段全局布线方法 --&gt; HubRouter</p>
</li>
<li>
<p>generation phase（生成阶段）</p>
<p><code>hubs</code>, <code>routes</code>, and <code>stripe masks</code> are together generated under a multi-task framework by generative models  </p>
<p>可以在多个框架下生成，比如 GAN (Generative Adversarial Nets) , VAE (Variational Auto-Encoder) , DPM (Diffusion Probabilistic Models) 。虽然 hub 是生成阶段的主要输出，但为了提升生成质量和准确性，发现生成附加信息是非常有用的。比如感知和掩码(<code>local perception</code> and <code>stripe masks</code>)，能够去除噪声点。引入 <code>多任务学习</code>，布线和掩码一起生成，提高 hub 生成质量</p>
</li>
<li>
<p>pin-hub-connection phase（hub 和 pin 连接阶段）</p>
<p>将连接视为 <code>最小斯坦纳树(RSMT)</code> 问题，使用 <code>actor-critic</code> 模型网络策略。</p>
<p>is hub generate correcttly, reconstruction time complexity can be reduced to <strong>O(n log n)</strong>  </p>
</li>
<li>
<p>SOTA generative global routing models  </p>
</li>
</ul>
<p><strong>model:</strong></p>
<p><img alt="image-20250210234537382" src="../assets/image-20250210234537382.png" /></p>
<ul>
<li>Hub</li>
</ul>
<p><img alt="image-20250212194312475" src="../assets/image-20250212194312475.png" /></p>
<ul>
<li>(virtual) key point in the route  </li>
<li>transferring the pin-pin connection problem to the hub-pin connection problem</li>
<li>斯坦纳点(Rectilinear Steiner Point --&gt; RSP)是搜索全局最小总距离，但是 hub 是来确定路径。RSPs are special cases of hubs  </li>
<li>RSP 是 Hub 的特例，Hub 可以随意生成不同形状的路径(不仅是最短的)</li>
<li>这里的 <code>c</code> 和 <code>x</code> 分别代表条件图像和输入图像。条件图像可能包括引脚位置、已经提取的中心点以及条带掩模（stripe mask）。条带掩模是用来指示布线区域的一种方式，它可以帮助模型更好地理解哪些区域可以用于布线</li>
<li></li>
</ul>
<h5 id="flow_28">flow<a class="headerlink" href="#flow_28" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250212201906601" src="../assets/image-20250212201906601.png" /></p>
<ul>
<li>
<p>hub 生成阶段</p>
</li>
<li>
<p>Hub 生成可以表示为图像到图像的 <code>multi-task learning framework</code>   任务, address the impact of sensitive <strong>noise</strong> points with stripe <code>mask learning</code>  </p>
</li>
<li>
<p><code>附录 B</code> 介绍了将 GAN，VAE，EAN 纳入到生成框架</p>
</li>
<li>
<p>在这个阶段，模型旨在逼近条件分布 <code>pθ(x|z, c)</code> 使其接近先验分布 <code>p(x|c)</code>。给定条件 <code>c</code> 和从先验分布 <code>pz(z)</code> 中采样得到的潜在变量 <code>z</code>（通常假设为 <strong>高斯分布</strong>），模型会生成一些“中心点（hubs）”. 这里的 <code>c</code> 和 <code>x</code> 分别代表条件图像和输入图像。z is a latent variable from a prior distribution   </p>
</li>
<li>
<p>The main objective of hub generation is to minimize the difference between probability distributions  <code>p(x|c)</code> and <code>pθ(x|z, c)</code></p>
</li>
<li>
<p>a noise hub, especially the outermost one, can largely harm the wirelength of routing. Use <code>stripe mask</code> to focus on bad cases for hub generation  </p>
<p><img alt="image-20250212202848907" src="../assets/image-20250212202848907.png" /></p>
</li>
<li>
<p>hub 和 pin 连接阶段</p>
</li>
<li>
<p>模型连接第一阶段生成的 <strong>中心点</strong>，以获得最终的布线路由。这个过程可以被视为构建矩形稳定最小生成树（Rectilinear Steiner Minimum Tree，RSMT）的一部分。为了完成布线，模型遵循了一个基于强化学习（Reinforcement Learning，RL）的算法 <code>REST</code>。</p>
</li>
<li>在两阶段的过程中，作者还提出了一个 <code>多任务学习框架</code> 来提高生成中心点的质量。特别是，提出了一种新颖的 <code>条带掩模学习方法</code>，旨在减轻噪声点案例可能造成的负面影响。算法的具体细节在 <code>附录 B</code> 中给出。</li>
</ul>
<h4 id="neural-steiner-ai-for-steiner-neurips-2024-chinese-academy-of-sciences-cnn"><a href="">Neural Steiner-AI for Steiner-NeurIPS-2024-Chinese Academy of Sciences-CNN</a><a class="headerlink" href="#neural-steiner-ai-for-steiner-neurips-2024-chinese-academy-of-sciences-cnn" title="Permanent link">&para;</a></h4>
<h5 id="background_41">background<a class="headerlink" href="#background_41" title="Permanent link">&para;</a></h5>
<ul>
<li>the yielded routing paths by the existing approaches often <mark>suffer from considerable overflow,</mark> thus greatly hindering their application in practice.   </li>
<li>two advantgages:</li>
<li>learning scheme to ensures the connectivity  </li>
<li>can effectively scale to large nets and transfer to unseen chip designs   </li>
<li>Due to the complex and irregular distribution of congestion, the construction of escape graph becomes complicated, while the <mark>Hanan grid is ineffective at circumventing congestion</mark>  </li>
<li><code>FLUTE</code> is unaware of congestion  </li>
<li><code>CUGR-2</code> applies the construction of <code>augmented graphs</code> to build candidate paths for nets’ RSTs, adjusting the position of certain Steiner points to circumvent potential congestion  </li>
<li>主要是和 HubRouter 做对比</li>
<li><img alt="image-20250324210830618" src="../assets/image-20250324210830618.png" /></li>
</ul>
<h5 id="contribution_31">contribution<a class="headerlink" href="#contribution_31" title="Permanent link">&para;</a></h5>
<ol>
<li><code>Neural Steiner</code> can effectively scale to <mark>large</mark> nets</li>
<li>transfer to unseen chip designs without any modifications or fine-tuning without any modifications or fine-tuning  </li>
<li>achieves up to a 99.8% <mark>reduction in overflow</mark> while <mark>speeding up</mark> the generation  and maintaining a slight <mark>wirelength loss within only 1.8%</mark>.  </li>
<li><mark>the first</mark> learning-based approach capable of optimizing both wirelength and overflow and effectively addressing the routing problem of large-scale nets  </li>
<li>Moreover, NeuralSteiner can generate overflow-avoiding routes for nets with more than 1000 pins  </li>
</ol>
<h5 id="flow_29">flow<a class="headerlink" href="#flow_29" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250324192220953" src="../assets/image-20250324192220953.png" /></p>
<ol>
<li>
<p>Parallel Routing Tasks Construction</p>
</li>
<li>
<p>divides the numerous nets in the design into a set of mutually conflicting routing tasks.   </p>
</li>
<li>
<p>也就是不重叠的 net 分 batch， 一个 batch 内的布线任务用 t 表示</p>
</li>
<li>
<p>Nets within a task t can be batched together and fed into the neural network for <code>prediction</code> and <code>post-processing</code>,  这个网络是针对 batch 的</p>
</li>
<li>
<p>Candidate point prediction phase  </p>
</li>
<li>
<p>image segmentation task  </p>
</li>
<li>we simplify the learning target in RST construction and select Steiner points and corner points in RST as candidate points to learn  </li>
<li><img alt="image-20250401112743014" src="../assets/image-20250401112743014.png" /></li>
<li>
<p>due to the fixed geometric structures, CNN is inherently limited to local receptive fields that face <mark>difficulties in capturing long-range correlations.</mark> Thus, we introduce the <code>recurrent crisscross attention mechanism (RCCA)</code> to aggregate features from all pixels on the feature map  </p>
</li>
<li>
<p>Overflow-  avoiding RST construction phase:  </p>
</li>
<li>
<p>net augmented graph (NAG)   </p>
<ol>
<li>first merge the predicted candidate point map and pin map  </li>
<li><img alt="image-20250324201453180" src="../assets/image-20250324201453180.png" /></li>
<li>请注意，在 HubRouter [8] 中，引入了条带掩码作为一种滤波器，用于去除噪声中心点，以限制类似于哈南网格的解空间，从而确保线长度尽可能短。然而，如图 1e 所示，在 HubRouter 中添加条带掩码限制了其生成避开拥塞区域的 RST 的能力。相反，我们在这里 <mark>保留了模型预测的所有候选点</mark>，并基于它们构建了 <code>NAG</code></li>
</ol>
</li>
<li>
<p>RST construction</p>
<p><img alt="image-20250324203801098" src="../assets/image-20250324203801098.png" /></p>
</li>
<li>
<p>Since this method <mark>may generate additional detours</mark>, we use a <mark>simple</mark> algorithm to detect potential feasible path reuse to shorten the wirelength.  </p>
</li>
</ol>
<h5 id="data_22">data<a class="headerlink" href="#data_22" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>use <code>CUGR</code> to perform routing on public benchmarks: <code>ISPD'07 contest</code>   </p>
</li>
<li>
<p>adopt the <code>logistic function</code> in CUGR to calculate the overflow value using resource r(u, v)  </p>
</li>
</ul>
<p><img alt="image-20250324194434306" src="../assets/image-20250324194434306.png" /></p>
<ul>
<li>
<p>mark the Steiner points and corner points in the RSTs constructed by CUGR as candidate points and generate the label candidate point map for every net.   </p>
</li>
<li>
<p>we maintain <code>three</code> maps of every net at the original scale of its bounding box. This preserves the precise spatial and overflow information and does not exclude any large-scale nets.  three map 指的是什么？</p>
</li>
<li>
<p>we limit the nets’ Half-perimeter wirelength (HPWL) in the training set to <mark>HPW L ≤ 128</mark>  </p>
</li>
</ul>
<h5 id="experiment_23">experiment<a class="headerlink" href="#experiment_23" title="Permanent link">&para;</a></h5>
<ol>
<li>Loss:</li>
</ol>
<p><img alt="image-20250324200141321" src="../assets/image-20250324200141321.png" /></p>
<p><img alt="image-20250324200724626" src="../assets/image-20250324200724626.png" /></p>
<p><img alt="image-20250324200716473" src="../assets/image-20250324200716473.png" /></p>
<p><img alt="image-20250324200818753" src="../assets/image-20250324200818753.png" /></p>
<ol>
<li>
<p><img alt="image-20250324205051612" src="../assets/image-20250324205051612.png" /></p>
</li>
<li>
<p><img alt="image-20250324205105330" src="../assets/image-20250324205105330.png" /></p>
</li>
<li>
<p><img alt="image-20250324205218340" src="../assets/image-20250324205218340.png" /></p>
</li>
<li>
<p><img alt="image-20250324205435186" src="../assets/image-20250324205435186.png" /></p>
</li>
<li>
<p><img alt="image-20250324205522516" src="../assets/image-20250324205522516.png" /></p>
</li>
<li>
<p><img alt="image-20250324205627094" src="../assets/image-20250324205627094.png" /></p>
</li>
<li>
<p><img alt="image-20250324205634710" src="../assets/image-20250324205634710.png" /></p>
</li>
</ol>
<h3 id="gr_adv_sequential">GR_Adv_Sequential<a class="headerlink" href="#gr_adv_sequential" title="Permanent link">&para;</a></h3>
<ul>
<li>GPU-accelerate</li>
<li>these approaches rely on “parallelizing " traditional sequential algorithms in GPUs. </li>
<li>the quality of the routing result is <mark>still limited</mark> by the traditional sequential-based algorithms  </li>
</ul>
<h4 id="han-gpunetlevel-parallelism-iccad-2011-"><a href="">han-GPU+netlevel parallelism-ICCAD-2011- -</a><a class="headerlink" href="#han-gpunetlevel-parallelism-iccad-2011-" title="Permanent link">&para;</a></h4>
<h4 id="a-global-router-on-gpu-architecture-iccad-2013-"><a href="">A global router on GPU architecture- -ICCAD-2013- -</a><a class="headerlink" href="#a-global-router-on-gpu-architecture-iccad-2013-" title="Permanent link">&para;</a></h4>
<h4 id="vfgr-fat-via-congestion-modeling-asp-dac-2014-thu"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=6742945">VFGR-Fat via congestion modeling-ASP DAC-2014--THU</a><a class="headerlink" href="#vfgr-fat-via-congestion-modeling-asp-dac-2014-thu" title="Permanent link">&para;</a></h4>
<ul>
<li>net-level and region-level parallelization  </li>
<li>有点偏工业</li>
</ul>
<h4 id="sproute-20-detailed-routability-driven-asp-dac-2022-"><a href="https://ieeexplore.ieee.org/abstract/document/9712557">SPRoute 2.0- detailed routability driven-ASP DAC-2022-</a><a class="headerlink" href="#sproute-20-detailed-routability-driven-asp-dac-2022-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/asyncvlsi/SPRoute/tree/master">OpenSource!</a></li>
<li>2D</li>
<li>可以将 guide 文件输入到 innovus?</li>
<li><code>soft capacity</code>   The soft capacity is downsized from the hard capacity (number of available tracks), using the pin density and RUDY value of the region.   </li>
<li><code>batch</code> for <mark>deterministic</mark> net-level parallelization strategy  </li>
<li><code>bulk-synchronously</code> maze-routes  </li>
<li>baseline FLUTE, <a href="# [fastroute 4.0-via min tree+3 bending-ASPDAC-2009-]()">FastRoute 4.0</a> for pattern routing, <a href="# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)">CUGR</a></li>
</ul>
<h5 id="background_42">background<a class="headerlink" href="#background_42" title="Permanent link">&para;</a></h5>
<h2 id="-in-terms-of-parallelization-maze-routing-is-widely-used-in-global-routing-and-is-the-most-time-consuming-stage-on-hardto-route-benchmarks">- In terms of parallelization, maze routing is widely used in global routing and <mark>is the most time-consuming stage</mark> on hardto-route benchmarks.<a class="headerlink" href="#-in-terms-of-parallelization-maze-routing-is-widely-used-in-global-routing-and-is-the-most-time-consuming-stage-on-hardto-route-benchmarks" title="Permanent link">&para;</a></h2>
<h5 id="contribution_32">contribution<a class="headerlink" href="#contribution_32" title="Permanent link">&para;</a></h5>
<ul>
<li><code>soft capacity</code> to reserve space for detailed routability. </li>
<li>parallelize maze routing in a <code>deterministic bulk synchronous approach</code></li>
<li>design a <code>scheduler</code> for the deterministic parallel  execution model  </li>
</ul>
<h5 id="flow_30">flow<a class="headerlink" href="#flow_30" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250225114628773" src="../assets/image-20250225114628773.png" /></p>
<h5 id="model_28">model<a class="headerlink" href="#model_28" title="Permanent link">&para;</a></h5>
<h6 id="soft-capacity">soft capacity<a class="headerlink" href="#soft-capacity" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250225120300741" src="../assets/image-20250225120300741.png" /></p>
<p><img alt="image-20250225120328607" src="../assets/image-20250225120328607.png" /></p>
<p><img alt="image-20250225120309420" src="../assets/image-20250225120309420.png" /></p>
<p>Different layers have different parameters for the ratio function since they are influenced by the congestion in different scales  </p>
<h6 id="bulk-synchronous-deterministic-approach">bulk synchronous deterministic approach<a class="headerlink" href="#bulk-synchronous-deterministic-approach" title="Permanent link">&para;</a></h6>
<p>就是分 batch，all threads execute one batch of nets at a time  </p>
<p>在批处理开始时，每个线程从批处理中获取一个网络，读取全局图的使用情况，并在其线程局部图中执行撕裂和重新路由。</p>
<p><img alt="image-20250225163426630" src="../assets/image-20250225163426630.png" /></p>
<p>还是看不太懂</p>
<h5 id="data_23">data<a class="headerlink" href="#data_23" title="Permanent link">&para;</a></h5>
<p>ICCAD19 contest</p>
<h5 id="experiment_24">experiment<a class="headerlink" href="#experiment_24" title="Permanent link">&para;</a></h5>
<h4 id="fastgr-gpu-pattern-routing-multi-thread-mazedate-2022-pkucuhkhnal"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9774606">FastGR-GPU pattern routing+ multi thread maze–DATE-2022-PKU+CUHK+HNAL</a><a class="headerlink" href="#fastgr-gpu-pattern-routing-multi-thread-mazedate-2022-pkucuhkhnal" title="Permanent link">&para;</a></h4>
<ul>
<li>GPU-accelerated</li>
<li>accelerated the 3D pattern routing algorithm of <a href="# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)">CUGR</a> for initial routing by both <code>net-level</code> and <code>path-level</code> parallelization on GPU</li>
</ul>
<h5 id="background_43">background<a class="headerlink" href="#background_43" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>The literature has extensively explored shortest path searching with GPU [11], [12]. However, most studies only consider the most basic single-source shortest path problem and assume only to find one path on a large graph. This is impractical for routing since we need to route millions of nets subjecting to various objectives and constraints like wirelength, number of vias, and design rules  </p>
</li>
<li>
<p><img alt="image-20250403191259460" src="../assets/image-20250403191259460.png" /></p>
</li>
</ul>
<p>Fig. 1 shows that it is PATTERN dominated on average since the number of nets which pattern routing stage needs to process is much more than the maze routing stage  </p>
<ul>
<li></li>
</ul>
<h5 id="contribution_33">contribution<a class="headerlink" href="#contribution_33" title="Permanent link">&para;</a></h5>
<ul>
<li>a novel GPU-accelerated <code>pattern routing algorithm</code></li>
<li>a high-performance task <code>graph scheduler</code> to distribute CPU and GPU tasks for workload balancing and efficiency</li>
<li></li>
</ul>
<h5 id="flow_31">flow<a class="headerlink" href="#flow_31" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250403193046048" src="../assets/image-20250403193046048.png" /></p>
<h5 id="model_29">model<a class="headerlink" href="#model_29" title="Permanent link">&para;</a></h5>
<ol>
<li>
<p>task graph scheduler==(没看懂！！！！！！！)==</p>
</li>
<li>
<p>是用来指导迷宫布线并行的，用了<code>taskflow</code></p>
</li>
<li>
<p>two-stage task graph scheduler:</p>
<ol>
<li>construct the task graph from the conflicted relationship between each pair of tasks  </li>
<li>determine the execution order for each conflict edge </li>
</ol>
</li>
<li>
<p>Pattern routing stage: Task graph generation  </p>
</li>
<li>
<p>GPU friendly pattern routing</p>
</li>
</ol>
<p><img alt="image-20250403200448178" src="../assets/image-20250403200448178.png" /></p>
<ul>
<li>we apply each block to process one single multi-pin net  </li>
<li><img alt="image-20250403200934314" src="../assets/image-20250403200934314.png" /></li>
</ul>
<h5 id="data_24">data<a class="headerlink" href="#data_24" title="Permanent link">&para;</a></h5>
<p>ICCAD2019 benchmarks  </p>
<h5 id="experiment_25">experiment<a class="headerlink" href="#experiment_25" title="Permanent link">&para;</a></h5>
<ol>
<li>
<p>RTX 2080 GPU.  </p>
</li>
<li>
<p>we choose six different strategies only applied to the rip-up and reroute iterations to show the effect of net ordering  </p>
</li>
<li>
<p><img alt="image-20250403204637280" src="../assets/image-20250403204637280.png" /></p>
</li>
<li>
<p>不同net order 的实验结果：</p>
</li>
</ol>
<p><img alt="image-20250403204815611" src="../assets/image-20250403204815611.png" /></p>
<ol>
<li><img alt="image-20250403204747224" src="../assets/image-20250403204747224.png" /></li>
</ol>
<h4 id="gamer-iccadtrans-20212023-cuhk-"><a href="">Gamer- -ICCAD/Trans-2021/2023- -CUHK-</a><a class="headerlink" href="#gamer-iccadtrans-20212023-cuhk-" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>GPU-accelerated</p>
</li>
<li>
<p>accelerated the two-level maze routing of <a href="# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)">CUGR</a> for rip-up and reroute by updating vertical and horizontal routing costs alternatively on GPU  </p>
</li>
<li>
<p>to accelerate the <code>multisource–multidestination shortest path problem</code> for VLSI routing  </p>
</li>
</ul>
<blockquote>
<p>什么是多源多汇最短路径问题？</p>
<p><img alt="image-20250403210333648" src="../assets/image-20250403210333648.png" /></p>
</blockquote>
<ul>
<li>
<p>integrating <code>GAMER</code> into the state-of-the-art academic global router <code>CUGR</code> </p>
</li>
<li></li>
</ul>
<h5 id="background_44">background<a class="headerlink" href="#background_44" title="Permanent link">&para;</a></h5>
<ul>
<li>Maze routing is usually the most time-consuming step in <code>global routing</code> and <code>detailed routing</code></li>
<li>Many of them adopt the <code>negotiation-based rip-up and reroute</code> method introduced in [3]. Hard-to-route nets are ripped-up and rerouted many times with incrementally changing history cost until getting a feasible solution.   </li>
<li>One way to do this is to separate nets by their bounding boxes and create a task pool. Each thread will search for a net in the <code>task pool</code> whose bounding box does not overlap with any other nets being routed at the moment and perform maze routing [6]. However, if the bounding boxes are too big, the level of parallelism for this method is low  </li>
<li>The approach described in <code>[7]</code> attempts to solve this problem by allowing nets with overlapping bounding boxes to be routed together, and fix any possible overflows afterward by rerouting  (这篇也许可以看看)</li>
<li><code>SPRoute [8]</code> does not forbid routing in the same region if and only if the region has abundant routing resources.   </li>
<li><code>NCTU-GR 2.0 [9]</code> also allows nets with overlapping bounding boxes to be routed simultaneously, but they adopt a more sophisticated technique to avoid the racing situation  </li>
<li>However, some extra efforts are needed to resolve <code>data racing</code>, which may lead to <code>unbalanced workloads</code> and routing performance degradation. Besides, as technology evolves over time, graphics processing units (<mark>GPUs</mark>) are standing out, and can provide better solution to parallelism. There are relatively fewer attempts to load maze routing onto GPUs.  </li>
<li></li>
</ul>
<h5 id="contribution_34">contribution<a class="headerlink" href="#contribution_34" title="Permanent link">&para;</a></h5>
<ol>
<li>decomposes the shortest path search into <code>alternating vertical and horizontal sweep operations</code>,  </li>
<li>two parallel algorithms are proposed to accelerate a sweep operation <mark>from O(n2) to O(log2 n)</mark> on a grid graph of n × n.   </li>
</ol>
<h5 id="flow_32">flow<a class="headerlink" href="#flow_32" title="Permanent link">&para;</a></h5>
<h5 id="model_30">model<a class="headerlink" href="#model_30" title="Permanent link">&para;</a></h5>
<ol>
<li>SWEEP Operation</li>
</ol>
<p><img alt="image-20250403215236451" src="../assets/image-20250403215236451.png" /></p>
<ol>
<li>Parallelization With Conditional Partial Sum  </li>
</ol>
<blockquote>
<p>divide-and-conquer method:</p>
<p><img alt="image-20250403215647910" src="../assets/image-20250403215647910.png" /></p>
</blockquote>
<h4 id="ggr-pattern-and-maze-gpu-accelerated-iccad-2022">GGR-pattern and maze gpu accelerated-ICCAD-2022<a class="headerlink" href="#ggr-pattern-and-maze-gpu-accelerated-iccad-2022" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://github.com/cuhk-eda/Xplace/tree/main/cpp_to_py/gpugr">Open source!</a></p>
</li>
<li>
<p>第一个pattern routing和maze routing都是GPU-accelerate的</p>
</li>
<li>The solution space of pattern routing is intentionally <mark>restricted</mark> to shorten running time by only allowing certain routing topologies such as <mark>L-shape, Z-shape and 3-bend routing</mark></li>
<li>用的<code>FLUTE</code></li>
</ul>
<h5 id="background_45">background<a class="headerlink" href="#background_45" title="Permanent link">&para;</a></h5>
<ul>
<li>Routability-driven placement relies on global routing for accurate routability estimation,  and faster global routing can significantly improve both the running time and the quality of routability-driven placement.   他把应用场景明确了，是给placement用的。开源工程中也是这么放的，放到<code>Xpalce</code>中</li>
<li>Compared to multi-threading with CPU, GPU has more cores and is potentially a good platform for fast global routing.  </li>
<li><img alt="image-20241114231041875" src="../assets/image-20241114231041875.png" /></li>
<li>The computations of the <mark>DP</mark> framework can be performed very efficiently, but the <mark>most time-consuming part</mark> comes from computing the minimum costs connecting two points using 3D L/Z-shape routing</li>
</ul>
<h5 id="contribution_35">contribution<a class="headerlink" href="#contribution_35" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250401105951278" src="../assets/image-20250401105951278.png" /></p>
<h5 id="flow_33">flow<a class="headerlink" href="#flow_33" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241114230008749" src="../assets/image-20241114230008749.png" /></p>
<h5 id="model_31">model<a class="headerlink" href="#model_31" title="Permanent link">&para;</a></h5>
<ul>
<li>An efficient way to calculate the total cost of a long wire segment is to use <code>prefix sum</code>.</li>
<li>Parallel L-Shape Routing  </li>
<li><img alt="image-20250401123216904" src="../assets/image-20250401123216904.png" /></li>
<li>Our L-shape routing for a single 2-pin connection can be divided into <mark>5 steps</mark> as shown by the 5 arrows in Fig. 3  </li>
<li>Every step can be done sequentially in <mark>𝑂(𝐿) time</mark>  </li>
</ul>
<h5 id="data_25">data<a class="headerlink" href="#data_25" title="Permanent link">&para;</a></h5>
<h5 id="experiment_26">experiment<a class="headerlink" href="#experiment_26" title="Permanent link">&para;</a></h5>
<ul>
<li>a The global routing quality is evaluated using an academic detailed router Dr. CU[8]  </li>
</ul>
<h4 id="cugr-20-dag-based-dac-2023-cuhk"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10247702">CUGR 2.0-DAG-based-DAC-2023- -CUHK</a><a class="headerlink" href="#cugr-20-dag-based-dac-2023-cuhk" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/cuhk-eda/cu-gr-2">open source! </a></li>
</ul>
<h5 id="background_46">background<a class="headerlink" href="#background_46" title="Permanent link">&para;</a></h5>
<ul>
<li>many of the aforementioned global routers is that most of them rely heavily on <strong>time-consuming path search algorithms</strong> like maze routing to resolve overflows. These approaches are not efficient enough even with parallilization and may cause lots of unnecessary detours  </li>
</ul>
<h5 id="contribution_36">contribution<a class="headerlink" href="#contribution_36" title="Permanent link">&para;</a></h5>
<ul>
<li>a <mark>DAG-based</mark> generalized pattern routing algorithm</li>
<li>a new <mark>dynamic programming-based</mark> algorithm to calculate the routing cost time complexity from $\mathcal{O}(L^4|V|)$ to $\mathcal{O}(L^2|V|)$</li>
<li>a DAG <mark>augmentation algorithm</mark> that enables the creation of alternative paths in a routing DAG.   can even shift or create Steiner points. over 99% nets can be successfully routed <mark>without the need of maze routing</mark></li>
<li>a new sparse graph <mark>maze routing algorithm</mark> creation of alternative paths in a  routing DAG</li>
</ul>
<h5 id="flow_34">flow<a class="headerlink" href="#flow_34" title="Permanent link">&para;</a></h5>
<ol>
<li>RSMT </li>
</ol>
<p><img alt="image-20250210142956411" src="../assets/image-20250210142956411.png" /></p>
<ol>
<li>DFS and <code>Routing DAG</code> with L pattern</li>
</ol>
<p>注意多了节点 g, f, i, h, 现在每条都是直线</p>
<p><img alt="image-20250210143037337" src="../assets/image-20250210143037337.png" /></p>
<p><code>Routing DAG</code> with other patterns，但是在这里没用做初始布线，初始只用了 L-shape。文章也就这里提了一下，后面都和这个无关，得去源码仔细看看。</p>
<p><img alt="image-20250210143529434" src="../assets/image-20250210143529434.png" /></p>
<ol>
<li>Dynamic Programming-based DAG routing(L-shape + Layer assignment)</li>
</ol>
<p>没说怎么舍弃的？</p>
<ol>
<li>
<p>DAG-based pattern routing with <strong>augmentation</strong>  </p>
</li>
<li>
<p>sparse graph <strong>maze</strong> routing algorithm</p>
</li>
</ol>
<h5 id="model_32">model<a class="headerlink" href="#model_32" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>cost </p>
</li>
<li>
<p>Dynamic Programming-based  </p>
<p><img alt="image-20250210203428984" src="../assets/image-20250210203428984.png" /></p>
</li>
<li>
<p>DAG Augmentation for Congestion  </p>
<p><img alt="image-20250210203818643" src="../assets/image-20250210203818643.png" /></p>
<ol>
<li>create alternative paths   </li>
</ol>
<p><img alt="image-20250210204123847" src="../assets/image-20250210204123847.png" /></p>
<ol>
<li>Steiner point movement</li>
</ol>
<p>具体怎么移动的文章也没说</p>
</li>
</ul>
<h5 id="experiment_27">experiment<a class="headerlink" href="#experiment_27" title="Permanent link">&para;</a></h5>
<ul>
<li>compare with CUGR [12] and SPRoute 2.0 [13]  </li>
</ul>
<p><img alt="image-20250210211951988" src="../assets/image-20250210211951988.png" /></p>
<p><img alt="image-20250210212311337" src="../assets/image-20250210212311337.png" /></p>
<p>only one thread  for run time</p>
<ul>
<li>
<p><img alt="image-20250210212636193" src="../assets/image-20250210212636193.png" /></p>
</li>
<li>
<p>Effectiveness of  steiner point augmentation  </p>
</li>
<li>
<p><img alt="image-20250210212920933" src="../assets/image-20250210212920933.png" /></p>
</li>
<li>
<p>run time compare with GPU-accelerated GR</p>
</li>
<li>
<p>compare with FastGR [14] and GAMER [15]  </p>
</li>
<li>
<p>GPU 的好坏也有关系吧。本实验用的 RTX 3090  </p>
</li>
<li>
<p>slightly faster than FastGR for initial routing </p>
<p><img alt="image-20250210213728850" src="../assets/image-20250210213728850.png" /></p>
</li>
<li>
<p>around 5.2× as fast as GAMER</p>
<p><img alt="image-20250210215926150" src="../assets/image-20250210215926150.png" /></p>
</li>
</ul>
<h4 id="instantgr-scalable-gpu-parallelization-iccad-2024-cuhk"><a href="https://shijulin.github.io/files/1239_Final_Manuscript.pdf">InstantGR-Scalable GPU Parallelization-ICCAD-2024-CUHK</a><a class="headerlink" href="#instantgr-scalable-gpu-parallelization-iccad-2024-cuhk" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/cuhk-eda/InstantGR">open source! </a></li>
<li>second place of ISPD25 contest</li>
<li>GPU Parallelization  </li>
<li>parallel algorithm is mainly based on the DAG-based global routing algorithm in <a href="# [CUGR2.0 EDGE- -DAC-2023-](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10247702)">CUGR2</a>.  应该是 3D pattern routing DP 的部分和 maze routing 的部分</li>
<li>parallel while do initial routing  and RRR</li>
<li>提高了并行度，但是还是有串行的部分</li>
<li>也用了 FLUTE</li>
<li>一定要以 net 为单元吗？是为了用 DP</li>
<li></li>
</ul>
<h5 id="background_47">background<a class="headerlink" href="#background_47" title="Permanent link">&para;</a></h5>
<ul>
<li>GPU memory is limited  </li>
<li>This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization  </li>
<li>large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored  </li>
<li>nets in a batch can be routed in parallel</li>
</ul>
<h5 id="task_12">task<a class="headerlink" href="#task_12" title="Permanent link">&para;</a></h5>
<ul>
<li>parallelism for large-scale</li>
<li>partitioned  design</li>
</ul>
<h5 id="contribution_37">contribution<a class="headerlink" href="#contribution_37" title="Permanent link">&para;</a></h5>
<ul>
<li>a new method for <code>net-level batch generation</code>. based on 3D fine-grained overlap checking and explores more parallelism by increasing the number of nets per batch</li>
<li><code>node-level</code> parallel routing approach. achieves much higher parallelism compared to traditional net-level parallel routing.</li>
</ul>
<h5 id="flow_35">flow<a class="headerlink" href="#flow_35" title="Permanent link">&para;</a></h5>
<ul>
<li>In initial routing, we construct a basic <code>routing DAG</code> to perform <strong>L-shape pattern routing</strong>.  </li>
</ul>
<p><strong>key points</strong></p>
<p>specific explanation show in <a href="../routing/routing2.md">routing2</a></p>
<ul>
<li>
<p>NET-LEVEL PARALLELISM  </p>
</li>
<li>
<p>simultaneous routing of a <code>batch</code> of nets that do not “<code>overlap</code>”  </p>
</li>
<li>
<p>[2, 3, 14, 19, 20, 22, 26]  19 年开始的，cugr2 和 fastgr 都用了</p>
</li>
<li>
<p><strong>Typical</strong> Batch Generation Algorithm  </p>
<p>used in [2, 3, 14, 19, 20]  </p>
<p><img alt="image-20250212100127751" src="../assets/image-20250212100127751.png" /></p>
<p><code>R-trees</code> 是实现 <code>line 4</code> 的常用做法</p>
<p><code>pessimistically approximates</code>  significantly lowers the degree of parallelism  </p>
</li>
<li>
<p>define and graph model</p>
<p><img alt="image-20250212111440550" src="../assets/image-20250212111440550.png" /></p>
<p><img alt="image-20250212100930831" src="../assets/image-20250212100930831.png" /></p>
<p>以 <code>segment</code> 为单位，同时分开了水平和垂直两个部分，假设全部为 L-shape，同时对于不在一条线上的两个节点，有两个 L</p>
<p>These four nets will be divided into just <code>one batch</code> based on our exact representation of routing graphs for overlap checking, while into <code>four batches</code> by the traditional bounding box-based pessimistic approximation  </p>
<p>via model:</p>
<p><img alt="image-20250212110626674" src="../assets/image-20250212110626674.png" /></p>
<p><img alt="image-20250212104214378" src="../assets/image-20250212104214378.png" /></p>
<p>via 用一个十字表示</p>
</li>
<li>
<p>Overlap Checking Algorithms  </p>
<ol>
<li>
<p>以水平子图进行展示，垂直同理</p>
</li>
<li>
<p>以水平 segment 为单位进行 checking</p>
</li>
<li>
<p>首先判断是不是 y 坐标相等：group the segments with the same 𝑦  </p>
</li>
<li>
<p>tradictional algorithm:</p>
</li>
</ol>
<p>This is a classical computational geometry problem that can be efficiently solved by <code>segment trees</code> [1] in 𝑂(log𝑛) time for both operations,   </p>
<p><img alt="image-20250212114550426" src="../assets/image-20250212114550426.png" /></p>
<ol>
<li>new algorithm motivation:</li>
</ol>
<p><img alt="image-20250212114611742" src="../assets/image-20250212114611742.png" /></p>
<p>segments are very short</p>
<ol>
<li>new algorithm: <code>Point Exhaustion</code></li>
</ol>
<p>simply use a Boolean array to record whether each point in [1, 𝑛] is covered by some segment 𝑠 ∈ 𝑆. We mark every point 𝑥 ∈ [𝑙, 𝑟] when a segment [𝑙, 𝑟] is inserted, and check every point 𝑥 ∈ [𝑙𝑞, 𝑟𝑞] for overlap query of a segment [𝑙𝑞, 𝑟𝑞].   </p>
<p>further improve the efficiency of this point exhaustion by using bit arrays  </p>
<ol>
<li>
<p>another improvement: <code>representative point exhaustion</code></p>
</li>
<li>
<p>allowing a little bit of overlap.   </p>
</li>
<li>it only checks the two end points of a query segment. ??什么意思  </li>
<li>covering most overlap scenarios in practice.   </li>
<li>The only scenario that this algorithm fails to find the overlap of two overlapping segments is when the query segment [𝑙𝑞, 𝑟𝑞] contains the overlapping segment [𝑙, 𝑟], [𝑙, 𝑟] ⊂ [𝑙𝑞, 𝑟𝑞]  </li>
</ol>
</li>
<li>
<p>NODE-LEVEL PARALLELISM</p>
</li>
</ul>
<p><img alt="image-20250212142040816" src="../assets/image-20250212142040816.png" /></p>
<ul>
<li>
<p>还是以 net 为单位分到不同的 batch？</p>
</li>
<li>
<p>routing nodes of the same depth in parallel  </p>
<p><img alt="image-20250212143816082" src="../assets/image-20250212143816082.png" /></p>
<p>Suppose we have 4 nets, Net A, B, C and D in our grid graph. Since nets with overlap cannot be routed together, Net A and B are distributed to batch 0, as shown in Figure 7a, and nets C and D are distributed to batch 1.  </p>
<p><img alt="image-20250212143140834" src="../assets/image-20250212143140834.png" /></p>
</li>
</ul>
<h5 id="experiment_28">experiment<a class="headerlink" href="#experiment_28" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>4 NVIDIA A800 GPUs and 8 CPU threads.</p>
</li>
<li>
<p>compare different overlap checking methods  </p>
<p><img alt="image-20250212145328644" src="../assets/image-20250212145328644.png" /></p>
<p>The number of nets per batch is limited to 1000  </p>
</li>
<li>
<p>compare 2 largest benchmark</p>
</li>
</ul>
<p><img alt="image-20250212154458440" src="../assets/image-20250212154458440.png" /></p>
<ul>
<li>compare with Top-3 Global Routers of ISPD2024 Contest   </li>
</ul>
<p><img alt="image-20250212161238221" src="../assets/image-20250212161238221.png" /></p>
<ul>
<li>Runtime (s) of DAG-Based Augmented Routing with and without Node-Level Parallelism  </li>
</ul>
<p><img alt="image-20250212161314333" src="../assets/image-20250212161314333.png" /></p>
<p>acceleration 那一行好像是加速倍率才对</p>
<h4 id="helem-gr-heterogeneouslinearized-exponential-multiplier-method-iccad-2024-pek"><a href="">HeLEM-GR-Heterogeneous+Linearized Exponential Multiplier Method-ICCAD-2024- -PEK</a><a class="headerlink" href="#helem-gr-heterogeneouslinearized-exponential-multiplier-method-iccad-2024-pek" title="Permanent link">&para;</a></h4>
<ul>
<li>first place of ISPD25 contest</li>
<li>not open source 2025/2/6</li>
<li>2D routing algorithm  </li>
</ul>
<p>background</p>
<h5 id="contribution_38">contribution:<a class="headerlink" href="#contribution_38" title="Permanent link">&para;</a></h5>
<ul>
<li><code>LEM</code>(linearized exponential multiplier) method for <mark>2D routing problem</mark> to minimize wirelength and overflow. This LEM framework is <mark>general to integrate any routing kernels.</mark>  </li>
<li><code>batched routing kernels</code>  including <mark>L shape and 3-bend routing</mark> for GPU parallelization.  </li>
<li><code>sweep operations</code>  for GPU-accelerated layer assignment.</li>
<li></li>
</ul>
<h5 id="flow_36">flow<a class="headerlink" href="#flow_36" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250225103529314" src="../assets/image-20250225103529314.png" /></p>
<ul>
<li>preparation  </li>
<li>run on CPU</li>
<li>use FLUTE</li>
<li>use <code>SPRoute 2.0</code>  to compact 3D graph to 2D graph  </li>
<li>2D routing  </li>
<li>run on GPU</li>
<li>layer assignment</li>
<li>run on GPU</li>
</ul>
<h3 id="rsmt">RSMT<a class="headerlink" href="#rsmt" title="Permanent link">&para;</a></h3>
<h4 id="hannan-grid-1966-"><a href="">Hannan grid- - -1966- -</a><a class="headerlink" href="#hannan-grid-1966-" title="Permanent link">&para;</a></h4>
<ul>
<li>has proven that an optimal RSMT can always be constructed on the Hanan grid  </li>
</ul>
<h4 id="geosteiner-1998-"><a href="">GeoSteiner- - -1998- -</a><a class="headerlink" href="#geosteiner-1998-" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="http://geosteiner.com/">GeoSteiner Homepage</a>, 一直有更新，5.x版本貌似比FLUTE更好了。97年搞到现在（2025）。4.0版本是商用的。</p>
</li>
<li>
<p>an efficient optimal algorithm that <mark>enumerates</mark> all possible full Steiner tree to form an RSMT</p>
</li>
<li>It is proven that an optimal RSMT can always be found by combining full Steiner trees only, which are Steiner trees with a special structure.   </li>
<li>The running time of GeoSteiner inevitably goes to exponential</li>
</ul>
<h4 id="-multilayer-obstacle-avoidingspanning-graphs-trans-2008-"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=6930811">-Multilayer Obstacle Avoiding+Spanning Graphs-Trans-2008- -</a><a class="headerlink" href="#-multilayer-obstacle-avoidingspanning-graphs-trans-2008-" title="Permanent link">&para;</a></h4>
<h2 id="-">-<a class="headerlink" href="#-" title="Permanent link">&para;</a></h2>
<h4 id="flute-2008-"><a href="">FLUTE- - -2008- -</a><a class="headerlink" href="#flute-2008-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://home.engineering.iastate.edu/~cnchu/flute.html">OpenSource!</a></li>
<li>The runtime complexity of FLUTE with fixed accuracy is O(n log n) for a net of degree n  </li>
<li>FLUTE is an RSMT construction algorithm adopting a look-up table approach, which is both fast and optimal for low-degree nets. However, FLUTE is unaware of routing <strong>congestion</strong>.  </li>
</ul>
<p><img alt="image-20241116114652698" src="../assets/image-20241116114652698.png" /></p>
<p>下面是一系列 FLUTE 和基于 FLUTE 的改进</p>
<p><img alt="image-20241116114634422" src="../assets/image-20241116114634422.png" /></p>
<h5 id="background_48">background<a class="headerlink" href="#background_48" title="Permanent link">&para;</a></h5>
<ul>
<li>RSMT problem is NP-complete [1].  </li>
<li>Most signal nets in VLSI circuits have a low degree. Therefore, in VLSI applications, rather than having a low runtime complexity, it is more important for RSMT algorithms to be simple so that they can be efficient for small nets.   </li>
<li>Hanan [16] pointed out that an optimal RSMT can always be constructed based on the Hanan grid.  </li>
<li>基本定义</li>
</ul>
<p><img alt="image-20250227114157112" src="../assets/image-20250227114157112.png" /></p>
<p>x, y, s, h, v</p>
<p><code>position sequence</code>: s1, s2, s3, s4 = 3142</p>
<p><img alt="image-20250227111722382" src="../assets/image-20250227111722382.png" /></p>
<p><img alt="image-20250227111733809" src="../assets/image-20250227111733809.png" /></p>
<p>wirelength vectors are: (1, 2, 1, 1, 1, 2), (1, 1, 1, 1, 2, 3), and (1, 2, 1, 1, 1, 1)<br />
- POWV and POST for net(degree &lt; 9)</p>
<ul>
<li>For each group, the optimal wirelength of any net can be found based on a few vectors called potentially optimal <mark>wirelength vectors</mark> <mark>(POWVs)</mark>.  </li>
<li>We also store one corresponding Steiner tree, which we called potentially optimal <mark>Steiner tree</mark> <mark>(POST)</mark> associated with each POWV. </li>
</ul>
<h5 id="contribution_39">contribution<a class="headerlink" href="#contribution_39" title="Permanent link">&para;</a></h5>
<h2 id="-we-show-that-the-set-of-all-degree-n-nets-can-be-partitioned-into-n-groups-according-to-the-relative-positions-of-their-pins">- We show that the set of all <mark>degree-n nets can be partitioned into n! groups</mark> according to the relative positions  of their pins.<a class="headerlink" href="#-we-show-that-the-set-of-all-degree-n-nets-can-be-partitioned-into-n-groups-according-to-the-relative-positions-of-their-pins" title="Permanent link">&para;</a></h2>
<h5 id="model_33">model<a class="headerlink" href="#model_33" title="Permanent link">&para;</a></h5>
<h6 id="_8">制表枚举化简：<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h6>
<ul>
<li>Note that, although the number of the possible Steiner trees is huge, the number of the possible wirelength vectors is much less. And we notice that not all the wirelength vectors have the potential to produce the optimal wirelength</li>
<li>Most vectors are redundant because they have a larger or equal value than that of another vector in all coefficients.  For example, we can ignore the wirelength vector (1, 2, 1, 1, 1, 2) because the wirelength produced by the vector (1, 2, 1, 1, 1, 1) is always v3 less.  </li>
<li>We called a vector that can potentially produce the optimal wirelength (i.e., cannot be ignored) a <mark>POWV</mark>  </li>
<li>for every low-degree net, there are only a few POWVs. For example, for all degree-3 nets, the only optimal wirelength vector is (1, 1, 1, 1), which corresponds to the half-perimeter wirelength (HPWL).   </li>
</ul>
<h6 id="group-the-nets-which-can-share-the-same-set-of-powvs">group the nets which can share the same set of POWVs<a class="headerlink" href="#group-the-nets-which-can-share-the-same-set-of-powvs" title="Permanent link">&para;</a></h6>
<ul>
<li>
<p>如果每一种 POST 对应一些 POSTs，会有太多种可能，浪费空间</p>
</li>
<li>
<p>定义：topologically equivalent</p>
</li>
</ul>
<p><img alt="image-20250227113943777" src="../assets/image-20250227113943777.png" /></p>
<p>have the same <code>position sequence</code></p>
<ul>
<li>Theorem 1: the set of all degree-n nets can be divided into <mark>n!</mark> groups according to the position sequence such that all nets in each <mark>group</mark> share the same set of POWVs. (9!= 362,880)</li>
</ul>
<h6 id="lut-generateion">LUT generateion<a class="headerlink" href="#lut-generateion" title="Permanent link">&para;</a></h6>
<ul>
<li>
<p>如果使用遍历的方法，慢。Even for degree 5, we need to enumerate a Hanan grid consisting of 40 edges（$4 \times 5 \times 2$） for each of the 120 groups(5!)</p>
</li>
<li>
<p><code>boundary-compaction technique</code> for efficient:</p>
</li>
</ul>
<p>By compacting the four boundaries in a different order, a set of different Steiner trees with different wirelength vectors can be generated</p>
<ul>
<li>
<p><img alt="image-20250227120546770" src="../assets/image-20250227120546770.png" /></p>
</li>
<li>
<p>边界压缩技术通过压缩四个边界中的一个来减小网格大小，即，将边界上的所有引脚移到与该边界相邻的网格线上。</p>
<p><img alt="image-20250227121330548" src="../assets/image-20250227121330548.png" /></p>
</li>
<li>
<p><img alt="image-20250311104321293" src="../assets/image-20250311104321293.png" /></p>
</li>
<li>
<p>还是没看懂 0.0</p>
</li>
<li>
<p>结果：number of POWVS in a Group:</p>
<p><img alt="image-20250311103853312" src="../assets/image-20250311103853312.png" /></p>
</li>
<li>
<p>REDUCTION OF LOOKUP TABLE SIZE  </p>
</li>
<li>
<p>The POST associated with each POWV should have up to seven Steiner nodes and 9 + 7 - 1 = 15 branches. If 1 byte is used to store each branch in a POST, the POST storage requirement for degree 9 will be 155.9 MB  </p>
</li>
<li>
<p><img alt="image-20250311105345845" src="../assets/image-20250311105345845.png" /></p>
</li>
<li>
<p><img alt="image-20250311105433321" src="../assets/image-20250311105433321.png" /></p>
</li>
<li>
<p>Groups are equivalent for two reasons  </p>
<ul>
<li>First:</li>
</ul>
<p><img alt="image-20250311110049688" src="../assets/image-20250311110049688.png" /> Therefore, up to 2^4^ = 16 different groups can share a set of POWVs and POSTs  (the number of equivalent groups may be less than 16 because pins can be shared by adjacent boundaries, and therefore, not all combinations exist).   </p>
<ul>
<li>Second, if two nets are symmetrical horizontally, vertically, or diagonally, the POWVs and POSTs of one group can be transformed to those of the other.   </li>
</ul>
</li>
<li>
<p>The total table size is only 9.00 MB in the end  </p>
</li>
<li>
<p>SPEEDUP OF MINIMUM-WIRELENGTH COMPUTATION  </p>
</li>
<li>
<p>Since entries in POWVs are typically small integers and addition is computationally much less expensive than multiplication, it is more efficient to add the edge length several times instead of using multiplication (加法比乘法好)</p>
</li>
<li>
<p>Many of them differ from others in only one or two entries. Hence, some POWVs can be efficiently evaluated by adding or subtracting some terms from some other previously computed POWVs.   </p>
</li>
<li>
<p>NET BREAKING  </p>
</li>
<li>
<p>Nets with a degree <mark>higher than D (D 一般等于 9)</mark> are broken into several subnets with a degree ranging from 2 to D to which the table lookup estimation can be applied  </p>
</li>
<li><mark>four heuristics</mark> are applied to collectively determine a score for each way of breaking.   </li>
<li>In this technique, a scheme is also introduced to allow users to control the <mark>tradeoff between accuracy and runtime</mark>  </li>
<li><img alt="image-20250311112531953" src="../assets/image-20250311112531953.png" /></li>
<li><img alt="image-20250311112540051" src="../assets/image-20250311112540051.png" /></li>
<li><img alt="image-20250311112848743" src="../assets/image-20250311112848743.png" /></li>
<li><img alt="image-20250311121152650" src="../assets/image-20250311121152650.png" /></li>
</ul>
<h5 id="data_26">data<a class="headerlink" href="#data_26" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250311120818694" src="../assets/image-20250311120818694.png" /></p>
<h5 id="experiment_29">experiment<a class="headerlink" href="#experiment_29" title="Permanent link">&para;</a></h5>
<ol>
<li>模型对比 </li>
</ol>
<p>GeoSteiner 作为标准</p>
<p><img alt="image-20250311120900286" src="../assets/image-20250311120900286.png" /></p>
<ol>
<li>不同度的图对比</li>
</ol>
<p><img alt="image-20250311120937527" src="../assets/image-20250311120937527.png" /></p>
<ol>
<li>runtime</li>
</ol>
<p><img alt="image-20250311121011023" src="../assets/image-20250311121011023.png" /></p>
<p>The runtime is increasing at a rate much slower than A(log A+1)/2 because most nets have a low degree  </p>
<p>because the redundant edge removal and the local refinement techniques described at the end of Section VI-B cannot be used, the error is increased.  </p>
<ol>
<li>更大的 degree</li>
</ol>
<p><img alt="image-20250311121624728" src="../assets/image-20250311121624728.png" /></p>
<h4 id="-obstacle-avoidingparallel-iccad-09-cuhk-"><a href="https://www.cse.cuhk.edu.hk/~fyyoung/paper/iccad09_geosteiner.pdf">-obstacle avoiding+parallel -ICCAD-09- -CUHK-</a><a class="headerlink" href="#-obstacle-avoidingparallel-iccad-09-cuhk-" title="Permanent link">&para;</a></h4>
<h4 id="-obstacle-avoiding-science-direct-2013-cuhk"><a href="https://www.sciencedirect.com/science/article/pii/S0167926013000424">-Obstacle avoiding-Science Direct-2013- -CUHK</a><a class="headerlink" href="#-obstacle-avoiding-science-direct-2013-cuhk" title="Permanent link">&para;</a></h4>
<h4 id="rest-attention-mechanism-iccad-2021-rlac-cuhk"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=9586209">REST-attention mechanism-ICCAD-2021-RL(AC)-CUHK</a><a class="headerlink" href="#rest-attention-mechanism-iccad-2021-rlac-cuhk" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/cuhk-eda/REST">OpenSource!</a></li>
<li><a href="https://github.com/fugjgjguhih/Solving-VLSI-DRL/tree/40b6c6324927a8ef875558ab6d229a3545a451e6">github 上有个相关的复现</a></li>
<li>the first successful attempt to solve this problem using a machine learning approach  </li>
</ul>
<h5 id="background_49">background<a class="headerlink" href="#background_49" title="Permanent link">&para;</a></h5>
<ul>
<li>machine learning based approaches have shown several advantages over the traditional heuristics, e.g., shorter time for development, superior quality and speed for small to middle size instances.  </li>
<li>previous ML-based combinatorial problem (TSP) work: RNN-based pointer network [6] --&gt; RL-based work [8] --&gt; multi-hand atttention+[8] work [9]</li>
</ul>
<h5 id="model_34">model<a class="headerlink" href="#model_34" title="Permanent link">&para;</a></h5>
<h6 id="rectilinear-edge-sequence-res">Rectilinear Edge Sequence (RES)<a class="headerlink" href="#rectilinear-edge-sequence-res" title="Permanent link">&para;</a></h6>
<ul>
<li>
<p>designed for bridge the gap between machine learning output and RSMT structure.  </p>
</li>
<li>
<p><img alt="image-20250227170745540" src="../assets/image-20250227170745540.png" /></p>
</li>
<li>
<p>res = ((2; 1); (2; 4); (3; 4))  ,(vi, hi)分别表示在点 vi 上做垂线，在 hi 上做水平线</p>
</li>
<li>
<p>overlapping edges indicated by an RES are merged automatically, with Steiner points created</p>
</li>
<li>
<p>原文证明了 res 一定可以找到最优的 RSMT</p>
</li>
<li>
<p><strong>Good Properties of RES</strong>  </p>
</li>
<li>
<p>Fixed Length Sequence: Determining the number of pairs to output is non-trivial for a neural network model. Fortunately, this will not be a problem with RES, since the length of the RES for any set of n points is always n - 1  </p>
</li>
<li>
<p>The evaluation process is often the bottleneck of reinforcement learning, as it usually requires lots of computations or even simulations. The RES can be evaluated in linear time by finding the length of the horizontal and vertical segments over each point.   </p>
<p><img alt="image-20250227173421461" src="../assets/image-20250227173421461.png" /></p>
<p><img alt="image-20250227174218023" src="../assets/image-20250227174218023.png" /></p>
</li>
</ul>
<h6 id="ac-model">AC model<a class="headerlink" href="#ac-model" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250227174340598" src="../assets/image-20250227174340598.png" /></p>
<h2 id="-n-x-y">- 输入是 n 个节点的(x, y)坐标<a class="headerlink" href="#-n-x-y" title="Permanent link">&para;</a></h2>
<h5 id="experiment_30">experiment<a class="headerlink" href="#experiment_30" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250324185340529" src="../assets/image-20250324185340529.png" /></p>
<ul>
<li>好像没什么提升</li>
</ul>
<h4 id="-gpu-accelerated-iccad-2022-pek"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10069158">-GPU-Accelerated-ICCAD-2022--PEK</a><a class="headerlink" href="#-gpu-accelerated-iccad-2022-pek" title="Permanent link">&para;</a></h4>
<ul>
<li>first GPU-accelerated RSMT generation algorithm  </li>
</ul>
<h5 id="background_50">background<a class="headerlink" href="#background_50" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Rectilinear Steiner minimum tree (RSMT) generation is a fundamental component in the VLSI design automation flow. Due to its extensive usage in circuit design iterations at early design stages like <mark>synthesis, placement, and routing</mark>, the performance of RSMT generation is critical for a reasonable design turnaround time.   </p>
</li>
<li>
<p>previous work are CPU-based</p>
</li>
<li>
<p>在 GPU 上加速 RSMT 生成是一项重要但极具挑战性的任务，主要原因在于其复杂的、非平凡(non-trivial)的分治(divide-and-conquer)计算模式与递归操作。</p>
</li>
<li>
<p>NP-completeness of RSMT generation --cite--&gt; [1]</p>
</li>
<li>
<p>the current most efficient and widely-adopted heuristic is FLUTE [9], </p>
</li>
<li>
<p>Although most of the nets in a typical circuit design have only a small degree (≤ 9), larger nets are exponentially harder to solve</p>
</li>
</ul>
<p><img alt="image-20250225234107526" src="../assets/image-20250225234107526.png" /></p>
<ul>
<li>
<p>RSMT algorithms, such as FLUTE, are based on a <mark>divide-and-conquer</mark> strategy with deep recursions, which are impossible to be executed on GPU threads with very limited stack memory</p>
</li>
<li>
<p>The sizes of nets in a circuit netlist are <mark>highly uneven</mark>, from 2-pin nets to nets with 40 pins or more, which leads to an extremely <mark>imbalanced workload</mark> and harms the parallelism.   </p>
</li>
<li>
<p>基于汉南网格：</p>
</li>
</ul>
<p><img alt="image-20250226223050705" src="../assets/image-20250226223050705.png" /></p>
<ul>
<li>
<p>每个点三个特征：(x, y)坐标(sort according to y coordinate)，排序 s(sort according to x coordinate)</p>
</li>
<li>
<p>R-MST does not insert any Steiner points and can be efficiently constructed in 𝑂 (𝑛 log𝑛) time for a net with 𝑛 pins [4], but at the cost of up to 50% worse result than RSMT [5]  </p>
</li>
<li>
<p><img alt="image-20250226234011393" src="../assets/image-20250226234011393.png" /></p>
</li>
</ul>
<h5 id="contribution_40">contribution<a class="headerlink" href="#contribution_40" title="Permanent link">&para;</a></h5>
<ul>
<li>propose a <code>levelized task decomposition strategy</code></li>
<li>ensures a balanced workload and enables high-performance data parallelism  </li>
<li>a algorithmic transforms  </li>
<li>eliminate the recursion patterns of FLUTE  </li>
<li>GPU-efficient kernels   </li>
</ul>
<h5 id="flow_37">flow<a class="headerlink" href="#flow_37" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250226234755100" src="../assets/image-20250226234755100.png" /></p>
<ul>
<li>break and merge stages work in an <code>iterative</code> way rather than the <code>recursive</code> mode in FLUTE  </li>
<li>
<p>There is no extensive data copy between CPU and GPU during the inner algorithm loops which ensures minimal overhead of CPU-GPU communication  </p>
</li>
<li></li>
</ul>
<h4 id="-obstacle-avoiding-iscas-2024-sysu"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10558430">-Obstacle avoiding-ISCAS-2024--SYSU</a><a class="headerlink" href="#-obstacle-avoiding-iscas-2024-sysu" title="Permanent link">&para;</a></h4>
<h4 id="a_simple_fast_and_gpu-friendly_steiner-tree_heuristic"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=9835675">A_Simple_Fast_and_GPU-friendly_Steiner-Tree_Heuristic</a><a class="headerlink" href="#a_simple_fast_and_gpu-friendly_steiner-tree_heuristic" title="Permanent link">&para;</a></h4>
<h4 id="nn-steiner-mixed-neural-aaai-2024-california-"><a href="">NN Steiner-Mixed Neural-AAAI-2024-California-</a><a class="headerlink" href="#nn-steiner-mixed-neural-aaai-2024-california-" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/ABKGroup/NN-Steiner">OpenSource!</a></li>
<li>we develop NN-Steiner1, a mixed neural-algorithmic framework that leverages the ideas behind Arora’s PTAS for RSMT (Arora 1998). The costly <code>DP step</code> is replaced by a single NN component that outputs a learned embedding of the solutions to the DP subproblems.   </li>
<li>solving <mark>large-scale</mark> RSMT problems。这篇原理看很难看，也比较偏RSMT算法在多Point上的实现，在GR上的应用场景感觉倒是不大</li>
</ul>
<h5 id="background_51">background<a class="headerlink" href="#background_51" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>there has been a surge in use of NNs to help tackle <code>combinatorial optimization  problems</code>  </p>
</li>
<li>
<p><code>REST (Liu, Chen, and Young 2021)</code> achieved the first NN-based approach for RSMT by finding so-called rectilinear edge sequences using <code>RL</code>.  (Chen et al. 2022) designed an RL framework to find obstacleavoiding Steiner minimum trees.   Significant challenges in <mark>neural combinatorial optimization</mark> (NCO) remain. NNs are often used in an <code>ad-hoc manner</code> with limited theoretical understanding of the resulting framework. It is also often not known if machine-learning pipelines have the capacity to solve a given combinatorial optimization problem, or how network-architecture design could leverage problem structure to design more effective and efficient neural models.  </p>
</li>
</ul>
<blockquote>
<p>在神经网络和机器学习领域，<strong>"ad-hoc manner"（临时性/特定场景性方式）</strong> 通常指一种 <strong>缺乏系统性理论指导、依赖经验或直觉的设计和调整方法</strong></p>
<p>神经网络的设计和优化往往依赖实验结果而非数学证明（例如，无法严格证明某网络结构对组合优化问题的收敛性）。</p>
<ul>
<li>例如：Transformer 的注意力机制最初是启发式设计，后续才逐渐有理论分析其表达能力。</li>
</ul>
<p><strong>为什么神经网络常被批评为 "ad-hoc"？</strong></p>
<p><strong>历史原因</strong>：</p>
<ul>
<li><strong>黑箱性质</strong>：神经网络的函数逼近能力强大，但内部工作机制难以解释。</li>
<li><strong>工程实践优先</strong>：深度学习的发展长期由实验结果推动（如ImageNet竞赛），理论滞后于应用。</li>
<li><strong>灵活性与代价</strong>：神经网络的通用性使其能适应多种任务，但这也导致设计时缺乏严格约束。</li>
</ul>
<p><strong>典型案例</strong>：</p>
<ul>
<li><strong>ResNet 的跳跃连接</strong>：最初是实验发现“深度增加导致训练误差上升”后提出的解决方案，后续才有理论分析其梯度传播性质。</li>
<li><strong>激活函数选择</strong>：ReLU 的普及源于实验中发现其训练效率优于Sigmoid，而非先验理论推导。</li>
</ul>
</blockquote>
<ul>
<li>Arora’s PTAS  1998</li>
</ul>
<h5 id="contribution_41">contribution<a class="headerlink" href="#contribution_41" title="Permanent link">&para;</a></h5>
<ul>
<li>the first neural architecture of <code>bounded size</code> that has capacity to approximately solve the RSMT problem  </li>
<li>leads to better practical performance than existing SOTA methods for <mark>large instances</mark>  </li>
<li>one of the first NCO(neural combinatorial optimization) frameworks to use algorithmic alignment to <mark>remove dependence on problem size</mark>. </li>
<li>Training on large instances is prohibitively expensive: for supervised learning this requires computation of exact solutions to large instances, and for RL and unsupervised learning, training becomes exponentially more challenging as size increases. Thus, size generalization is essential for performance on large instances  </li>
<li>pin可以拓展到多维（不只是2,3维空间）, 还可以不用直线（欧几里得空间）</li>
<li></li>
</ul>
<h5 id="flow_38">flow<a class="headerlink" href="#flow_38" title="Permanent link">&para;</a></h5>
<h5 id="model_35">model<a class="headerlink" href="#model_35" title="Permanent link">&para;</a></h5>
<h5 id="data_27">data<a class="headerlink" href="#data_27" title="Permanent link">&para;</a></h5>
<h5 id="experiment_31">experiment<a class="headerlink" href="#experiment_31" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250422230008874" src="../assets/image-20250422230008874.png" /></p>
<p><img alt="image-20250422230039422" src="../assets/image-20250422230039422.png" /></p>
<h4 id="-delay-driven-trans-2024-"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10756606">-Delay Driven-Trans-2024- - </a><a class="headerlink" href="#-delay-driven-trans-2024-" title="Permanent link">&para;</a></h4>
<h3 id="dr-outdated">DR outdated<a class="headerlink" href="#dr-outdated" title="Permanent link">&para;</a></h3>
<h4 id="tritonroute-ilp-"><a href="">TritonRoute- - - -ILP-</a><a class="headerlink" href="#tritonroute-ilp-" title="Permanent link">&para;</a></h4>
<h4 id="drcu"><a href="">DRCU</a><a class="headerlink" href="#drcu" title="Permanent link">&para;</a></h4>
<ul>
<li>academic DR  </li>
</ul>
<h3 id="dr-adv">DR adv<a class="headerlink" href="#dr-adv" title="Permanent link">&para;</a></h3>
<h2 id="adv-node">Adv-Node<a class="headerlink" href="#adv-node" title="Permanent link">&para;</a></h2>
<h4 id="-multi-row-standard-cell-layout-synthesis-with-enhanced-scalability-iseda-2025-pek">-Multi Row Standard Cell Layout Synthesis with Enhanced Scalability-ISEDA-2025--PEK<a class="headerlink" href="#-multi-row-standard-cell-layout-synthesis-with-enhanced-scalability-iseda-2025-pek" title="Permanent link">&para;</a></h4>
<h5 id="background_52">background<a class="headerlink" href="#background_52" title="Permanent link">&para;</a></h5>
<ul>
<li>Multi-row standard cells are widely adopted in advanced technology nodes, especially for complicated and large cells like multi-bit flip-flops(MBFFs).   </li>
</ul>
<p><img alt="image-20250614213428550" src="../assets/image-20250614213428550.png" /></p>
<ul>
<li>
<p>In advanced technology nodes, standard cell libraries have expanded to include a larger variety and number of cells, which makes manual design more time-consuming.   </p>
</li>
<li>
<p>the height of standard cells in advanced nodes has been steadily reduced  </p>
</li>
</ul>
<p><img alt="image-20250614210915175" src="../assets/image-20250614210915175.png" /></p>
<ul>
<li>
<p>multi-row standard cells typically contain a higher number of transistors  </p>
</li>
<li>
<p><img alt="image-20250614211754985" src="../assets/image-20250614211754985.png" /></p>
</li>
<li>
<p>相关工作比较少，之前解决这个问题使用的基于one-row的算法然后通过折叠等方式变成multi-row, 难以获得全局最优解</p>
</li>
<li></li>
</ul>
<h2 id="circuit-representation">Circuit Representation<a class="headerlink" href="#circuit-representation" title="Permanent link">&para;</a></h2>
<h4 id="netlistgnn-gnn-congestion-nips-2022-gnn-ark"><a href="">NetlistGNN-GNN Congestion-NIPS-2022-GNN-Ark</a><a class="headerlink" href="#netlistgnn-gnn-congestion-nips-2022-gnn-ark" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://github.com/PKUterran/NetlistGNN">OpenSource!</a></li>
<li>can be a post-placement congestion predictor, also for some other task, not like LHNN。也做了Net WL预测的实验</li>
<li>这篇文章的 geometrical 信息也是用GNN实现的</li>
<li>貌似推理很快，可以看看</li>
<li>强调了这是一个general的Circuit Representaion的工作</li>
<li>他的公式写的很好看，可以借鉴一下</li>
</ul>
<h5 id="background_53">background<a class="headerlink" href="#background_53" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>the two most informative ones: the netlist and the design layout; handling each information source independently is sub-optimal  </p>
</li>
<li>
<p>categorize  into <code>topological methods</code>[4, 5, 6]   and <code>geometrical methods.</code>   [7, 8, 9]  </p>
</li>
</ul>
<p>topological methods only consider the topological information in netlists and cannot effectively perceive geometrical structure introduced <mark>after the placement</mark> stage, so their performance on circuits after placement is greatly stifled.   </p>
<p>the geometrical models heavily rely on geometrical information and neglect the topology underlying the netlists, so they cannot handle circuits in stages earlier than global placement where geometry is not available.   </p>
<h5 id="contribution_42">contribution<a class="headerlink" href="#contribution_42" title="Permanent link">&para;</a></h5>
<ul>
<li><code>Circuit Graph</code>: a heterogeneous graph  with a linear time consumption to the scale of the design  </li>
<li><code>Circuit GNN</code>:  </li>
</ul>
<h5 id="flow_39">flow<a class="headerlink" href="#flow_39" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250921000705159" src="../assets/image-20250921000705159.png" /></p>
<h5 id="model_36">model<a class="headerlink" href="#model_36" title="Permanent link">&para;</a></h5>
<p>graph：</p>
<p><img alt="image-20250921000724862" src="../assets/image-20250921000724862.png" /></p>
<blockquote>
<p>shift-window的线性复杂度实现！</p>
</blockquote>
<h5 id="data_28">data<a class="headerlink" href="#data_28" title="Permanent link">&para;</a></h5>
<p>Congestion Prediction  <a href="http://www.ispd.cc/contests/11/ispd2011_contest.html">ISPD2011  Contest</a></p>
<p>Net Wirelength Prediction  <a href="http://archive.sigda.org/dac2012/contest/dac2012_contest.html">DAC2012  contest</a></p>
<h5 id="experiment_32">experiment<a class="headerlink" href="#experiment_32" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250921001533660" src="../assets/image-20250921001533660.png" /></p>
<p><img alt="image-20250921001953449" src="../assets/image-20250921001953449.png" /></p>
<blockquote>
<p>[!WARNING]</p>
<p>但是没有说这些对比模型是怎么设计的</p>
</blockquote>
<h2 id="floorplan">Floorplan<a class="headerlink" href="#floorplan" title="Permanent link">&para;</a></h2>
<h4 id="incredflip-dataflow-driven-macro-filp-iseda-2025-sjtu-"><a href="">IncreDFlip-dataflow driven Macro filp-ISEDA-2025-SJTU-</a><a class="headerlink" href="#incredflip-dataflow-driven-macro-filp-iseda-2025-sjtu-" title="Permanent link">&para;</a></h4>
<h2 id="-a-methodology-that-leverages-dataflow-information-to-narrow-the-search-space-and-utilizes-dataflow-decomposition-from-the-synthesized-netlist-to-guide-flipping-decisions">- a methodology that leverages dataflow information to narrow the search space and utilizes dataflow decomposition from the synthesized netlist to guide flipping decisions.<a class="headerlink" href="#-a-methodology-that-leverages-dataflow-information-to-narrow-the-search-space-and-utilizes-dataflow-decomposition-from-the-synthesized-netlist-to-guide-flipping-decisions" title="Permanent link">&para;</a></h2>
<h5 id="background_54">background<a class="headerlink" href="#background_54" title="Permanent link">&para;</a></h5>
<ul>
<li>传统macro都是用手摆的, macro 越来越多</li>
<li>Typically, mixed-size placers [2], [8], [9] or macro placers [10], [7], [11] consider flipping as one among several co-optimization strategies during placement which will lead to sub-optimal placement outcomes.   </li>
<li></li>
</ul>
<h5 id="contribution_43">contribution<a class="headerlink" href="#contribution_43" title="Permanent link">&para;</a></h5>
<h2 id="-a-dataflow-driven-flipping-approach-to-reduce-the-search-space-and-time-complexity">- a <mark>dataflow-driven</mark> flipping approach to reduce the <mark>search space</mark> and <mark>time complexity</mark><a class="headerlink" href="#-a-dataflow-driven-flipping-approach-to-reduce-the-search-space-and-time-complexity" title="Permanent link">&para;</a></h2>
<h5 id="flow_40">flow<a class="headerlink" href="#flow_40" title="Permanent link">&para;</a></h5>
<h5 id="model_37">model<a class="headerlink" href="#model_37" title="Permanent link">&para;</a></h5>
<h5 id="data_29">data<a class="headerlink" href="#data_29" title="Permanent link">&para;</a></h5>
<h5 id="experiment_33">experiment<a class="headerlink" href="#experiment_33" title="Permanent link">&para;</a></h5>
<h2 id="toread">toread<a class="headerlink" href="#toread" title="Permanent link">&para;</a></h2>
<h4 id="algorithms_and_data_structures_for_fast_and_good_vlsi_routing"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=6241546">Algorithms_and_data_structures_for_fast_and_good_VLSI_routing</a><a class="headerlink" href="#algorithms_and_data_structures_for_fast_and_good_vlsi_routing" title="Permanent link">&para;</a></h4>
<h4 id="rsmt_1">一堆关于 RSMT 的论文<a class="headerlink" href="#rsmt_1" title="Permanent link">&para;</a></h4>
<h4 id="dr-ispd-contest-tritonroute-dr-cu-draps-rdta">DR ISPD contest: TritonRoute, Dr. CU, DRAPS, RDTA<a class="headerlink" href="#dr-ispd-contest-tritonroute-dr-cu-draps-rdta" title="Permanent link">&para;</a></h4>
<p>TritonRoute [15] adopted integer linear programming (ILP) for parallel intralayer routing. DRAPS [18] developed an A*-interval-based path search algorithm to handle complicated design rules. Dr. CU [16], [17], [21] proposed an optimal correct-by-construction path search algorithm and a two-level sparse data structure for runtime and memory efficiency. RDTA [19] developed an analytical approach to solve the track assignment problem following the global routing guides.   </p>
<h4 id="dr-pin-acess-a-multithreaded-initial-detailed-routing-algorithm-considering-global-routing-guides">DR Pin Acess: A multithreaded initial detailed routing algorithm considering global routing guides<a class="headerlink" href="#dr-pin-acess-a-multithreaded-initial-detailed-routing-algorithm-considering-global-routing-guides" title="Permanent link">&para;</a></h4>
<h4 id="salt-tcad-2020-cuhk"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=8624460">SALT- -TCAD-2020- -CUHK</a><a class="headerlink" href="#salt-tcad-2020-cuhk" title="Permanent link">&para;</a></h4>
<h4 id="timing-driven-routing-iccad-2023-ustc"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10323981">Timing-Driven Routing-ICCAD-2023-USTC</a><a class="headerlink" href="#timing-driven-routing-iccad-2023-ustc" title="Permanent link">&para;</a></h4>
<h4 id="timing-iccad-2024_guo"><a href="......\Download\TIMING_ICCAD2024_Guo.pdf">TIMING-ICCAD-2024_Guo</a><a class="headerlink" href="#timing-iccad-2024_guo" title="Permanent link">&para;</a></h4>
<h4 id="gpu-accelerated_static_timing_analysis"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=9256516">GPU-Accelerated_Static_Timing_Analysis</a><a class="headerlink" href="#gpu-accelerated_static_timing_analysis" title="Permanent link">&para;</a></h4>
<h4 id="an-optimization-aware-pre-routing-timing-prediction-framework-based-on-multi-modal-learning"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10909720">An Optimization-aware Pre-Routing Timing Prediction Framework Based on Multi-modal Learning</a><a class="headerlink" href="#an-optimization-aware-pre-routing-timing-prediction-framework-based-on-multi-modal-learning" title="Permanent link">&para;</a></h4>
<h4 id="-chip-placement-arxiv-2020-gnnrl-google"><a href="https://arxiv.org/pdf/2004.10746">-Chip Placement-arxiv-2020-GNN+RL-Google</a><a class="headerlink" href="#-chip-placement-arxiv-2020-gnnrl-google" title="Permanent link">&para;</a></h4>
<h4 id="-drl-rosmt-trans-2023-drl-fzupek"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10816669">-DRL ROSMT-Trans-2023-DRL-FZU+PEK</a><a class="headerlink" href="#-drl-rosmt-trans-2023-drl-fzupek" title="Permanent link">&para;</a></h4>
<h4 id="-adaptive-route-guides-asp-dac-2024-xu"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=10473934">-Adaptive Route Guides-ASP DAC-2024-XU</a><a class="headerlink" href="#-adaptive-route-guides-asp-dac-2024-xu" title="Permanent link">&para;</a></h4>
<h4 id="-asynchronous-rlknowledge-transfer-trans-2023-rl-pek"><a href="https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&amp;arnumber=9557780">-Asynchronous RL+Knowledge Transfer-Trans-2023-RL-PEK</a><a class="headerlink" href="#-asynchronous-rlknowledge-transfer-trans-2023-rl-pek" title="Permanent link">&para;</a></h4>
<h5 id="background_55">background<a class="headerlink" href="#background_55" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>串行布线下的 net order 对布线收敛结果影响很大，尤其在先进工艺节点下，设计规则愈加复杂且布线规模庞大，到时 net order 的影响更大</p>
</li>
<li>
<p>以往的工作往往使用简单的启发式方法对特定的 benchmark 进行优化</p>
</li>
<li>
<p>传统方法依赖于简单的 <mark>启发式规则</mark>（如网络覆盖区域大小、引脚数量等）确定布线顺序，比如：the number of pins in a net; 2) the number of DRC violations caused by a net [23]; 3) the region size covered by a net [17]; and 4) the distance from a certain point [24] 。但由于不同设计差异大，这类固定策略难以通用化，导致布线质量（如 DRC 违规、绕线长度等）不稳定。现有方法在应对大规模、多样化设计时缺乏灵活性，因此亟需一种自动化、可泛化的网络顺序优化方案。</p>
</li>
<li>
<p>DRC</p>
</li>
</ul>
<p><img alt="image-20250316151037763" src="../assets/image-20250316151037763.png" /></p>
<ul>
<li>
<p>In this work, we adopt Dr.CU as the target detailed routing framework for studying, while the methodology can work on other routers as well.   </p>
</li>
<li>
<p><img alt="image-20250316151304676" src="../assets/image-20250316151304676.png" /></p>
</li>
<li>
<p><img alt="image-20250316152913499" src="../assets/image-20250316152913499.png" /></p>
</li>
</ul>
<p>Although the wirelength does not change much, the order affects both via count and the number of <code>DRC violations</code>.  </p>
<ul>
<li><code>Dr.CU</code> sorts nets by the routing region sizes (half-perimeter of the bounding box) of each net in descent order. In other words, <mark>nets covering large routing regions are routed first.</mark>  However, we observe that the routing region sizes of different nets can be very similar, leading to random orders between these nets, and eventually causing high variations in the final violations.   For example, Fig. 3 shows that 5293 nets have the same routing region size, accounting for 14.4 % of the total number of nets in benchmark ispd18_test3.   Therefore, there is a potential to improve the routing performance by developing an ordering strategy considering more features  </li>
</ul>
<p><img alt="image-20250316153631925" src="../assets/image-20250316153631925.png" /></p>
<ul>
<li>
<p>RL: One of the main obstacles in using supervised ML-based techniques for solving routing problems, especially the net ordering problems, is the lack of golden labeled datasets to learn.   </p>
</li>
<li>
<p>metrics：</p>
</li>
<li>
<p>the total wirelength of all nets;  </p>
</li>
<li>the number of the total used vias  </li>
<li>the number of DRC violations.  </li>
</ul>
<h5 id="contribution_44">contribution<a class="headerlink" href="#contribution_44" title="Permanent link">&para;</a></h5>
<ol>
<li><strong>异步强化学习框架</strong>：</li>
<li>提出基于 <strong>A3C（异步优势演员-评论家）</strong> 的异步 RL 框架，支持多智能体并行训练，加速策略搜索。 </li>
<li><strong>状态特征</strong>：定义 7 维网络级特征（如布线区域尺寸、相邻网络重叠度、历史重布次数等），输入策略网络生成排序评分。</li>
<li><strong>奖励机制</strong>：结合总成本（线长、通孔数、DRC 违规）与基线策略，引入 <strong>不匹配惩罚项</strong>，引导智能体学习优于默认启发式策略的排序策略。</li>
<li><strong>基于策略蒸馏的迁移学习算法</strong>：</li>
<li>通过 <strong>小区域剪裁</strong>（从目标设计截取约 500 个网络的密集子区域）进行微调，避免全设计训练的高开销。 </li>
<li>利用教师网络（已预训练的通用策略）指导学生网络（针对目标设计的定制策略），最小化两者策略分布的 KL 散度，实现高效知识迁移。 </li>
<li><strong>模型无关的灵活架构</strong>：</li>
<li>网络结构 <strong>解耦设计规模</strong>，通过独立编码每个网络的局部特征再拼接，支持不同设计间策略共享，避免输入尺寸约束。</li>
</ol>
<h5 id="model_38">model<a class="headerlink" href="#model_38" title="Permanent link">&para;</a></h5>
<h6 id="enviroment">enviroment<a class="headerlink" href="#enviroment" title="Permanent link">&para;</a></h6>
<p><code>Dr. Cu</code></p>
<p>每一个 step 就要跑一次 <code>Dr.Cu</code>，训练不是很慢？</p>
<p>而且什么时候 episode 结束？</p>
<h6 id="state_1">state<a class="headerlink" href="#state_1" title="Permanent link">&para;</a></h6>
<p>is the collective representation of features for <mark>all nets</mark>.</p>
<p><img alt="image-20250316155614349" src="../assets/image-20250316155614349.png" /></p>
<p><code>Cost</code> 具体是指什么？</p>
<p>state 很大啊</p>
<h6 id="action_2">action<a class="headerlink" href="#action_2" title="Permanent link">&para;</a></h6>
<p>An action a is a real number vector. Each number is defined as an ordering score of a net.  </p>
<p><code>之前做的都是很少个的action</code></p>
<h6 id="reward_2">reward<a class="headerlink" href="#reward_2" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250316161153277" src="../assets/image-20250316161153277.png" /></p>
<p><img alt="image-20250316161214905" src="../assets/image-20250316161214905.png" /></p>
<p>可以使用 <code>Dr.Cu</code> 的 net order 进行初始的排序，而不是从随机开始，提高模型收敛速度。尤其是这个难收敛的任务，很重要</p>
<p><img alt="image-20250316165056621" src="../assets/image-20250316165056621.png" /></p>
<p><img alt="image-20250316165214850" src="../assets/image-20250316165214850.png" /></p>
<p>it will speed up the training, but not limit the exploration space to the heuristic ordering strategy used in <code>Dr.CU</code>.   </p>
<h6 id="a3c">A3C<a class="headerlink" href="#a3c" title="Permanent link">&para;</a></h6>
<p><img alt="image-20250316163725745" src="../assets/image-20250316163725745.png" /></p>
<p><img alt="image-20250316163407987" src="../assets/image-20250316163407987.png" /></p>
<p>Intuitively, the policy network tells us the ordering scores of the nets and the value network evaluates the scores in the sense of future rewards  </p>
<p><img alt="image-20250316163738250" src="../assets/image-20250316163738250.png" /></p>
<p>输出的不是一个具体的 action，而是一个分布。 We pick the action by sampling from this normal distribution p.   </p>
<p><img alt="image-20250316164147810" src="../assets/image-20250316164147810.png" /></p>
<p>这样有什么效果？：（没理解）</p>
<p><img alt="image-20250316164738691" src="../assets/image-20250316164738691.png" /></p>
<h6 id="transfer-learning-algorithm">TRANSFER LEARNING ALGORITHM<a class="headerlink" href="#transfer-learning-algorithm" title="Permanent link">&para;</a></h6>
<ul>
<li>Our task is to mine the knowledge from the pretrained policy and adapt to a target design to improve the performance  </li>
<li>If we can customize the policy for each design with low overhead, there is an opportunity to improve the performance further.  </li>
<li>To reduce the overhead of customization, we fine-tune the well-trained policy from the previous section using a <mark>small region clipped</mark>  </li>
</ul>
<h4 id="dierouter-fpga-die-routing-dp-shandong-"><a href="">DieRouter+- FPGA Die Routing-DP-ShanDong-</a><a class="headerlink" href="#dierouter-fpga-die-routing-dp-shandong-" title="Permanent link">&para;</a></h4>
<h5 id="background_56">background<a class="headerlink" href="#background_56" title="Permanent link">&para;</a></h5>
<ul>
<li><img alt="image-20250614235302025" src="../assets/image-20250614235302025.png" /></li>
<li>大型数字设计往往需要使用多块<code>FPGA（MFS）</code>进行原型验证</li>
<li><code>2.5D FPGA</code> integrates <mark>multiple dies</mark> and offers significantly higher capacity than a traditional <mark>single-die</mark> FPGA  </li>
<li>Super Long Lines (SLLs)  </li>
<li>Time-Division Multiplexing (TDM)  多路分时复用，是一种串并-并串转换IP. 缓解FPGA的外部Pin不够问题。这个IP可以调节等效Pin个数，Ratio越大，延时越大。</li>
<li></li>
</ul>
<h5 id="contribution_45">contribution<a class="headerlink" href="#contribution_45" title="Permanent link">&para;</a></h5>
<ul>
<li>a simpler yet more effective initial routing method based on <code>shortest path trees</code></li>
<li>a <code>Second-Order Cone Programming formulation</code> of an extended relaxed TDM assignment problem to compute <mark>optimal continuous TDM ratios</mark></li>
<li>a <code>scheduler-driven Dynamic Programming (DP)</code>- based legalization technique that adaptively schedules state evaluations</li>
</ul>
<h5 id="flow_41">flow<a class="headerlink" href="#flow_41" title="Permanent link">&para;</a></h5>
<p><img alt="image-20250615112501557" src="../assets/image-20250615112501557.png" /></p>
<h5 id="data_30">data<a class="headerlink" href="#data_30" title="Permanent link">&para;</a></h5>
<p>2023 EDA Elite Design Challenge  </p>
<h2 id="_9">综述<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<h3 id="ml4pr">ML4PR<a class="headerlink" href="#ml4pr" title="Permanent link">&para;</a></h3>
<p><a href="https://blog.csdn.net/SP_FA/article/details/134063224">Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview</a></p>
<p><img alt="image-20241101173512416" src="../assets/image-20241101173512416.png" /></p>
<p>放置和布线是两个不可或缺且具有挑战性的 NP-hard 问题</p>
<p>机器学习凭借其数据驱动的性质显示出了广阔的前景，它可以减少对知识和先验的依赖，并且通过其先进的计算范式具有更大的可扩展性 (例如 GPU 加速的深度网络)</p>
<p><strong>挑战:</strong></p>
<p>placement:</p>
<ul>
<li>在路由完成之前，无法评估诸如可达性之类的放置目标；因此，在优化循环中可能需要花费数小时才能获得反馈，这对于进行数千次查询来说是负担不起的</li>
<li>现代的放置器需要在几个小时内处理数万个宏和数百万个标准单元。这种可扩展性的要求仍然超出了现有 ML 方法的能力</li>
</ul>
<p>routing:</p>
<ul>
<li>在公平的比较下，现有技术很难在效率和求解质量上系统地优于经典布线算法</li>
<li>大多数基于学习的技术在具有数千个网络的小型电路上工作得很好，而实际的布线引擎需要在超大型 3D 网格图 ( &gt; 1000 × 1000 × 10 ) (&gt; 1000 × 1000 × 10)(&gt; 1000×1000×10) 上有效地处理数百万个网络并产生高质量的解决方案</li>
</ul>
<p>相关工作</p>
<ul>
<li>
<p>placement</p>
</li>
<li>
<p><img alt="image-20241101175552665" src="../assets/image-20241101175552665.png" /></p>
</li>
<li><img alt="image-20241101175600184" src="../assets/image-20241101175600184.png" /></li>
<li>
<p><img alt="image-20241101175612168" src="../assets/image-20241101175612168.png" /></p>
</li>
<li>
<p>Routing</p>
</li>
<li>
<p><img alt="image-20241101175915691" src="../assets/image-20241101175915691.png" /></p>
<p><img alt="image-20241101175922593" src="../assets/image-20241101175922593.png" /></p>
<p><img alt="image-20241101175934137" src="../assets/image-20241101175934137.png" /></p>
</li>
<li>
<p><img alt="image-20241101180007732" src="../assets/image-20241101180007732.png" /></p>
</li>
<li>
<p><img alt="image-20241101180029509" src="../assets/image-20241101180029509.png" /></p>
</li>
</ul>
<h3 id="_10">超大规模集成电路布线算法综述<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<p><a href="https://www.sciengine.com/MNEIM/doi/10.19816/j.cnki.10-1594/TN.2021.02.086">超大规模集成电路布线算法综述</a></p>
<h5 id="background_57">background<a class="headerlink" href="#background_57" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241116095906162" src="../assets/image-20241116095906162.png" /></p>
<p><img alt="image-20241116095924293" src="../assets/image-20241116095924293.png" /></p>
<p><img alt="image-20241116095932126" src="../assets/image-20241116095932126.png" /></p>
<p>布线相关详细看 routing2.md, 详细布线、面向可制造性设计的布线算法 还没记录</p>
<h3 id="edagnn">EDA+GNN<a class="headerlink" href="#edagnn" title="Permanent link">&para;</a></h3>
<p>详细看 <a href=".\notebak\EDA+GNN.md">A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks</a></p>
<h2 id="_11">参考<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="AI技术带给EDA的机遇和挑战-Yibo Lin.pdf">AI 技术带给 EDA 的机遇和挑战</a></li>
<li><a href="[[读论文] Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview_toward machine learning....lake-CSDN博客](https://blog.csdn.net/SP_FA/article/details/134063224)">Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview</a></li>
<li><a href="https://blog.csdn.net/sxf1061700625/article/details/127865492">【阅读】A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN 综述翻译_ppaml-CSDN 博客</a></li>
</ol>
<h2 id="bak">bak<a class="headerlink" href="#bak" title="Permanent link">&para;</a></h2>
<p><a href="">CongestionNet-Congestion Prediction-IFIP-2019-GNN</a></p>
<p><a href="">-placement Congestion prediction-arXiv-2021-GNN</a></p>
<p><img alt="image-20241101171055570" src="../assets/image-20241101171055570.png" /></p>
<p>输入：网表</p>
<p>输出：congestion at placement stage</p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10528675">EDA-ML: Graph Representation LearningFramework for Digital IC Design Automation</a></p>
<p>德雷塞尔大学电气与计算机工程系 Pratik Shrestha 和 Ioannis Savidis</p>
<h5 id="background_58">background<a class="headerlink" href="#background_58" title="Permanent link">&para;</a></h5>
<p>VLSI : traditional methodologies -&gt; ML, Graph representation learning  ability to capture complex relationships in graph-structured data  </p>
<p>GNN：</p>
<p><img alt="image-20241116142013379" src="../assets/image-20241116142013379.png" /></p>
<p><img alt="image-20241116142052562" src="../assets/image-20241116142052562.png" /></p>
<h5 id="task_13">task<a class="headerlink" href="#task_13" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241116143449696" src="../assets/image-20241116143449696.png" /></p>
<h5 id="flow_42">flow<a class="headerlink" href="#flow_42" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241116144708326" src="../assets/image-20241116144708326.png" /></p>
<h5 id="data_31">data<a class="headerlink" href="#data_31" title="Permanent link">&para;</a></h5>
<p><img alt="image-20241116155309167" src="../assets/image-20241116155309167.png" /></p>
<p><img alt="image-20241116143927933" src="../assets/image-20241116143927933.png" /></p>
<p><img alt="image-20241116155354597" src="../assets/image-20241116155354597.png" /></p>
<p><strong>模型</strong></p>
<p><img alt="image-20241116155947525" src="../assets/image-20241116155947525.png" /></p>
<p><img alt="image-20241116155857412" src="../assets/image-20241116155857412.png" /></p>
<p><strong>实验</strong></p>
<p><img alt="image-20241116160529100" src="../assets/image-20241116160529100.png" /></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../EDA4PR-Analog/" class="btn btn-neutral float-left" title="EDA4PR-Analog"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../EDA4PR-LCM/" class="btn btn-neutral float-right" title="EDA4PR-LCM">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../EDA4PR-Analog/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../EDA4PR-LCM/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
