# EDA4PR-Digtal

## Cross-Stage Prediction

- Earlystage prediction can enhance design quality by proactively detecting potential design issues in advance  --cite-->[cluster-net]
- `Shift left`å‡ºå¤„ï¼šV. Bhardwaj, â€œShift left trends for design convergence in soc: An eda perspective,â€ International Journal of Computer Applications, vol. 174, no. 16, pp. 22â€“27, Jan 2021  

### congestion

#### background

- Routing congestion can overwhelm routing resources and lead to low cell utilization and routing detours  

- congestion is not known accurately until late in the design cycle, after placement and routing.  

- Many modern placement and synthesis tools leverage congestion estimation in their cost analysis in order to minimize the effects of congestion in the final physical design 

- ![image-20241101193119582](./assets/image-20241101193119582.png)

- It is known that the total net length can be a good proxy for congestion   

- A simple approximation for congestion prediction is to use the size of the local neighborhood  

- ![image-20241102170308031](./assets/image-20241102170308031.png)

- å’Œ fan-in, fan-out å¼ºç›¸å…³

- Precise congestion prediction from a placement solution plays a crucial role in circuit placement   
- Multiple **previous works** have attempted to predict detailed routing congestion in the **placement step** in an effort to optimize routability of the placement solution: RUDY, POLAR 2.0. All these techniques are implemented  in the placement step and need the position information of cells .

- To avoid the high computation cost of placement, it is more useful to be able to predict congestion in the logic synthesis phase.   

- congestion prediction problem can be frame as **node regression problem**  
- with the growth of circuit scale and complexity, time consumption
  tends to be unacceptable when utilizing a **global router** in the placement cycle to obtain the **congestion map**.  
- Current machine learning models commonly follow a two-phase workflow. First, based on domain knowledge, human experts generate various local features on the circuit using predefined functions on netlist. Then, based on the generated features, a specific model, e.g. convolution neural network (CNN) model is designed to predict either the routing demand map or the congestion map  
- the emergence of **Graph Neural Network (GNN)** triggered applications of undirected homogeneous graphs models on routing congestion prediction, since a VLSI circuit can be naturally represented by a graph  

#### [RouteNet-DRC Hotspot Prediction-ICCAD-2018-CNN](https://zhiyaoxie.com/files/ICCAD18_RouteNet.pdf)

##### background

- Every chip design project must complete routing **without design rule violation** before tapeout. However, this basic requirement is often difficult to be satisfied especially when routability is not adequately considered in early design stages.  

- In light of this fact, routability prediction has received serious attention in both academic research and industrial tool development. Moreover, routability is widely recognized as a main objective for **cell placement**  

- CNN and Transfer Learning  

  - CNN learns more abstract patterns from images  
  - Our RouteNet transfers such state-of-the-art ability in image pattern recognition to circuits for capturing the patterns about routability. RouteNet predicts routability based on a pretrained ResNet architecture  
  - Fully Convolutional Network (FCN): outputs an image with size equal to or smaller than input.   many FCNs have both deep and shallow paths in one network.   

- RUDY(Rectangular Uniform wire DensitY)

  - å®ƒè¢«ç”¨ä½œæˆ‘ä»¬ RouteNet çš„è¾“å…¥ç‰¹å¾ï¼Œå› ä¸ºå®ƒä¸è·¯ç”±æ‹¥å¡éƒ¨åˆ†ç›¸å…³ï¼Œè·å–é€Ÿåº¦å¿«ï¼Œå¯ä»¥ç›´æ¥è¡¨ç¤ºä¸ºä¸ RouteNet ç›¸å»åˆçš„å›¾åƒ

- challenge of macros

  ![image-20250205214716706](./assets/image-20250205214716706.png)

  - The orange circles in Figure 3 indicate a strong tendency for hotspots to aggregate at the small gap between neighboring macros  
  - Blue dashed circles indicate the remaining sparsely distributed hotspots 
  - ![image-20250205220737891](./assets/image-20250205220737891.png)
  - æœ‰ macroï¼Œçº¿æ€§ç¨‹åº¦ä½

##### task

- predict overall routability (DRC count), åˆ†ç±»ä»»åŠ¡ï¼Œé¢„æµ‹æ€»çš„#DRV
- predict `DRC hotspot` locations.DRC hotspots mean the specific locations with high density of DRVs. like an end-to-end object detection task, which is more difficult to solve. GCell å†…#DRV è¶…è¿‡è®¾å®šå€¼åˆ™ä¸º `DRC hotspot`



##### contribution:

![image-20250205210214325](./assets/image-20250205210214325.png)

- mixed-size macros
- first systematic study on CNN-based routability prediction  
- high accuracy and high speed  



##### flow

![image-20250205222502598](./assets/image-20250205222502598.png)



##### model

- \#DRV prediction

  ResNet18-based

  ![image-20250205223554347](./assets/image-20250205223554347.png)

  preprocess

  - ![image-20250205223153166](./assets/image-20250205223153166.png)

  - ![image-20250205223742770](./assets/image-20250205223742770.png)

    ResNet æ˜¯ä¸€ä¸ªå›ºå®šè¾“å…¥ï¼ˆ224*224ï¼‰çš„æ¨¡å‹ï¼Œä¸ºäº†ä½¿ç”¨çŸ¥è¯†è¿ç§»ï¼Œå°†è¾“å…¥ ![image-20250205223849469](./assets/image-20250205223849469.png) é€šè¿‡æ’å€¼çš„æ–¹æ³•å˜æˆ ![image-20250205223907748](./assets/image-20250205223907748.png)ã€‚å…·ä½“æ€ä¹ˆæ’ï¼Ÿ

  

- hotspot prediction



![image-20250205224325007](./assets/image-20250205224325007.png)



##### data

dataset:

ISPD 2015 benchmarks  

![image-20250205225007139](./assets/image-20250205225007139.png)

different placement made by â€œobstacle-aware macro placement " algorithm [5].  

each floorplan is placed and routed by Cadence Encounter v14.20 [2]  

##### experiment

![image-20250205230614878](./assets/image-20250205230614878.png)



![image-20250205230628088](./assets/image-20250205230628088.png)

![image-20250205230725019](./assets/image-20250205230725019.png)

we compare the TPR of all methods under the same FPR (error under 1%)



![image-20250205230816030](./assets/image-20250205230816030.png)

#### [CongestionNet-predict congestion hotspots-IFIP-2019-GNN(GAT)-nvidia](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8920342&tag=1)

a **graph**-based deep learning method for predicting **routing congestion hotspots** from a **netlist** before placement.  Predict the ==detail routed== **lower metal layer** congestion values  

![image-20241101192745004](./assets/image-20241101192745004.png)

why low layer? å› ä¸ºè¾ƒä½é‡‘å±å±‚ä¸Šçš„æ‹¥å¡ä¸»è¦æ˜¯ç”±å±€éƒ¨é€»è¾‘ç»“æ„é©±åŠ¨çš„ï¼Œè€Œä¸æ˜¯ç”±æ— å…³é€»è¾‘ç°‡ä¹‹é—´çš„è¾ƒé•¿äº’è¿é©±åŠ¨çš„ï¼Œåè€…å¾€å¾€åœ¨è¾ƒé«˜é‡‘å±å±‚ä¸Šè¿è¡Œ. predicting lower metal layer congestion is not only more important for the underlying task of identifying congested logic structures, but also simplifies the task for our
graph based network  



##### contribution

- é˜¶æ®µæ—©, åªä½¿ç”¨ç½‘è¡¨
- ç”±äºè¯¥æ¨¡å‹ä»…åŸºäºç½‘è¡¨çš„é€»è¾‘ç»“æ„è€Œä¸æ˜¯ä»»ä½•ç‰¹å®šçš„å•å…ƒå¸ƒå±€è¿›è¡Œé¢„æµ‹ï¼Œå› æ­¤å®ƒæ¶ˆé™¤äº†åŸºäºå¸ƒå±€çš„æ–¹æ³•ä¸­å­˜åœ¨çš„æ¬¡ä¼˜å¸ƒå±€çš„ä¼ªå½± ![image-20241101192504194](./assets/image-20241101192504194.png)
- can be done without any physical information  
- GNN, å¿«
- the first work exploring the use of graph based deep learning for physical design problems  



**æ•°æ®:**

![image-20241101194746768](./assets/image-20241101194746768.png)

![image-20241101195219055](./assets/image-20241101195219055.png)

roughly 5000 distinct cell types  

we project our per cell predictions back onto their respective 2D grid (using the **final ground truth physical placement**) and average all cells within each grid cell to come up with a predicted value that can be compared to the original ground truth grid value.  



**æ¨¡å‹å‚æ•°:**

an 8 layer Graph Attention Network (GAT) with size 16 intermediate (or hidden) state  

æ— å‘å›¾, each node corresponds to a cell 

èŠ‚ç‚¹ç‰¹å¾: length 50 for each **cell type** and each cellâ€™s **logic description** as well as the **pin count** and **cell size** of that cell



**å®éªŒ:**

report correlation values using the **Kendall ranking coefficient**  

å®é™…æ•ˆæœå¯è§†åŒ–

![image-20241101211844804](./assets/image-20241101211844804.png)



![image-20241007114109425](./assets/image-20241007114109425.png)

å¯¹æ¯”å®éªŒ

![image-20241101214611345](./assets/image-20241101214611345.png)

æ¶ˆèå®éªŒ

![image-20241101214630174](./assets/image-20241101214630174.png)

cell type or function is an essential part of our predictions.   

cell type ä¸æ˜¯æ²¡èµ·ä½œç”¨å—



**ç¼ºç‚¹:** 

- model needs to be **retrained** for every **new process technology**, since the embeddings are over cell types specific to a process technology.  
- it occasionally over predicts congestion in areas of **low to moderate** congestion, such as in most failing parts of Partition A  
- due to the **graph based** nature of the model, it sometimes makes **overly soft decision** boundaries  
- ![image-20241102170708557](./assets/image-20241102170708557.png)
- the CongestionNet uses informative cell attributes (cell size and pin count) alone as the input to the GAT and does not use any embedding encoding the netlist structure  



**å¯æ”¹è¿›çš„ç‚¹:**

![image-20241101215450089](./assets/image-20241101215450089.png)



#### [-Congestion prediction + embedding + matrix factorization + partition-arXiv-2021-GNN(Sage)-NAL+]()

- a framework that can directly learn embeddings for the given netlist to enhance the quality of our node features  
- ç›®çš„æ˜¯ä½¿ç”¨ç½‘è¡¨æ•°æ®ï¼Œå‡å°‘ placement è¿­ä»£
- The key difference between this work and [CongestionNet]() model lies in our construction of an ==embedding== pipeline for EDA netlists  

##### background

- predicting cell congestion due to improper logic combination can reduce the burden of subsequent physical implementations.  

- previous work: require informative cell features 

- an awareness of high congestion areas at an early design stage is of great importance to provide fast feedback and shorten design cycles  

- Although the global routing result provides a good estimation of routing congestion [6], [19], an awareness of high congestion areas at an **early** design stage is of great importance to provide fast feedback and shorten design cycles

- Multiple works have attempted to predict detailed **routing congestion** in the placement step in an effort to optimize **routability** of the placement solution  

- The process of node embedding involves learning a free vector ev for each node.   

- Embedding learning has achieved great success in the field of Natural Language Processing (NLP), where methods such as Word2Vec   

- Random-walk based embedding method  

  - Node2vec, LINE, DeepWalk
  - These methods are derived from the skip-gram encoding method Word2vec   
  - there are two aspects of EDA that pose difficulties for standard random-walk based methods  
    1. the typical circuit is extremely large   
    2. in the congestion prediction context, the desired prediction is often on the unseen cells in a new circuit.   (åƒæ–‡æœ¬é‚£ç§ï¼Œåº”è¯¥æ˜¯æ‰€æœ‰æ–‡æœ¬éƒ½ä½œä¸ºè®­ç»ƒé›†ï¼Œæ‰€ä»¥å’Œç”µè·¯ä¸ä¸€æ ·)ã€‚training and testing on distinct graphs requires ==extra alignment post-processing== [26], [27], which is both challenging and extremely time consuming.  

- Embedding ==alignment==  

  Wasserstein-Procrustes alignment  

  uses a æ­£äº¤å˜æ¢çŸ©é˜µ $Q \in \mathbb{R}^{d \times d}$ å’Œæ’åˆ—ï¼ˆç½®æ¢ï¼‰çŸ©é˜µ $P \in \mathbb{R}^{V \times V} $ to align two graphs G, G' with $X \in \mathbb{R}^{V \times d}$

  ![image-20250301120251168](assets/image-20250301120251168.png)

  æœ€ç»ˆç›®æ ‡ï¼šè®©ä¸¤ä¸ªå›¾çš„èŠ‚ç‚¹åæ ‡å°½å¯èƒ½é‡åˆï¼Œå³ä½¿å®ƒä»¬æœ€åˆçœ‹èµ·æ¥ä¸ä¸€æ ·ã€‚

  ![image-20250301142650331](assets/image-20250301142650331.png)

  !!! note
      æ‰“ä¸ªæ¯”æ–¹ï¼šå‡è®¾ä½ æœ‰ä¸€ä¸ªç­çº§çš„åº§ä½è¡¨ï¼Œæ¯ä¸ªå­¦ç”Ÿçš„ä½ç½®ç”¨åæ ‡ï¼ˆæ¯”å¦‚ x, yï¼‰è¡¨ç¤ºã€‚ç°åœ¨éš”å£ç­ä¹Ÿæœ‰ä¸€ä¸ªåº§ä½è¡¨ï¼Œåº§ä½å½¢çŠ¶å’Œä½ ä»¬ç­å®Œå…¨ä¸€æ ·ï¼Œä½†å¯èƒ½ï¼š
      
      1. ä»–ä»¬çš„åº§ä½æ•´ä½“æ—‹è½¬äº†æŸä¸ªè§’åº¦ï¼ˆæ¯”å¦‚ä½ ä»¬ç­æ­£åŒ—æ–¹å‘æ˜¯è®²å°ï¼Œä»–ä»¬ç­æ­£ä¸œæ–¹å‘æ˜¯è®²å°ï¼‰
      2. å­¦ç”Ÿçš„åº§ä½ç¼–å·é¡ºåºè¢«æ‰“ä¹±äº†ï¼ˆæ¯”å¦‚ä½ ä»¬ç­ 1 å·ååœ¨å‰æ’å·¦ï¼Œä»–ä»¬ç­ 1 å·å¯èƒ½ååœ¨åæ’å³ï¼‰
      
      ### å¯¹åº”åˆ°å›¾ä¸­çš„æ¦‚å¿µï¼š
      
      1. **å›¾åµŒå…¥ï¼ˆNode Embeddingï¼‰**
          å°±åƒæŠŠæ¯ä¸ªå­¦ç”Ÿç”¨åæ ‡è¡¨ç¤ºï¼Œè¿™é‡Œçš„ "åæ ‡" å°±æ˜¯ç®—æ³•ç”Ÿæˆçš„ d ç»´å‘é‡ Xã€‚è¿™äº›åæ ‡è¦ä¿ç•™åŒå­¦ä¹‹é—´çš„å…³ç³»ï¼ˆæ¯”å¦‚ç»å¸¸äº’åŠ¨çš„åŒå­¦åæ ‡æ›´æ¥è¿‘ï¼‰ã€‚
      2. **æ­£äº¤å˜æ¢çŸ©é˜µ Q**
          ç›¸å½“äºæ—‹è½¬æˆ–é•œåƒæ•´ä¸ªåº§ä½è¡¨ï¼ˆæ¯”å¦‚æŠŠæ•´ä¸ªç­çº§çš„åº§ä½é¡ºæ—¶é’ˆè½¬ 90 åº¦ï¼‰ã€‚è¿™ç§å˜æ¢ä¸æ”¹å˜åŒå­¦ä¹‹é—´çš„ç›¸å¯¹è·ç¦»â€”â€”åŸæœ¬ååœ¨ä¸€èµ·çš„åŒå­¦ï¼Œæ—‹è½¬åè¿˜æ˜¯ååœ¨ä¸€èµ·ã€‚
      3. **æ’åˆ—çŸ©é˜µ P**
          ç›¸å½“äºé‡æ–°ç»™åº§ä½ç¼–å·ã€‚æ¯”å¦‚æŠŠåŸæœ¬ 1 å·åŒå­¦çš„æ ‡ç­¾è´´åˆ° 5 å·åº§ä½ä¸Šï¼Œä½†åº§ä½æœ¬èº«çš„ä½ç½®æ²¡å˜ã€‚è¿™å°±åƒæ´—ç‰Œä¸€æ ·æ‰“ä¹±é¡ºåºï¼Œä½†å®é™…åº§ä½å¸ƒå±€ä¸å˜ã€‚
      
      ### å…·ä½“åˆ°ä½ çš„é—®é¢˜ï¼š
      
      - **ç¬¬ä¸€æ­¥ï¼šå¯¹é½æ—‹è½¬/é•œåƒï¼ˆæ‰¾ Qï¼‰**
       å‡è®¾ä¸¤ä¸ªç­çº§åº§ä½å¸ƒå±€å®Œå…¨ä¸€æ ·ï¼Œä½†æ–¹å‘ä¸åŒã€‚æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ª "æ—‹è½¬è§’åº¦" Qï¼Œè®©ä¸¤ä¸ªç­çº§çš„åº§ä½è¡¨æ–¹å‘ä¸€è‡´ã€‚
      
       æ¯”å¦‚ä½ ä»¬ç­åº§ä½è¡¨æ˜¯æ­£å¸¸æ–¹å‘ï¼Œéš”å£ç­è¢«æ—‹è½¬äº† 90 åº¦ã€‚é€šè¿‡ Q è¿™ä¸ªæ—‹è½¬çŸ©é˜µï¼Œå¯ä»¥æŠŠä»–ä»¬çš„åº§ä½è¡¨è½¬å›æ¥ï¼Œè¿™æ ·ä¸¤ä¸ªç­çº§çš„åº§ä½åæ ‡å°±èƒ½å¯¹é½ã€‚
      
      - **ç¬¬äºŒæ­¥ï¼šå¯¹é½ç¼–å·é¡ºåºï¼ˆæ‰¾ Pï¼‰**
       å³ä½¿åº§ä½æ–¹å‘å¯¹é½äº†ï¼ŒåŒå­¦çš„ç¼–å·å¯èƒ½è¿˜æ˜¯ä¹±çš„ã€‚æ¯”å¦‚ä½ ä»¬ç­ 1 å·åŒå­¦ååœ¨(1,1)ï¼Œè€Œéš”å£ç­ 1 å·å¯èƒ½ååœ¨(1,1)çš„æ˜¯ä»–ä»¬ç­çš„ 5 å·åŒå­¦ã€‚è¿™æ—¶å€™éœ€è¦ä¸€ä¸ª "ç¼–å·é‡æ’" çŸ©é˜µ Pï¼ŒæŠŠä»–ä»¬çš„ç¼–å·é¡ºåºè°ƒæ•´åˆ°å’Œä½ ä»¬ç­ä¸€è‡´ã€‚
      
      ### å®é™…åº”ç”¨åœºæ™¯ï¼š
      
      å‡è®¾æ·˜å®å’Œäº¬ä¸œéƒ½æœ‰ç”¨æˆ·å…³ç³»ç½‘å›¾ï¼š
      
      1. **æ·˜å®å›¾**ï¼šç”¨æˆ· Aã€Bã€C çš„åµŒå…¥åæ ‡æ˜¯ X
      2. **äº¬ä¸œå›¾**ï¼šåŒæ ·çš„ç”¨æˆ·è¢«ç§°ä½œ X'ã€Yã€Zï¼ŒåµŒå…¥åæ ‡æ˜¯ X'
      
      å³ä½¿ä¸¤ä¸ªå¹³å°çš„ç”¨æˆ·å…³ç³»å®Œå…¨ç›¸åŒï¼š
      
      - äº¬ä¸œå¯èƒ½ç”¨äº†ä¸åŒçš„åµŒå…¥ç®—æ³•ï¼ˆå¯¼è‡´éœ€è¦æ—‹è½¬ Qï¼‰
      - ç”¨æˆ·çš„ ID ç¼–å·ä¸åŒï¼ˆå¯¼è‡´éœ€è¦é‡æ–°æ’åˆ— Pï¼‰
      
      é€šè¿‡æ‰¾åˆ° Q å’Œ Pï¼Œå°±èƒ½åˆ¤æ–­ "æ·˜å®ç”¨æˆ· A" å¯¹åº” "äº¬ä¸œç”¨æˆ· X"ï¼Œå®ç°è·¨å¹³å°ç”¨æˆ·å¯¹é½ã€‚
      
      ### å†ç®€åŒ–æ€»ç»“ï¼š
      
      è¿™ä¸ªæ•°å­¦é—®é¢˜å°±åƒåœ¨åšä¸¤ä»¶äº‹ï¼š
      
      1. **çº æ­£æ–¹å‘å·®å¼‚**ï¼šç”¨ Q æ—‹è½¬/é•œåƒï¼Œè®©ä¸¤ä¸ªå›¾çš„æ–¹å‘ä¸€è‡´
      2. **çº æ­£ç¼–å·æ··ä¹±**ï¼šç”¨ P é‡æ–°æ’åˆ—ï¼Œè®©å¯¹åº”çš„èŠ‚ç‚¹æ‰¾åˆ°å½¼æ­¤
      
      æœ€ç»ˆç›®æ ‡ï¼šè®©ä¸¤ä¸ªå›¾çš„èŠ‚ç‚¹åæ ‡å°½å¯èƒ½é‡åˆï¼Œå³ä½¿å®ƒä»¬æœ€åˆçœ‹èµ·æ¥ä¸ä¸€æ ·ã€‚
      
      ![image-20250301142650331](assets/image-20250301142650331.png)

- Pointwise Mutual Information (PMI) Matrices  

  PMI çŸ©é˜µæ˜¯ç”¨æ¥è¡¡é‡å›¾ä¸­ä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´ç›¸ä¼¼åº¦çš„å·¥å…·ã€‚æ¯”å¦‚ï¼Œå®ƒå¯ä»¥å‘Šè¯‰ä½ ä¸¤ä¸ªç”¨æˆ·çš„å…³ç³»æœ‰å¤šç´§å¯†ã€‚

  å®šä¹‰ï¼š

  ![image-20250301145032148](assets/image-20250301145032148.png)

  - ![image-20250301145239768](assets/image-20250301145239768.png)

  - ![image-20250301145259969](assets/image-20250301145259969.png)

  - ![image-20250301145536298](assets/image-20250301145536298.png)

    æ¨å¯¼ï¼š

    ![image-20250301145951825](assets/image-20250301145951825.png)

  - !!! note
  -     ### **ä¸¾ä¸ªä¾‹å­**
  -     
  -     å‡è®¾ä½ æœ‰ä¸€ä¸ªç¤¾äº¤ç½‘ç»œï¼Œæœ‰ 3 ä¸ªç”¨æˆ·ï¼šAã€Bã€Cã€‚ä»–ä»¬çš„åµŒå…¥å‘é‡å¦‚ä¸‹ï¼š
  -     
  -     - A çš„åµŒå…¥å‘é‡ï¼š*X* 1 = [1,0]
  -     - B çš„åµŒå…¥å‘é‡ï¼š*X* 2 = [0,1]
  -     - C çš„åµŒå…¥å‘é‡ï¼š*X* 3 = [1,1]
  -     
  -     ä¹Ÿå°±æ˜¯ $X \in \mathbb{R}^{3 \times 2}$
  -     
  -     #### **1. è®¡ç®—ç›¸ä¼¼åº¦**
  -     
  -     - A å’Œ B çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X* 1, *X* 2âŸ© = 1Ã—0+0Ã—1 = 0
  -     - A å’Œ C çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X* 1, *X* 3âŸ© = 1Ã—1+0Ã—1 = 1
  -     - B å’Œ C çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X* 2, *X* 3âŸ© = 0Ã—1+1Ã—1 = 1
  -     
  -     #### **2. æ„å»º PMI çŸ©é˜µ**
  -     
  -     PMI çŸ©é˜µå°±æ˜¯ï¼š
  -     
  -     ![image-20250301145748553](assets/image-20250301145748553.png)
  -     
  -     - ç¬¬ (1,2) é¡¹æ˜¯ 0ï¼Œè¡¨ç¤º A å’Œ B ä¸ç›¸ä¼¼ã€‚
  -     - ç¬¬ (1,3) é¡¹æ˜¯ 1ï¼Œè¡¨ç¤º A å’Œ C ç›¸ä¼¼ã€‚
  -     
  -     #### **3. æ­£äº¤çŸ©é˜µçš„ä½œç”¨**
  -     
  -     å‡è®¾æˆ‘ä»¬ç”¨ä¸€ä¸ªæ­£äº¤çŸ©é˜µ *Q* æ—‹è½¬åµŒå…¥å‘é‡ï¼Œæ¯”å¦‚ï¼š
  -     
  -     *Q* = [0110]
  -     
  -     æ–°çš„åµŒå…¥çŸ©é˜µ `X~=XQ` å°±æ˜¯ï¼š
  -     
  -     - A çš„æ–°åµŒå…¥å‘é‡ï¼š*X*~1 = [0,1]
  -     - B çš„æ–°åµŒå…¥å‘é‡ï¼š*X*~2 = [1,0]
  -     - C çš„æ–°åµŒå…¥å‘é‡ï¼š*X*~3 = [1,1]
  -     
  -     é‡æ–°è®¡ç®—ç›¸ä¼¼åº¦ï¼š
  -     
  -     - A å’Œ B çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X*~1, *X*~2âŸ© = 0Ã—1+1Ã—0 = 0
  -     - A å’Œ C çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X*~1, *X*~3âŸ© = 0Ã—1+1Ã—1 = 1
  -     - B å’Œ C çš„ç›¸ä¼¼åº¦ï¼šâŸ¨ *X*~2, *X*~3âŸ© = 1Ã—1+0Ã—1 = 1
  -     
  -     PMI çŸ©é˜µä»ç„¶æ˜¯ï¼š
  -     
  -     ![image-20250301150907011](assets/image-20250301150907011.png)
  -     
  -     ä¹Ÿå°±æ˜¯è¯´ï¼Œæ­£äº¤å˜æ¢ä¸ä¼šæ”¹å˜èŠ‚ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚

- PMI Matrix eigendecomposition for network embedding  

  - ç”±äºä¸Šä¸€ç« å·²ç»è¯æ˜ï¼šX ä¹˜ä¸Š Q ä»¥åï¼Œ PMI ä¸å˜ï¼Œæ‰€ä»¥ä¸ç”¨æ‰¾ Q çŸ©é˜µ
  - ![image-20250301151036651](assets/image-20250301151036651.png)
  - åé¢å…³äºç‰¹å¾å‘é‡æ²¡çœ‹æ˜ç™½
  - ç»“è®ºæ˜¯ PMI çŸ©é˜µåˆ†è§£æ¯”éšæœºæ¸¸èµ°å¿«


##### contribution

- an efficient mini-batch training method at the sub-graph level
  - can guarantee parallel training and satisfy the memory restriction for large-scale netlists
- Matrix-factorization based embedding learning  





##### data

![image-20250301151648940](assets/image-20250301151648940.png)

![image-20250301151653817](assets/image-20250301151653817.png)



##### task

![image-20241102170157570](./assets/image-20241102170157570.png)

- during the logic synthesis stage  

- ![image-20241102185917955](./assets/image-20241102185917955.png)

  åˆ°åº•æ˜¯ä»€ä¹ˆæ—¶å€™çš„ congestion æ•°æ®? Routing åçš„çœŸå®å€¼è¿˜æ˜¯é¢„æµ‹ plcament åçš„ congestion RUDY é¢„æµ‹å€¼? åº”è¯¥æ˜¯ **Global Routing** åçš„: å¼ºè°ƒäº† congestion value = wiring demand/routing capacity

  ![image-20241102190757814](./assets/image-20241102190757814.png)

  

**contrbution**

##### data

DAC2012 contest benchmark

http://archive.sigda.org/dac2012/contest/dac2012_contest.html

![image-20241102185210635](./assets/image-20241102185210635.png)

OpenROAD dataset

![image-20241102185314200](./assets/image-20241102185314200.png)

- place via **DREAMPLACE**  

- ![image-20241102185814366](./assets/image-20241102185814366.png)

- Macros and terminals are removed from the graph  

- Nets with degree more than 10 are excluded from the final graph as they introduce cliques too large to work with efficiently.   

- node features (pin number, cell size) , This follows the flow of CongestionNet

- ![image-20241102190725383](./assets/image-20241102190725383.png)

- \#### flow

  ![image-20241102193019887](./assets/image-20241102193019887.png)

- congestion value for each grid cell computed as the wiring demand divided by the routing capacity , The output along the z-axis is reduced by a max function,   

- Our focus is on predicting congestion due to local logic structure, which manifests itself on lower metal layers. Therefore, we use congestion labels from the lower half of the metal layers to train and evaluate the model  

- æ¨ç†çš„æ—¶å€™å–æ‰€æœ‰ cell çš„é¢„æµ‹å¹³å‡å€¼

   

**principle**

- æå‡ºç›¸è¿è¶Šè¿‘çš„èŠ‚ç‚¹ç›¸ä¼¼åº¦è¶Šé«˜,

- æå‡º structural node similarity  

  ![image-20241102182916257](./assets/image-20241102182916257.png)

- Sub-graph partition ? METIS? ClusterGCN?

- Matrix Factorization  ?



##### model

- The key **difference** between this approach and **CongestionNet** lies in **embedding** pipeline 

- graph is undirected complete circuit is too **large** for direct matrix factorization and must be **partitioned** into clusters, use **METIS** partitioning tool   in **ClusterGCN**
- Sub-graph partition: clusters of â‰ˆ 5000 nodes each
- Matrix Factorization  ?



##### experiment

three metrics of correlation to measure performance:   **Pearson, Spearman, Kendall** 

Before evaluation, both the prediction and the label have some (very low) **noise** added to them.   

![image-20241102204924004](./assets/image-20241102204924004.png)

![image-20241102204932495](./assets/image-20241102204932495.png)

![image-20241102204956720](./assets/image-20241102204956720.png)

![image-20241102205029766](./assets/image-20241102205029766.png)



#### [PGNN-DRVs prediction+Pin Proximity Graph-ICCAD-2022-GNN+UNet(CNN)-Korea]()

##### background

- (1) pin accessibility and (2) routing congestion are two major causes of DRVs (design rule violations)  

- Particularly, the complex design rules put so much burden on physical design, demanding lots of iterations on the time-consuming process of cell placement and net routing to **clean up all DRVs (design rule violations)** before tapping out . Thus, at the placement stage, if we were able to identify, with high confidence, DRC (design rule check) hotspots that would be
  likely to occur at the routing stage, we can pay more attention  

- shortcoming of **image based**:

  local pin accessibility cannot be accurately modeled by pin pattern **image** alone  

  using high-resolution pin pattern images incur significant additional **run-time** as well as **memory** overhead to the prediction models  

- to optimize the placement before routing.  

##### task

a novel ML based DRC hotspot prediction technique,   

- GNN is used to embed pin accessibility information, **U-net** is used to extract routing congestion information from grid-based
  features  
- ![image-20241108113804178](./assets/image-20241108113804178.png)
- ![image-20241108100942346](./assets/image-20241108100942346.png)
- placement åˆ†å‰²ä¸º grid, é•¿å®½ = G-Cell
- DRVs are extracted as the ground-truth after **detailed routing**  

##### contribution

- GNN model, base pin proximity graph

##### model

PGNN can adopt pin proximity graph as well as grid-based feature map as input feature  



Pin Proximity Graph :

- æ— å‘å›¾ï¼Œ åŒæ„å›¾

![image-20241108105308585](./assets/image-20241108105308585.png)

![image-20241108105400483](./assets/image-20241108105400483.png)



U-Net:

![image-20241108100615500](./assets/image-20241108100615500.png)

featrue:

![image-20241108111019050](./assets/image-20241108111019050.png)

![image-20241108111430728](./assets/image-20241108111430728.png)



æ•´ä½“æ¨¡å‹:

![image-20241108110729825](./assets/image-20241108110729825.png)

**æ•°æ®é›†**:

![image-20241108111933323](./assets/image-20241108111933323.png)

ä»¥åä¹Ÿå¯ä»¥è¿™ä¹ˆåš, åŒä¸€ä¸ª benchmark ä¸åŒçš„ config å‚æ•°å°±æœ‰ä¸åŒçš„æ•°æ®

##### experiment

Nangate 15nm library  

9 groups are used for training and the remaining 1 group for test.   K æŠ˜éªŒè¯

![image-20241108112502662](./assets/image-20241108112502662.png)

positive å’Œ negative æ˜¯ä»€ä¹ˆæ„æ€?

å¯è§†åŒ–:

![image-20241108102857037](./assets/image-20241108102857037.png)

æ¶ˆèå®éªŒ:

![image-20241108112646099](./assets/image-20241108112646099.png)

ä»¥åä¹Ÿå¯ä»¥è¿™æ ·ç”¨ç‰¹å¾æ¶ˆè?



å¯¹æ¯”å®éªŒ(F1-score):

![image-20241108112751008](./assets/image-20241108112751008.png)

![image-20241108114209199](./assets/image-20241108114209199.png)

- æ³¨æ„ä¸éœ€è¦ GR!

- **GR-Cong** is obtained from ICC2 after global routing stage, and grids with high routing congestion are classified as DRC hotspot. å•†ç”¨  
- RouteNet å’Œ J-Net éƒ½æ˜¯ç›¸å…³çš„å­¦æœ¯å·¥ä½œ

æ—¶é—´å¯¹æ¯”:

![image-20241108114501484](./assets/image-20241108114501484.png)

#### [LHNN-CongestionPrediction-DAC-2022-GNN-CUHK+Huawei+YiboLin]()

##### background

- å›¾çš„èŠ‚ç‚¹çš„è®¾ç½®å¾ˆæ–°é¢–
- with the growth of circuit scale and complexity, time consumption
  tends to be unacceptable when utilizing a **global router** in the placement cycle to obtain the **congestion map**.  
- due to the need for the **"shift-left"** in circuit design, researchers begin to seek alternative solutions in machine learning [4] [5] to achieve accurate and fast congestion map prediction  

##### task

- two related tasks, **routing demand regression** and **congestion classification**  

##### data

regard each **G-cell** **as a node** and add an edge between two nodes if the respective two G-cells are adjacent.  

**hypergraphs and heterogeneous  graph** , ä¸¤ç§èŠ‚ç‚¹ï¼šG-cell å’Œ G-net

![image-20241108141650136](./assets/image-20241108141650136.png)

![image-20241108142449292](./assets/image-20241108142449292.png)

- featureï¼š

  ![image-20241108142931213](./assets/image-20241108142931213.png)

![image-20241108145640376](./assets/image-20241108145640376.png)

ISPD 2011 [16] and DAC 2012 [17] contest benchmarks , 

##### model

![image-20241219145252874](./assets/image-20241219145252874.png)

![image-20241108144617443](./assets/image-20241108144617443.png)

ä»–è¿™é‡Œè¯´ congestion map æ˜¯ä¸€ä¸ªäºŒå€¼åŒ–(0/1?)çš„æ•°æ®é›†ï¼Œ æ‰€ä»¥æ˜¯åˆ†ç±»ä»»åŠ¡, ä½†æ˜¯ä¸ºäº†åˆ©ç”¨æ•°æ®ï¼ŒåŒæ—¶é˜²æ­¢ routing demand çš„ä¿¡æ¯ä¸¢å¤±ï¼Œ è¿˜è®¾ç½®äº†ä¸€ä¸ªé¢„æµ‹ routing demand çš„ä»»åŠ¡ï¼Ÿ

##### experiment

15benchmarks: 10 for training and 5 for testing  

run **DREAMPlace** [18] on each of the designs to generate placement solutions 

**NCTU-GR 2.0** [2] to attain horizontal/vertical **routing demand maps**  , and set the **congestion maps** as a **binary** indicator according to whether the horizontal/vertical routing demand of the G-cell **exceeds the circuitâ€™s capacity**  

![image-20241108150810402](./assets/image-20241108150810402.png)



![image-20241108150803029](./assets/image-20241108150803029.png)

![image-20241108150837509](./assets/image-20241108150837509.png)

å¯¹æ¯”å®éªŒï¼š

![image-20241108151611413](./assets/image-20241108151611413.png)

![image-20241108151757751](./assets/image-20241108151757751.png)

å¯è§†åŒ–ï¼š

![image-20241108150918563](./assets/image-20241108150918563.png)

æ¶ˆèå®éªŒï¼š

![image-20241108152104185](./assets/image-20241108152104185.png)

#### [ClusterNet- -ICCAD-2023--Korea]()

- Netlist as input



#### [MEDUSA-2D&3D-Trans-2023-CNN-Columbia  ](https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/3590768)

- Routing congestion is one of the many factors that need to be minimized during the physical design phase of large integrated circuits. 
- compare with `c-DCGAN [33]` , which is GAN-based. One of the drawbacks of GANs, however, is that they are generally difficult to train and so the performance benefits that they may yield comes at a significant computing cost.  



##### background

- feature encoding algorithm.

  Features extracted from the routing topology are stored in a multi-layer hyper-image that preserves the circuitâ€™s structural information

- a customized CNN   

  - takes our proposed hyper-image as inputs and produces congestion maps that are comparable to ground truth
  - simplified customized CNNs  

  

- embedded them with two open source routers

##### contribution




##### flow

![image-20250419181244276](assets/image-20250419181244276.png)



![image-20250419181016015](assets/image-20250419181016015.png)



##### model

![image-20250419174928184](assets/image-20250419174928184.png)

- In 3D routing m = 16;   
- input feature:

  - Vertex related: Pin density and level-one pin density  
- Vertex-east-edge related: Wire density, wire usage, and wire capacity  
  - Vertex-north-edge related: Wire density, wire usage, and wire capacity  
- 3D information: Via usage and capacity.  
- Wire densityæ˜¯pattern routingçš„ç»“æœ
  - pattern routing å…·ä½“æ˜¯æ€ä¹ˆåšçš„ï¼Ÿ

![image-20250419174933984](assets/image-20250419174933984.png)

**CU-GR-M and UBC-Route**

- In the case of 2D routing, m = 2 ï¼›
- the via feature is not considered when using MEDUSA-2D  





![image-20250419181857247](assets/image-20250419181857247.png)

The cost functions of CU-GR [21] do not take into consideration the estimated via usage produced by MEDUSA-3D  

![image-20250419181951737](assets/image-20250419181951737.png)





##### data

developed MEDUSA-3D, which is used with `CU-GR [21]` for performing 3D routing on `ICCAD 2019 benchmarks`   

MEDUSA-2D, was also developed to be used for traditional 2D routing using `ISPD 2008 benchmarks `[1].   



##### experiment

![image-20250419182310076](assets/image-20250419182310076.png)

PD, NP, ND, LN, GN, and C are abbreviations for pin density, neighborhood pin density, net density, local net, global net, and capacity (both pin capacity and via capacity if applicable), respectively  

![image-20250419183118299](assets/image-20250419183118299.png)

![](assets/image-20250419183137781.png)

![image-20250419183649292](assets/image-20250419183649292.png)

![image-20250419183658723](assets/image-20250419183658723.png)





#### [-NN Robustness improve-arXiv-2024- -UC-]()

##### background

- æœ€è¿‘çš„å·¥ä½œå·²ç»è¯æ˜ç¥ç»ç½‘ç»œé€šå¸¸æ˜¯å®¹æ˜“å—åˆ°ç²¾å¿ƒé€‰æ‹©çš„è¾“å…¥å°æ‰°åŠ¨çš„å½±å“ 
- Our definition of **imperceptibility** is characterized by a guarantee that a perturbation to a layout will not alter its global routing  
- recent work [10, 18] has demonstrated that image classifiers can be **fooled** by **small, carefully chosen** perturbations of their input  
- ![image-20250102215202387](./assets/image-20250102215202387.png)



##### task

- design two efficient methods for finding perturbations that demonstrate brittleness of recently proposed congestion predictors  
- one potential approach to address the issues by modifying the training procedure to promote robustness



##### contribution









[Painting on PIacement-predict the routing congestion-ACM-2019-GAN-](https://ieeexplore.ieee.org/document/8807040)

![image-20241012153331855](./assets/image-20241012153331855.png)

![image-20241012153541960](./assets/image-20241012153541960.png)



[-DRC Hotspot Prediction-ISCAS-2021-CNN](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9401274)



[-Routing Congestion Prediction-ASPDAC-2020-GAN](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9045178)

- slice [FPGACong_ASPDAC20 (yibolin.com)](https://yibolin.com/publications/papers/FPGA_ASPDAC2020_Alawieh.slides.pdf)

[-predict #DRV, a macro placer-DATE-2019-CNN](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8715126)





### Timing

#### background

![image-20241026164128136](./assets/image-20241026164128136.png)

#### [TimingGCN-STA prediction-DAC-2022-GNN](https://dl.acm.org/doi/abs/10.1145/3489517.3530597)

- the first workï¼
- opensource
- still relies on local net/cell delay prediction as auxiliary tasks  
- no optimization, not fit the real-world scenario where timing **optimization** is taken into account  

[PreRoutGNN-STA prediction-AAAI-2024-GNN](https://github.com/Thinklab-SJTU/EDA-AI/tree/main/PreRoutGNN)

- opensource

#### [Multimodal Fusion-Restructure tolerant+CNN+Endpoint-wise Masking4Layout -DAC-2023-GNN+CNN-7nm RISCV](D:\MyNotes\EDA\Timing\Multimodal Fusion-Pre Route Timing Prediction-DAC-2023-GNN-7nm RISCV.pdf)

[slice](https://www.cse.cuhk.edu.hk/~byu/papers/C167-DAC2023-PathPred-poster.pdf)

- Restructureï¼šé¢„æµ‹ç»ˆç‚¹çš„å»¶æ—¶ï¼Œä½†æ˜¯ Timing Opt ä¼šæ”¹å˜ç½‘è¡¨ç»“æ„(end point ä¸å˜ï¼‰ã€‚å¯¹ä¸€ä¸ª Pre-routing ä»»åŠ¡æ¥è¯´ï¼Œè¾“å…¥çš„ç½‘è¡¨å’Œæœ€ç»ˆçš„ç½‘è¡¨ä¸ä¸€æ ·

- netlist **restructuring** causes a mismatch between local input features and ground-truth features in the restructured sub-regions  

  ![image-20241026173420844](./assets/image-20241026173420844.png)

  As a result, prior local-view models can only be trained on the unchanged regions in a **semi-supervised manner**.  

  In other words, the better the models fit on labeled (unreplaced) net/cell delays, the worse they fit on replaced regions and eventually on endpoint arrival time  

- æ•°æ®é›†ï¼šåŸºæœ¬ä¿¡æ¯å’Œ Timing ä¼˜åŒ–å¯¼è‡´çš„ç½‘è¡¨å˜åŒ–

  - average 40% nets and 21% cells are replaced during timing optimization  
  - timing optimization brings an average change of 59.6% to net delays
    and 33.3% to cell delays  

  ![image-20241026170120254](./assets/image-20241026170120254.png)

- ä¸ºä»€ä¹ˆç”¨ layout ä¿¡æ¯ï¼šSince most timing optimization techniques include gate insertion or gate sizing, placement should reserve space for subsequent timing
  optimization. In other words, the timing optimizerâ€™s efficacy is tied closely to global layout information. The layout information plays a dominant role in determining the timing optimizerâ€™s impact since most optimization
  techniques need space to be applied  

- æ•´ä½“æ¨¡å‹

  ![image-20241026184138343](./assets/image-20241026184138343.png)

  ç»„æˆï¼š**GNN+CNN+Endpoint-wise Masking**  

  - Netlist(GNN):

  ![image-20241026184646854](./assets/image-20241026184646854.png)

  å’Œ [TimingGCN-STA prediction-DAC-2022-GNN](https://dl.acm.org/doi/abs/10.1145/3489517.3530597) å¾ˆåƒ(æ²¡å‘ç°ä¸åŒ)

  - Layout(CNN+Endpoint-wise Masking)

    ![image-20241026185621311](./assets/image-20241026185621311.png)

    ![image-20241026193815323](./assets/image-20241026193815323.png)

    ä¸‰ä¸ªç‰¹å¾ï¼šcell density, rectangular uniform wire density (RUDY), and macro cells region  

    ![image-20241026190115449](./assets/image-20241026190115449.png)

    **Endpoint-wise Masking**  

    ![image-20241026194544366](./assets/image-20241026194544366.png)

- å¯¹æ¯”å®éªŒï¼š

  ![image-20241026200330616](./assets/image-20241026200330616.png)

  ![image-20241026200838620](./assets/image-20241026200838620.png)

  

- run time å®éªŒ

  

  ![image-20241026201203648](./assets/image-20241026201203648.png)

  

  



##### other

[Ahead RC network-STA prediction-DAC-2022-?](file:///D:/MyNotes/EDA/Timing/aheadRCnetwork.pdf)



[Doomed Run Prediction-TNS prediction-ACM-2021-GNN+RNN](https://ieeexplore.ieee.org/document/9643435)

![image-20241007121002859](./assets/image-20241007121002859.png)

##### not DL

![image-20241026164603048](./assets/image-20241026164603048.png) The two-stage approaches [2], [3] first predict localnet/cell delays and then apply PERT traversals [5] to evaluate the global timing metrics, i.e., endpoint arrival time.  



## Optimization

### Timing

#### [TSteiner - Steiner Points Opt-DAC-2023-GNN-CUHK]()

##### background

  å¯¹äº multi-pin net éœ€è¦æ„å»º steiner tree æ¥è¿›è¡Œ routingï¼Œæ•… steiner tree ä¸­ steiner points ä¹Ÿä¼šå½±å“ routing

  FLUTE [[3\]](https://www.zhihu.com/question/579615273/answer/3154651342#ref_3) æ˜¯å¸¸ç”¨çš„ç”Ÿæˆ steiner tree çš„ç®—æ³•ã€‚åœ¨ç”Ÿæˆ steiner tree åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿‘ä¸€æ­¥ä¼˜åŒ– steiner point æ¥ä¼˜åŒ– timing

![image-20241102112154369](./assets/image-20241102112154369.png)

the previous early-stage timing optimization works only focus on improving
early timing metrics. æå‡ºäº†è¯¸å¦‚ net åŠ æƒå’Œå¯å¾®åˆ†æ—¶é—´ç›®æ ‡ç­‰ç­–ç•¥æ¥ä¼˜åŒ–æ—¶é—´, only focus on improving pre-routing timing metrics, which may have a considerable gap to **signoff** timing performance. æ–¯å¦é‚£ç‚¹æ›´åŠ é è¿‘å¸ƒçº¿é˜¶æ®µ(å’Œå¸ƒçº¿æ›´åŠ ç›¸å…³)

all the aforementioned works are not directly targeted at sign-off timing performance due to its high acquisition cost  



**ä»»åŠ¡:**

![image-20241102111709494](./assets/image-20241102111709494.png)

In this paper, we focus on explicit sign-off timing optimization at the pre-routing stage to reduce the turnaround time

optimization framework is built to adjust Steiner point positions  for better sign-off timing performance iteratively  

The most popular Steiner minimum tree construction algorithms aim to **minimize wirelength**. Moreover, the Steiner point refinement is introduced to update the generated Steiner point positions for specific objectives, e.g., sign-off timing performance, while maintaining the two-pin net connections



**å¯å‘:**

we surprisingly find that the signoff timing performance could be significantly affected even by a **random** disturbance on Steiner point positions, as shown in Fig. 2.  

![image-20241102114842155](./assets/image-20241102114842155.png)

Nevertheless, the impact of random moving is considerately unstable, and its average performance is slight (with a ratio close to 1.0).  æ‰€ä»¥å¯å‘æ‰¾åˆ°ä¸€ä¸ªå¥½çš„æ–¹æ³•æ¥æ›´æ–°æ–¯å¦çº³ç‚¹æ¥é™ä½ TNS

åœ¨æœ€å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯èŠ‚ç‚¹ä¸­ï¼Œä¸ **è·¯å¾„é•¿åº¦** æœ€ç›¸å…³çš„å®šæ—¶åº¦é‡â€”â€”å‡€å»¶è¿Ÿï¼Œå¹¶ä¸èƒ½è§£é‡Šå¤§éƒ¨åˆ†çš„æ•´ä½“å®šæ—¶æ€§èƒ½. è¿™é‡Œç”¨çš„åˆå§‹åŒ–æ–¯æ³°çº³æ ‘çš„æ–¹æ³•çš„ä¼˜åŒ–ç›®æ ‡éƒ½æ˜¯è·¯å¾„é•¿åº¦æœ€çŸ­



##### contribution:

- first  earlystage timing optimization framework   via Steiner point refinement
- GNN
- TSteiner framework is fully automated with an adaptive stepsize scheme and the auto-convergence scheme  
- improves 11.2% and 7.1% on average (up to 45.8% and 43.9%) for WNS and TNS





**æ¨¡å‹:**

Steiner tree construction decomposes each multi-pin net into **a set of two-pin**
**nets** via additional Steiner points before global routing  to reduce the problem complexity

The proposed framework can be divided into two stages, **sign-off timing gradient generation** (Section III-A) and **concurrent Steiner point refinement** (Section III-B)  

![image-20241102123009705](./assets/image-20241102123009705.png)

  ![image-20241102115937138](./assets/image-20241102115937138.png)

å’Œ TimingGCN ç›¸æ¯”å°±æ˜¯å¤šäº† Steiner èŠ‚ç‚¹, ç„¶åå§ç¬¬ä¸€éƒ¨åˆ†çš„çš„ node embedding éƒ¨åˆ†åŠ ä¸Šäº† steiner çš„éƒ¨åˆ†

![image-20241102121828217](./assets/image-20241102121828217.png)

å®é™…æ˜¯: ![image-20241102122509138](./assets/image-20241102122509138.png)

![image-20241102122552273](./assets/image-20241102122552273.png)



ä¼˜åŒ–çš„æŒ‡æ ‡, WNS å’Œ TNS çš„åŠ æƒ

æ ¹æ®ä¼˜åŒ–æŒ‡æ ‡å¯¹æ–¯æ³°çº³ç‚¹åæ ‡å‚æ•°åšæ¢¯åº¦ä¸‹é™

![image-20241102132825834](./assets/image-20241102132825834.png)

![image-20250102200912287](./assets/image-20250102200912287.png)

ç›¸æ¯”ç®€å•çš„æ¢¯åº¦ä¸‹é™ï¼Œåªæ˜¯å‡å°äº†å¯¹ä¸åŒ benchmark çš„æ‰‹åŠ¨å­¦ä¹ ç‡å¾®è°ƒ

**æ•°æ®**

![image-20241102132430596](./assets/image-20241102132430596.png)





**å®éªŒ**

![image-20241102132506821](./assets/image-20241102132506821.png)

![image-20241102132555409](./assets/image-20241102132555409.png)

![image-20241102132646602](./assets/image-20241102132646602.png)

![image-20241102132734827](./assets/image-20241102132734827.png)



### Placement

#### [-Pin Accessibility+DRV prediction-DAC-2019-CNN-NTU]()

##### background

- Standard cells on the lower metal layers severely suffer from low routability due to high pin density, low pin accessibility, and limited routing resources.  

- ![image-20250206153002501](./assets/image-20250206153002501.png)

  It can be observed that the access points of pin B are blocked by the metal 2 (M2) routing segments routed from Pin A and Pin C, so an M2 short design rule violation (DRV) will be induced when dropping a via12 on Pin B. pin accessibility is not only determined by cell layout design but also strongly affected by adjacent cells    

- å¯¹äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸¤ä¸ªç¼ºç‚¹ï¼š

  - Cell libraries provided by foundries should not be considerably redesigned because the optimized cell performance and manufacturability may be highly sensitive to cell layouts  
  - Deterministic approaches based on **human knowledge have been shown to be less effective in advanced nodes** for optimization problems such as DRV prediction and minimization because of the extremely high complexity through the overall design flow  

- ![image-20250206154744610](./assets/image-20250206154744610.png)

  It can be observed that most of the congested regions in the layout do not have DRVs, while some regions with DRVs are not so congested. ä½†æ˜¯æˆ‘æ„Ÿè§‰è¿˜æ˜¯æœ‰ç›¸å…³æ€§çš„ã€‚ä»–æ˜¯æƒ³è¯´æ˜ congestion å‡ºç°çš„åœ°æ–¹ä¸ä¸€å®šæœ‰ DRVï¼Œä½†æ˜¯æ²¡ congestion çš„åœ°æ–¹å¯èƒ½å› ä¸º poor pin accessibility å¯¼è‡´ DRV

- ![image-20250206154811206](./assets/image-20250206154811206.png)

  - ä¹Ÿæ˜¯è¯´æ˜ï¼šcongestion å‡ºç°çš„åœ°æ–¹ä¸ä¸€å®šæœ‰ DRVï¼Œä½†æ˜¯æ²¡ congestion çš„åœ°æ–¹å¯èƒ½å› ä¸º poor pin accessibility å¯¼è‡´ DRV
  - the two M2 shorts occur at the locations having **the same pin pattern** in the top cell-row and mid cell-row  



##### task

- DRV prediction, äºŒåˆ†ç±»

  ![image-20250206190055066](./assets/image-20250206190055066.png)

- pin accessibility optimization, ç»™ä¸€ä¸ªåˆæ³•åŒ–åçš„å¸ƒå±€ç»“æ„ï¼Œé€šè¿‡ç®—æ³•è¿›è¡Œå‡å°‘ bad pin accessibility çš„ detailed placement

  ![image-20250206190225309](./assets/image-20250206190225309.png)

- å…¶å®ä¹Ÿæ˜¯ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œä¸€ä¸ªä¼˜åŒ–æ¨¡å‹

##### contribution

- first work to apply pin pattern as the input features of `DRV prediction models`.  



##### flow

![image-20250206191224771](./assets/image-20250206191224771.png)



**model:**

PPR&DFPPR:

![image-20250206192506245](./assets/image-20250206192506245.png)

Model-guided Detailed Placement :

![image-20250206195817013](./assets/image-20250206195817013.png)

![image-20250206202610856](./assets/image-20250206202610856.png)

Dynamic Programming-based Placement Blockage Insertion  

![image-20250206202803548](./assets/image-20250206202803548.png)

- è¿˜ä¼šæ”¹æ–¹å‘ï¼Ÿ

Cell Displacement Refinement



##### data

![image-20250206192552413](./assets/image-20250206192552413.png)

Both the width and height of each pixel are set as the **minimum spacing of the M1 layer** in order to prevent a pixel from being occupied by two different pins. 

æ²¡çœ‹è§å…³äº benchmark çš„æè¿°

##### experiment

![image-20250206204743555](./assets/image-20250206204743555.png)



![image-20250206205223899](./assets/image-20250206205223899.png)

**shortcoming:**

- flow need routed designs to train, time 
- The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries  
- å¯¹äº VLSIï¼Œä¸€è¡Œä¸€è¡Œï¼Œä¸€å¯¹ä¸€å¯¹è¿›è¡Œï¼Œå¾ˆæ…¢ï¼Ÿ





#### [-Pin Accessibility+activ-ISPD-2020- -NTU+Synopsys](https://pdfs.semanticscholar.org/47f1/5e9fa283faddb8a6853398145d33e2ba9ae1.pdf)

##### background

- With the development of advanced process nodes of semiconductor, the problem of ` pin access ` has become one of the major factors to impact the occurrences of design rule violations (DRVs) due to complex design rules and limited routing resource  

- `supervised learning` approaches extract the labels of training data by generating a great number of routed designs in advance, giving rise to large effort on training data preparation. the pre-trained model could hardly predict unseen data    

- Unlike most of existing studies that aim at `design-specific` training, we propose a `library-based` model which can be applied to all designs referencing to the same standard cell library set.   

- Due to the shrinking of modern process nodes of semiconductor, the **pin access problem** of standard cells has become more harder to be coped with, especially on the **lower metal layers**.  

- ![image-20250206150405665](./assets/image-20250206150405665.png)

  åœ¨è¿™ç§ placement ä¸‹ï¼ŒMetal1 pin A/B ç”±äºå„è‡ªå·¦å³ä¸¤è¾¹åœ¨ Metal2 æœ‰ pinï¼Œè€Œä¸”åªèƒ½åœ¨é»„è‰² track ä¸‹æ¨ªå‘ç»•çº¿ï¼Œï¼ˆMetal1 ä¸èƒ½ç»•çº¿ï¼Ÿï¼‰ï¼Œé‚£ä¹ˆ Pin A/B é€šè¿‡ Via12 åå¿…å®šä¼šçŸ­è·¯

- 19 å¹´å·¥ä½œ [5] çš„ä¸¤ä¸ªç¼ºç‚¹

  - flow need routed designs to train, time 
  - The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries  






##### contribution

- first work of ` cell library-based` pin accessibility prediction (PAP), which can be applied to predict other designs referencing to the same cell library set
- applies **active learning** to train a PAP model  
- the proposed cell library-based PAP model **can be trained at the earlier stage** in a process development flow: once the cell libraries are provided.  



#### [Placement Optimization with Deep Reinforcement Learning- -ISPD-2020-RL+GNN-Google]([dl.acm.org/doi/pdf/10.1145/3372780.3378174](https://dl.acm.org/doi/pdf/10.1145/3372780.3378174))



#### [PL GNN-Affinity Aware for ICC2- ISPD-2021-GNN-Atlanta](https://dl.acm.org/doi/pdf/10.1145/3439706.3447045)

##### background:

- Placement is one of the most **crucial problems**,  placement directly impacts the final quality of a full-chip design

- multiple placement **iterations** to optimize key metrics(WL, timing), which is **time-consuming** and computationally inefficient, VLSI

- the ` logical affinity` among design instancesdominates the quality of the placement

  ![image-20241224115010379](./assets/image-20241224115010379.png)

  ` logical affinity` æºäºè¿™ç¯‡æ–‡ç« ï¼Ÿ

- performing **placement guidance** requires in-depth design-specific knowledge, which is only achievable by **experienced designers** who knows the underlying data flows in Register-Transistor Level (RTL) well  

- ![image-20241224114254672](./assets/image-20241224114254672.png)

- K-means åŸºç¡€ï¼š

  - ![image-20241224172053839](./assets/image-20241224172053839.png)

  - ![image-20241224172022162](./assets/image-20241224172022162.png)



##### task

- åŸºäºç½‘è¡¨æ•°æ®ï¼Œå’Œ floorplan ç»“æœï¼ˆmarco å·²ç»æ”¾å¥½ï¼‰
- `placement guidance`(grouping information) for commercial placers `ICC2`, by generating **cell clusters** based on **logical affinity** and manually defined attributes of design instances  
- our framework will determine the ` cell clusters` in an **unsupervised** manner which serve as placement guidance in order to guide commercial placers to optimize the key metrics such as **wirelength, power, and timing** by placing cells with a common **cluster** together



##### flow

![image-20241224111801884](./assets/image-20241224111801884.png)

**Two stages:**

1. GNN do unsupervised node representation learning, (it is generalizable to any design)

2. `weighted K-means clustering algorithm [3]` to group instances into different clustersã€‚To find the optimal number of groups for clustering, we introduce the `Silhouette score [19]` and perform sweeping experiments to find the sweet spot  

   K-means ç®—æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼šé€šè¿‡è¿­ä»£çš„æ–¹å¼ï¼Œå°†æ•°æ®åˆ’åˆ†ä¸º **K ä¸ªä¸åŒçš„ç°‡**ï¼Œå¹¶ä½¿å¾—æ¯ä¸ªæ•°æ®ç‚¹ä¸å…¶æ‰€å±ç°‡çš„è´¨å¿ƒï¼ˆæˆ–ç§°ä¸ºä¸­å¿ƒç‚¹ã€å‡å€¼ç‚¹ï¼‰ä¹‹é—´çš„ **è·ç¦»ä¹‹å’Œæœ€å°**ã€‚

![image-20241007102413593](./assets/image-20241007102413593.png)

##### data

two multi-core CPU designsï¼š

![image-20241224181733657](./assets/image-20241224181733657.png)

**nf**

- **design hierarchy** : æ ¹æ®ç½‘è¡¨å±‚çº§. top/inst1/sky130_INV/A. (åŒæ—¶ zero-padding)

  ![image-20241224160726962](./assets/image-20241224160726962.png)

- **logical affinity of memory macros** ï¼šlogical levels to memory macros ğ‘€ as features. because the logic to memory paths are often the critical timing paths  

![image-20241224161329678](./assets/image-20241224161329678.png)

**ef:**

![image-20241224171228803](./assets/image-20241224171228803.png)



##### model

- GraphSAGE-basedï¼Œ two layers

  ![image-20241224161923488](./assets/image-20241224161923488.png)

  ![image-20241224162351812](./assets/image-20241224162351812.png)

- Loss Function:

  ![image-20241224170359079](./assets/image-20241224170359079.png)

  ![image-20241224170818328](./assets/image-20241224170818328.png)

  ![image-20241224170824860](./assets/image-20241224170824860.png)

**Silhouette score**  

ç”¨äºè¯„ä¼°åˆ†ç±»ç»“æœï¼Œæ‰«æåˆ†ç±»æ•°ç›®ï¼Œé€‰æ‹©æœ€é«˜çš„åˆ†çš„

![image-20241224181002019](./assets/image-20241224181023453.png)

![image-20241224181044251](./assets/image-20241224181044251.png)

![image-20241224181052309](./assets/image-20241224181052309.png)

![image-20241224181116187](./assets/image-20241224181116187.png)





##### experiment

**env**:

- 2.40ğºğ»ğ‘ CPU   
- NVIDIA RTX 2070   
- 16ğºğµ memory.  
- PyTorch Geometric   



**setting:**

- the placement of memory macros is achieved manually based on design manuals provided by the design-house  
- Adam   



**result**

Louvainï¼šæ¯”è¾ƒå®éªŒå¯¹æ¯”æ¨¡å‹

![image-20241224181627782](./assets/image-20241224181627782.png)



**Question**:

benchmark å°‘

æ‰«æåˆ°çš„å°±é€‚ç”¨æ‰€æœ‰ï¼Ÿ

å¼€ç¯ï¼Ÿ







#### [-Innovus PPA placement optimize-Neurips-2021-RL ](https://www.semanticscholar.org/paper/A-General-Framework-For-VLSI-Tool-Parameter-with-Agnesina-Pentapati/30c644ffa213418182e795ea5e8132cb15e891c2)



![image-20241007103637165](./assets/image-20241007103637165.png)

![image-20241007105134964](./assets/image-20241007105134964.png)

##### contribution:

![image-20241224114117771](./assets/image-20241224114117771.png)



#### [-GP Routability Opt-DAC-2021-FCN-CUHK(SitingLiu BeiYu)+Yibo Lin]()

##### background



##### flow

![image-20241226160945080](./assets/image-20241226160945080.png)



1. three input features are extracted from the cell placement solution  
2. Through the inference of the pre-trained routability prediction model, we get the predicted congestion map.  
3. take `mean squared Frobenius norm` of this congestion map as the congestion penalty

![image-20241226161200384](./assets/image-20241226161200384.png)



##### data





##### model

![image-20241226161132128](./assets/image-20241226161132128.png)





#### [Lay-Net- -ICCAD/TCAD-2023/2025-GNN/ViT-CUHK-](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10323800)

- [OpenSource!](https://github.com/lanchengzou/congPred#)
- heterogeneous message-passing paradigm better embeds the routing demand into the model by considering both connections between cells and overlaps of nets  
- TCAD æ¯” ICCAD å¤šäº†contrastive learningå’ŒminiGnet



##### background:

- To accurately model the congestion, placers commonly integrate routing processes [14]â€“[17] or analytical models [18]â€“[21] to estimate the congestion. However, the `routing-based methods` are plagued by considerable runtime overhead while the `model-based approaches` suffer from low accuracy

- key module

  - Swin Transformer
    - è¯¦æƒ…æŸ¥çœ‹[CNN](../NN/CNN/cnn.md)

  - UperNet[42]

  - feature pyramids[41] and Pyramid pooling module (PPM) [43]  

- motivation:
  - ==multimodal== fusion of layout and netlist features has not been extensively. Existing models cannot effectively aggregate the information given by cell locations and net connectivity.   
  - most methods can only utilize ==local information==  
    - `vision-based models` predict congestion by extracting local features with convolutional layers, which lacks a global view of the routing demand  
    - `over-smoothing problem of GNN` [33] limits the collection of long-range information  
  - existing GNN models(LHNN) overlook the routing demand arising from the ==overlaps of nets==, which is a crucial factor contributing to routing congestion.  
    - the `cell-to-cell` or `cell-to-net` links in existing approaches cannot directly model the physical routing demand in GNNs  



##### contribution

- a ==multimodal== congestion prediction model  

  - gathering diverse information that can indicate routing congestion

- ==hierarchical== feature maps 

  - address the limitation of local information  

- ==net-to-net== message passing

  - Cell-to-cell and cell-to-netconnections can reflect the logical relationships betweenthe circuit components. Net-to-net connections can imply the physical relationships between the nets

- first ==contrastive learning== 

  



##### flow



##### model

![image-20250528222725294](assets/image-20250528222725294.png)

<img src="assets/image-20250528222736374.png" alt="image-20250528222736374" style="zoom:50%;" />



###### task:

![image-20250524150554089](assets/image-20250524150554089.png)

###### Multi-scale Feature Extraction  

Lay-Net extracts multi-scale features via `four stages`, which are based on Vision Transformer (ViT) [34] and Swin Transformer [35].   

![image-20250524150633457](assets/image-20250524150633457.png)



###### `ViT` and `Swin Transformer`

capture ==global information==  



##### graph

![image-20250524150540133](assets/image-20250524150540133.png)

![image-20250524152522701](assets/image-20250524152522701.png)

!!! note
    è¾¹çš„æ•°é‡çº§ä¼šå¾ˆå¤§å§ï¼Ÿ

![image-20250528220917995](assets/image-20250528220917995.png)

!!! note
    å°‘è§çš„

##### feature

![image-20250524155310018](assets/image-20250524155310018.png)

![image-20250524155445991](assets/image-20250524155445991.png)



###### contrastive learning  

![image-20250528213436733](assets/image-20250528213436733.png)



###### experiment

![image-20250528223510181](assets/image-20250528223510181.png)

![image-20250528223737824](assets/image-20250528223737824.png)

![image-20250528223747317](assets/image-20250528223747317.png)

![image-20250528223941835](assets/image-20250528223941835.png)

!!! note
    æ€ä¹ˆå˜å°‘äº†

![image-20250524160945464](assets/image-20250524160945464.png)



#### [-Congestion+ViT+GNN-TCAD-2025--Southeast]()

- congestion prediction model-based placer optimizer
- å’Œ`Lay-Net`å¾ˆåƒ
- HGCN+CNN

##### background

- previous way:

  - static-based  

    directly estimate routing congestion based on placement attributes (such as pin density and net overlap) without performing actual routing  

    such as `RUDY`  

  - probabilistic-based  

    calculate the probability of routing topology of each net based on pattern routing (such as L-shaped or Z-shaped routing) to estimate the congestion  

    such as <img src="assets/image-20250920212114822.png" alt="image-20250920212114822" style="zoom: 65%;" />

  - tool-based  

    calling global routing tools  

    congestion maps obtained by the first two categories of methods are often not accurate enough  

    precise but time-consuming  

- purely image-based models [4], [9], [13], [14] may fail to incorporate critical netlist information,   

- there have been efforts to address the congestion prediction problem using graph neural network  [15], [16], [17]  

- the homogeneous GNNs may exhibit poor performance when handling diverse netlists simultaneously  

  !!! warning
      
      ä»–æ²¡è§£é‡Šè¿™ä¸ªæ˜¯ä¸ºä»€ä¹ˆï¼Œä¹Ÿæ²¡å¼•ç”¨

- Recently, `multimodal fusion-based models` have attracted much attention due to their ability to provide various perspectives [19], [20], and current multimodal fusion-based congestion prediction models have demonstrated notable performance [8], [12]. However, they still lack the deep multimodal fusion of placement and netlist features  

- `Lay-Net` may still fall short in extracting deep features and restoring congestion maps effectively.   

  `Lay-Net` only utilizes MLP layers to simply connect transformer and HGNN layers, thus may fail to exploit the potential of deep multimodal feature fusion.  

- å…¶ä»–é¢†åŸŸå¤šæ¨¡æ€èåˆçš„æ–¹æ³•[19],[20]



##### contribution

![image-20250920212345656](assets/image-20250920212345656.png)

- dual multimodal fusions  
- early `feature fusion (EFF)` method: merge `HGCN+CNN`
- deep `feature fusion (DFF)` method: self attention `(SA)` [22] cross-attention `(CA)` [23] to perform cross-modal feature fusion 



##### flow

![image-20250921144622709](assets/image-20250921144622709.png)

![image-20250921142344600](assets/image-20250921142344600.png)



##### model

**CNN** input

**ResNet50**  

![image-20250921142452461](assets/image-20250921142452461.png)

**Graph**

![image-20250921142509379](assets/image-20250921142509379.png)

![image-20250921144731784](assets/image-20250921144731784.png)

**GAT**:

æ–‡ç« ä¸€å †ç›¸å…³å…¬å¼

**EFF:**

![image-20250921161038740](assets/image-20250921161038740.png)

**DFF:**

patch embedding

self attention `(SA)` [22] cross-attention `(CA)` [23]

![image-20250921160831962](assets/image-20250921160831962.png)

![image-20250921160838447](assets/image-20250921160838447.png)



**Cascaded Decoder:**



##### data

![image-20250921142158045](assets/image-20250921142158045.png)

ISPD 2015 Contest

![image-20250921151157723](assets/image-20250921151157723.png)

##### experiment

- åŸºäº`DREAMPlace`

- è¿˜åœ¨`innovus`åšäº†`routing`

- loss function: `MMD`

  ![image-20250921161710434](assets/image-20250921161710434.png)

- dataset augmentation  

- cross-validation

  ![image-20250921162747709](assets/image-20250921162747709.png)

![image-20250921170409767](assets/image-20250921170409767.png)

![image-20250921170418548](assets/image-20250921170418548.png)

### Gate Sizing

#### [-Differentiable Fusion GP&GS-ICCAD-2024--PEK-Du&Guo&Lin]()

- æœ€ä½³è®ºæ–‡æå

##### background

- ä¹‹å‰æ˜¯åˆ†å¼€åšçš„ï¼Œ current methodologies typically explore `gate sizing` after the `placement` or `routing` is fixedã€‚

  - restricts the ==exploration space== for `gate sizing`.  
  - Adjustments to gate sizes will sabotage the optimization efforts during earlier stages since the resized gates may not fit the original placement or routing layout.   
  - ==time-consuming==  

-  `gate sizing` has become more challenging due to the ==NP-hard== combinatorial optimization problem [1] for PPA trade-offs required in the large and discrete design space.  

- Innovus and OpenROAD éƒ½æ˜¯åˆ†å¼€åšçš„

- â€œshift-leftâ€ approach [4], suggesting that circuit constraints and performance should be considered in earlier stages of the design flow.   

- éš¾ç‚¹ï¼š`gate sizing` is ==discrete== in nature  

- ![image-20250513222515966](assets/image-20250513222515966.png)

- ![image-20250513223026186](assets/image-20250513223026186.png)

- Previous timing-driven gate sizing methods works' category

  - Dynamic programming-based methods

    - such as [21â€“23].   
    - only achieve optimal solutions for tree-structured circuit topologies and have limitations with reconvergent paths.  

  - Sensitive-based methods.   

    - Works like [24â€“26]   
    - entirely heuristic, with outcomes heavily reliant on the feasibility of the initial sensitivity knowledge  

  - Learning-based methods.   

    - reinforcement learningbased methods [27], generative AI-based methods [28], graph convolutional methods [29, 30], and deep learning-based methods [31]   

    - employ the prevailing learning tricks, the performance of these datadriven models may be compromised once they are applied to other cell and timing libraries. Also, a huge amount of retraining time is unbearable for current fast-paced commercial design cycles. 

    - !!! note
    -     æ„Ÿè§‰ä»¥ååšéå­¦ä¹ çš„æ¨¡å‹éƒ½å¯ä»¥è¿™ä¹ˆè¯´ï¼Ÿ

  - Heuristic methods improved by Lagrangian relaxation (LR)- based formulation 

    - [32â€“40]
    - achieved remarkable success in the past decade. By relaxing the timing constraints in the objective function and employing the Karush-KuhnTucker (KKT) optimality conditions, the search space can be greatly pruned.     
    - However, they still resort to heuristics and local search to derive a suboptimal solution, which can be ==slow== on large designs due to the sequential nature of gate sizing adjustments.  
    - [39] introduced a learning-driven methodology that reduced the initial heuristic search space to accelerate the algorithm. [35, 37, 38] focused on enhancing the efficiency of these processes.  



##### contribution

- the ==first== framework that fuses the optimizations of gate positions and gate sizes with ==differentiable== objectives
- leverages `interpolation`, `gradient descent`, and `GPU-accelerated` computation to optimize `timing` and `power` objectives efficiently
- making discrete gate sizes continuous 



##### flow

![image-20250513221047598](assets/image-20250513221047598.png)

![image-20250513231554361](assets/image-20250513231554361.png)

![image-20250513223915400](assets/image-20250513223915400.png)



##### model

###### ä¼˜åŒ–ä»»åŠ¡ï¼š

![image-20250513223757816](assets/image-20250513223757816.png)

minimize a designâ€™s total `leakage power` while satisfying `timing` constraints  

- åªæœ‰é™æ€åŠŸè€—ï¼Ÿ



###### problem formulation

Given a set of `gates` and an `initial placement layout`, the objective is to minimize total ==leakage power== and the absolute values  of ==TNS and WNS== by simultaneously determining gate positions `x, y` and gate sizes `s`.  



###### key novelty

![image-20250513225118110](assets/image-20250513225118110.png)

åŠ ä¸Šäº†s

![image-20250513225248733](assets/image-20250513225248733.png)

![image-20250513230131079](assets/image-20250513230131079.png)

!!! note
    çº¿æ€§çš„ã€‚è¿™é‡Œæ„Ÿè§‰è¿˜æœ‰å¼€å‘ç©ºé—´



###### Differentiable Leakage Power

![image-20250513225550438](assets/image-20250513225550438.png)

![image-20250513225612522](assets/image-20250513225612522.png)

![image-20250513225648916](assets/image-20250513225648916.png)

![image-20250513225716542](assets/image-20250513225716542.png)



###### Differentiable Timing Objectives  

![image-20250513230732591](assets/image-20250513230732591.png)

![image-20250513230759639](assets/image-20250513230759639.png)

![image-20250513231256182](assets/image-20250513231256182.png)

![image-20250513231306297](assets/image-20250513231306297.png)



![image-20250513231314133](assets/image-20250513231314133.png)



![image-20250513231324197](assets/image-20250513231324197.png)



![image-20250513231344760](assets/image-20250513231344760.png)

![image-20250513231356433](assets/image-20250513231356433.png)

##### dataset

CircuitNet-N28  

![image-20250513231954761](assets/image-20250513231954761.png)



##### experiment

compare our newly developed flow with the open-source OpenROAD [3] flow  

![image-20250513232210271](assets/image-20250513232210271.png)



![image-20250513232246097](assets/image-20250513232246097.png)

![image-20250513232257249](assets/image-20250513232257249.png)



#### [-Gate Sizing Differentiable-ISEDA-2025--PEK]()

- 2024 ICCAD CAD gate sizing contest  

##### background

- `continuity` and `expressivity` limitations  

  - continuity: as almost all core VLSI tasksâ€”such as logic optimization, placement, and routingâ€”require discrete solutions that conflict with the continuous nature of differentiable frameworks.  æ— æ³•æ¢¯åº¦ä¸‹é™

- Prior research on gate sizing generally falls into the following categories:
  - Dynamic programming-based methods  
    - [19]â€“[21]  
    - falter with general circuits containing reconvergent paths.  
    
  - Sensitivity-based method  
    - [22]â€“[24]  
    - based on initial sensitivity estimates
    - relies heavily on the quality of heuristics
    
  - Learning-based methods  
    - including RL [25], generative AI [26], and GCN [27]
    - incur time-consuming retraining when transferred to different technology libraries
    
  - Heuristic methods with Lagrangian relaxation (LR)   
    - [30]â€“[38]
    - reduce the search space using KKT conditions but often rely on slow, local searches and gate-by-gate iterations.
    
  - differentiable methods [5]â€“[7]   
  
    - their discrete size of gates mismatches with continuous gradient descent method  
    - only guarantee their optimization efforts in their own analyzing model outcomes  
  
    

##### contribution

- a  `gradient clipping strategy` to tackle the `continuity limitation`  
- a  `gradient calibration framework` to address the `expressivity limitation`  



##### flow

###### problem fomulation

- a set of gates and detailed placement layout  
- determine the size `s` of all gates in order to minimize total leakage power while eliminating DRVs and timing violations.   

![image-20250616152107048](assets/image-20250616152107048.png)



##### model

###### ä¼˜åŒ–ç›®æ ‡ï¼š

![image-20250514152212165](assets/image-20250514152212165.png)

###### quality score  

![image-20250616153226846](assets/image-20250616153226846.png)



###### Linear interpolation

![image-20250617010201785](assets/image-20250617010201785.png)

!!! note
    çº¿æ€§çš„ã€‚è¿™é‡Œæ„Ÿè§‰è¿˜æœ‰å¼€å‘ç©ºé—´

###### Differentiable Power and Area Objectives

![image-20250617010152468](assets/image-20250617010152468.png)



###### Differentiable DRV and Timing Objectives  

![image-20250617005926996](assets/image-20250617005926996.png)

##### continuity limitation

![image-20250514152910399](assets/image-20250514152910399.png)

With a deeper circuit logic level, this inaccuracy would be amplified  

`Gradient Clipping Solution`  

ä¸€ä¸ªæ›´ç›´è§‚çš„ä¾‹å­ï¼šå¦‚æœå…¨éƒ¨gatesizeéƒ½æ˜¯å››èˆï¼Œé‚£ä¸€å®šä¼šæœ‰å¾ˆå¤§è¯¯å·®

1. initially, all gate sizes are set to minimal. 
2. In each iteration, we upsize the top k~1~% gates with the smallest gradients, as these gates will ==most likely benefit== from adjustmentsï¼›
3. Conversely, to mitigate unnecessary area and power consumption, our algorithm also downsizes the top k~2~% gates with the largest gradients, which are supposed to be oversized gates.   è¿™æ˜¯ä»€ä¹ˆåŸç†ï¼Ÿ

!!! note
    å¯å‘å¼äººå·¥è¶…å‚æ•°åˆå‡ºç°äº†



###### expressivity limitation

gradient calibration  

![image-20250514154700314](assets/image-20250514154700314.png)

!!! note
    å¯ä»¥ç”¨åˆ°ç±»ä¼¼çš„å…¶ä»–å·¥ä½œä¸­

åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£çš„æ—¶å€™ä½¿ç”¨Reference Timerè¿›è¡Œå¯¹é½ä¸€æ¬¡ï¼Œè®¡ç®—ä¸€ä¸ªCalibrateæ¯”ä¾‹å‚æ•°ã€‚é€šè¿‡ç›¸ä¹˜è€Œä¸æ˜¯ä»¥å‰å·¥ä½œçš„ç›¸åŠ ï¼Œè®©å‚æ•°ä¼ é€’ï¼Œæœ€åå¯¹é½å•†ä¸šå·¥å…·ï¼Œè€Œä¸æ˜¯ç®€å•çš„æ•°å­¦æ¨¡å‹

!!! note
    ä½†æ˜¯è¿­ä»£è¶Šä¹…ä¼šè¶Šä¸å‡†ï¼Ÿ

 



###### data

2024 ICCAD CAD gate sizing contest  

post-placement ä¹‹åçš„æ•°æ®

![image-20250617101524760](assets/image-20250617101524760.png)

åŸºäºä»¥ä¸Šæ•°æ®ï¼Œè¿›è¡Œdetail placement å’Œglobal routing ï¼ˆä½¿ç”¨OpenROADï¼‰



##### experiment

![image-20250514155419262](assets/image-20250514155419262.png)

![image-20250617105745469](assets/image-20250617105745469.png)

åœ¨å¤§è§„æ¨¡ç”µè·¯ä¸Šæ•ˆæœæ›´å¥½ï¼šFor the first three cases, their smaller scale increases the variability in gate sizing optimization results, thus making it difficult to achieve consistently optimal outcomes  

### GR

#### [PROS-Routability Optimizatio

![image-20241128091405687](./assets/image-20241128091405687.png)

![image-20241128091759855](./assets/image-20241128091759855.png)



##### task

- congestion **predictor** and parameter **optimizer**
- only the data from the placement  
- it can optimize the cost parameters before the first routing iteration of GR and thus can give a better GR solution with less congestion.  



##### contribution

- with negligible runtime overhead  
- plug-in
- can be embedded into the state-of-the-art commercial EDA tool (Cadence Innovus v20.1)   



##### model

![image-20241219171627049](./assets/image-20241219171627049.png)

##### data

19 different industrial designs  

![image-20241219165446998](./assets/image-20241219165446998.png)



é€šè¿‡ **ä¸åŒçš„ placement å‚æ•°å’Œæ—‹è½¬**ï¼ˆCNN åŸç†ï¼‰ï¼Œä¸€å…±æœ‰ 1664 design cases in total.  



**Feature Extraction**  

- Horizontal/Vertical track capacity map  

- Cell density map

- Flip-flop cell density map  

- Fixed cell density map  

- Cell pin density map  

- Pin accessibility map  

  ![image-20241219161307835](./assets/image-20241219161307835.png)

  - Horizontal/Vertical net density map  

  - Small/Large-net RUDY map  

  ![image-20241219161336920](./assets/image-20241219161336920.png)

- Pin RUDY map

  a combination of cell pin density map and large-net RUDY
  map  

**Label Generation**  

![image-20241219162403381](./assets/image-20241219162403381.png) PROS does not need very detailed congestion map   

two-step smoothening process to convert raw data to desirable congestion labels  

help to make the prediction task easier  

if there are at least six congested G-cells out of the eight in the surrounding of a center G-cell Ğ´, Ğ´ will be labeled as congested  

![image-20241219162837909](./assets/image-20241219162837909.png)

**ä¼˜åŒ–åŸç†**

è¿™ä¸¤ä¸ªå€¼åœ¨ cadence æ€ä¹ˆæ”¹çš„? cadence ä¼ä¸šå†…éƒ¨è‡ªå·±å¼„çš„ï¼ˆè¿™æ˜¯ cadence çš„æ–‡ç« ï¼‰ï¼Ÿ

![image-20241219165904742](./assets/image-20241219165904742.png)

![image-20241219165912121](./assets/image-20241219165912121.png)

##### model

![image-20241219163417043](./assets/image-20241219163417043.png)



##### experiment

![image-20241219172158774](./assets/image-20241219172158774.png)

![image-20241219172205431](./assets/image-20241219172205431.png)

![image-20241219172212018](./assets/image-20241219172212018.png)



![image-20241219172620444](./assets/image-20241219172620444.png)



#### [PROS 2.0 - Routability Opt+Route WL estimation-Trans-2023-CNN-CNHK+Cadence]()

##### background

- the amount of routing resources on a design is limited.   
- The quality of a GR solution has a great impact on that of the resulted DR routing solution  
- Congestion in a GR solution is one of the major causes of DRC violations in the DR
  solution since most of DRC violations are due to overcrowded wires and vias [1], [2]  
- a better GR solution with less congestion is needed to lower the probability of getting DRC violations in advance. 
- if the initial GR solution is not good and has a lot of congestion, the GR tool can hardly tackle the problem by rip-up and reroute.  
- placement engines **[3]â€“[5]** which take routing congestion into consideration are applied  
- FCN: FCN å¸¸ç”¨äºå›¾åƒä¸­çš„æ¯åƒç´ åˆ†ç±»é—®é¢˜ã€‚é‡‡ç”¨ **ä»»æ„è¾“å…¥å¤§å°**ï¼Œå¹¶äº§ç”Ÿå¤§å°å®Œå…¨ç›¸åŒçš„è¾“å‡ºã€‚GR æ‹¥å¡é¢„æµ‹ä¹Ÿå¯ä»¥è¢«è§†ä¸ºä»»æ„å¤§å°çš„èŠ¯ç‰‡è®¾è®¡ä¸Šçš„åƒç´ äºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜ï¼ˆæ‹¥å¡ä¸å¦ï¼‰ã€‚å› æ­¤ï¼ŒåŸºäº FCN çš„é¢„æµ‹å™¨å¯ä»¥è‡ªç„¶åœ°åº”ç”¨äº PROSã€‚



##### task

- stage: post-placement, pre-route
- FCN based GR congestion `predictor`, use the predicted GR congestion to optimize the **cost parameters** of GR. 
- predictor based `parameter optimizer` to generate a better GR solution. GR tools are driven by the cost parameters stored in each G-cell. When arriving at a G-cell g, the tool will compute the cost, called `moving cost`, to move to each of its neighboring G-cells and push these costs into a heap. With optimized cost parameters in G-cells, the GR tool can find better paths and allocate the routing resources to each net more smartly. PROS optimizes two types of cost parameters **based on the prediction result**, including `overflow cost` and `wire/via cost  `.  PROS will adjust the cost parameters in the projected congestion regions on **all layers**  
  - overflow cost
  - wire/via cost: divided into two groups (small/large) according to their BBox sizes. 
    - Increasing the wire/via cost for small nets may be **useless** for congestion reduction and it may even increase the wire length or create new congestion due to detours out of the potential congestion region.  
    - In contrast, increasing the wire/via cost for large nets can be helpful since
      they can select another route within its BBox to completely avoid the potential congestion region
- CNN based  `wirelength estimator  `,  By **multiplying** the predicted wirelength ratio and the precomputed `FLUTE ` wirelength  (è®­ç»ƒä¸€ä¸ªç³»æ•°). The lack of consideration of routing congestion in traditional methods is due to the dif ficulty of quickly obtaining accurate congestion estimation at the placement **stage**



##### contribution

- plug-in for Innovus:  it can avoid extra runtime overhead of feature preparation  
- industrial design suite   
- advanced technology node  
- SOTA
- high accuracy
- first work that 
- utilizes the information of GR congestion to estimate routed wirelength at the placement stage  
- PROS does not change a lot for the original EDA steps  



**Overall Flow** :

![image-20241225231457615](./assets/image-20241225231457615.png)

![image-20241225231740032](./assets/image-20241225231740032.png)

åˆ†ç±»å’Œå›å½’

![image-20241225231939553](./assets/image-20241225231939553.png)

- F is the feature number.  
- X~WL~ has two features:  These two features will be resized to 128 Ã— 128 before prediction  
  - the **predicted** congestion map 
  - the cell pin density map   





##### data

feature F 

- Horizontal/Vertical Track Capacity Map  

- Cell Density Map  

- Flip-Flop Cell Density Map

- Fixed Cell Density Map  

- Cell Pin Density Map  

- Pin Accessibility Map  

  ![image-20241226095003879](./assets/image-20241226095003879.png)

- Horizontal/Vertical Net Density Map

  ![image-20241226095234394](./assets/image-20241226095234394.png)

- Small/Large-Net RUDY Map  

  ![image-20241226095702886](./assets/image-20241226095702886.png)

- Pin RUDY Map ?



**label**

**congestion label  pre-process**

PROS does not need a very detailed congestion map

![image-20241226100513980](./assets/image-20241226100513980.png)

æœ€åè¿˜æ˜¯ä¸ºäº†ä¼˜åŒ–æœåŠ¡çš„



##### model

![image-20241226133238155](./assets/image-20241226133238155.png)

- DC: get more local information, but more GPU usage(acceptable)
- SUB: w\*h\*4c â€“> 2w\*2h\*c.
  - Compared with bilinear upsampling which is not trainable, subpixel upsampling can learn to recover the local information.
  - Compared with deconvolution, subpixel upsampling is parameter free, so
    it will not significantly increase the training difficulty.  



![image-20241226133719030](./assets/image-20241226133719030.png)



**dataset**

industrial benchmark suite and  DAC-2012  benchmark suite(19 ä¸ª benchmark)

industrial benchmark suite é€šè¿‡ 11 ç§ä¸åŒå¸ƒå±€å‚æ•°ï¼Œç¿»è½¬å’Œæ—‹è½¬ï¼Œåˆ¶é€ äº†ä¸€å…±æœ‰ 1664 ä¸ª(çº¦ç­‰äº 19\*11\*8)benchmark

DAC-2012 20 different placements  

(4, 4, 4, 4, 3)  5 æŠ˜äº¤å‰éªŒè¯

![image-20241226134314062](./assets/image-20241226134314062.png)

![image-20241226134322968](./assets/image-20241226134322968.png)



##### experiment

**env**

- Tensorflow  
- Intel Xeon CPUs at 2.2 GHz  
- 256 GB memory  
- NVIDIA TITAN V GPU  

**setting**

- Adam

- One entire training process of the congestion predictor has 25 training epochs! è¿™ä¹ˆå°‘ï¼ˆæ”¶æ•›å¥½å¿«ï¼‰  

  ![image-20241226135108986](./assets/image-20241226135108986.png)



**congestion classification prediction**

![image-20241226135344696](./assets/image-20241226135344696.png)

![image-20241226135500109](./assets/image-20241226135500109.png)

compare with PROBABILISTIC METHODS  

![image-20241226135607227](./assets/image-20241226135607227.png)

![image-20241226135730697](./assets/image-20241226135730697.png)

![image-20241226135756327](./assets/image-20241226135756327.png)

**DR ä¼˜åŒ–ç»“æœ**

![image-20241226140031433](./assets/image-20241226140031433.png)

**çº¿é•¿ä¼°è®¡**

![image-20241226140057750](./assets/image-20241226140057750.png)

![image-20241226142425570](./assets/image-20241226142425570.png)

![image-20241226142433618](./assets/image-20241226142433618.png)

**Runtime**

![image-20241226142533340](./assets/image-20241226142533340.png)

![image-20241226142539173](./assets/image-20241226142539173.png)

#### DR

#### [-Detailed Router-DATE-2021-RL](https://ieeexplore.ieee.org/document/9474007)

![image-20241012161419196](./assets/image-20241012161419196.png)

#### [DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route]("D:\MyNotes\EDA\Routing\DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route.pdf ")

![image-20241027101634534](./assets/image-20241027101634534.png)

- BackGround

  - most time-consuming stages in the **package design** flow  
  - package designs have fewer layers; thus, we need to prevent net crashing cautiously  

- contrbution:

  - redefine the routing area and shrink the routing problem by dividing the entire design into **non-overlapping boxes**  
  - use DRL, not heuristic
  - prove the number of design rule violations (DRVs), wirelength and layout pattern.  

- task

  - 2-pin nets  

  ![image-20241027104527603](./assets/image-20241027104527603.png)

  

  Initial routing: ignores the number of bends and allows design rule violations  

  ![image-20241027104906544](./assets/image-20241027104906544.png)

- Model

  multi-agent deep reinforcement learning (**MARL**) task [15] for **asynchronous** routing planning between nets. We regard each net as an agent, which needs to consider the actions of other agents while making pathing decisions to avoid routing conflict  

  ![image-20241027104558097](./assets/image-20241027104558097.png)

  ![image-20241027105909572](./assets/image-20241027105909572.png)

  route and slide the window repeatedly. advantage of box: process every box independently  

  - sequential routing  

    ![image-20241027134657161](./assets/image-20241027134657161.png)

    ![image-20241027133917659](./assets/image-20241027133917659.png)

    ![image-20241027133231542](./assets/image-20241027133231542.png)

    ![image-20241027133826865](./assets/image-20241027133826865.png)

    the repulsion point will be moved from the inner ring to the outer one until the box is successfully routed.   

    å…·ä½“ç®—æ³•ï¼š

    ![image-20241027141238708](./assets/image-20241027141238708.png)

  - sequential routing  

    ![image-20241027142631796](./assets/image-20241027142631796.png)

    - ![image-20241027143243104](./assets/image-20241027143243104.png)
    - ![image-20241027144931328](./assets/image-20241027144931328.png)

  - Refinement

    ![image-20241027144108460](./assets/image-20241027144108460.png)

    

#### [-Detail routing+match+Opt-ISPD-2023-RL+GNN-FinFET ]()

##### background:

- cutom circuits: a custom detailed router cannot adopt specialized layout strategies for specific circuit classes like human layout experts  

- ![image-20241028221540078](./assets/image-20241028221540078.png)

- ![image-20241028224206180](./assets/image-20241028224206180.png)

- ![image-20241028222447134](./assets/image-20241028222447134.png)

- ä¸€ç›´åœ¨å¼ºè°ƒ match çš„é—®é¢˜ï¼š

  ![image-20241028224639124](./assets/image-20241028224639124.png)

##### contribution

- opt roouting, FinFET, sign-off solution
- å¼‚æ„å›¾
- A rip-up and re-routing scheme  
- can easily adapt to future design constraints  

**three categories  of routing methodologies**  

1. Template-based methods 
   - manual design  
   - suffers from scalability issues   
2. Simulation-based techniques  
   - provide accurate performance feedback and can be generalized to consider various performance metrics (e.g., phase
     margin, power dissipation) across circuit classes  
   - long execution time and resource-hungry computations  
3. Constraint-based approaches  
   - widely adopted in existing custom routing studies  

## PR Tools

### GP_Trad

#### [NTUplace4h- -TCAD-2014-]()



#### [ePlace- -TODAES-2015- ]()



#### [Replace- -TCAD-2018-]()



#### Generalized augmented lagrangian and its applications to vlsi global placement



#### [Chip Placement with Deep Reinforcement Learning-marcro-arXiv-2020-RL](https://arxiv.org/pdf/2004.10746)

- first explores the application of artificial intelligence in solving placement with the attempt to ease the difficulties of manual effort, which may indicate a new development stage for physical design  



#### [Differentiable-Timing-Driven Global Placement-global placement-DAC-2022-GNN-](https://dl.acm.org/doi/pdf/10.1145/3489517.3530486)



#### [Polar 2.0](https://ieeexplore.ieee.org/document/6881450)

 An effective **routability-driven** placer

cells that are estimated to have high congestion are spread out and inflated to distribute routing demand more evenly.  



#### NTUPlace3



#### [DeepPlace](https://github.com/PKUterran/DeepPlace)

##### flow



#### [RePlAce--TCAD-2018-](https://ieeexplore.ieee.org/abstract/document/8418790)



### GP_Adv

#### [DREAMPlace-GPU Accelerate-DAC+TCAD+ICCAD+DATE-2019~2023](https://github.com/limbo018/DREAMPlace)

##### background

- open up new directions for  GP
- current placement usually takes hours for large designs  
- Although `analytical placement` can produce high-quality solutions, it is also known to be relatively slow  

##### contribution

- a totally new perspective of making analogy between placement and deep learning
- Over `30X` speedup over the CPU implementation ([RePlAce](https://doi.org/10.1109/TCAD.2018.2859220)) is achieved in global placement and legalization on ISPD 2005 contest benchmarks
- DREAMPlace runs on both CPU and GPU. If it is installed on a machine without GPU, only CPU support will be enabled with multi-threading.
- DREAMPlace also integrates a GPU-accelerated detailed placer, ` ABCDPlace`, which can achieve around `16X` speedup on million-size benchmarks over the widely-adopted sequential placer [NTUPlace3](https://doi.org/10.1109/TCAD.2008.923063) on CPU.



**Publications**

- [Yibo Lin](http://yibolin.com/), Shounak Dhar, [Wuxi Li](http://wuxili.net/), Haoxing Ren, Brucek Khailany and [David Z. Pan](http://users.ece.utexas.edu/~dpan), "**DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement**", ACM/IEEE Design Automation Conference (DAC), Las Vegas, NV, Jun 2-6, 2019 ([preprint](http://yibolin.com/publications/papers/PLACE_DAC2019_Lin.pdf)) ([slides](http://yibolin.com/publications/papers/PLACE_DAC2019_Lin.slides.pptx))
- [Yibo Lin](http://yibolin.com/), Zixuan Jiang, [Jiaqi Gu](https://jeremiemelo.github.io/), [Wuxi Li](http://wuxili.net/), Shounak Dhar, Haoxing Ren, Brucek Khailany and [David Z. Pan](http://users.ece.utexas.edu/~dpan), "**DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement**", IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020
- [Yibo Lin](http://yibolin.com/), [Wuxi Li](http://wuxili.net/), [Jiaqi Gu](https://jeremiemelo.github.io/), Haoxing Ren, Brucek Khailany and [David Z. Pan](http://users.ece.utexas.edu/~dpan), "**ABCDPlace: Accelerated Batch-based Concurrent Detailed Placement on Multi-threaded CPUs and GPUs**", IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 ([preprint](http://yibolin.com/publications/papers/ABCDPLACE_TCAD2020_Lin.pdf))
- [Yibo Lin](http://yibolin.com/), [David Z. Pan](http://users.ece.utexas.edu/~dpan), Haoxing Ren and Brucek Khailany, "**DREAMPlace 2.0: Open-Source GPU-Accelerated Global and Detailed Placement for Large-Scale VLSI Designs**", China Semiconductor Technology International Conference (CSTIC), Shanghai, China, Jun, 2020 ([preprint](http://yibolin.com/publications/papers/PLACE_CSTIC2020_Lin.pdf))(Invited Paper)
- [Jiaqi Gu](https://jeremiemelo.github.io/), Zixuan Jiang, [Yibo Lin](http://yibolin.com/) and [David Z. Pan](http://users.ece.utexas.edu/~dpan), "**DREAMPlace 3.0: Multi-Electrostatics Based Robust VLSI Placement with Region Constraints**", IEEE/ACM International Conference on Computer-Aided Design (ICCAD), Nov 2-5, 2020 ([preprint](http://yibolin.com/publications/papers/PLACE_ICCAD2020_Gu.pdf))
- [Peiyu Liao](https://enzoleo.github.io/), [Siting Liu](https://lusica1031.github.io/), Zhitang Chen, Wenlong Lv, [Yibo Lin](http://yibolin.com/) and [Bei Yu](https://www.cse.cuhk.edu.hk/~byu/), "**DREAMPlace 4.0: Timing-driven Global Placement with Momentum-based Net Weighting**", IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), Antwerp, Belgium, Mar 14-23, 2022 ([preprint](https://yibolin.com/publications/papers/PLACE_DATE2022_Liao.pdf))
- Yifan Chen, [Zaiwen Wen](http://faculty.bicmr.pku.edu.cn/~wenzw/), [Yun Liang](https://ericlyun.github.io/), [Yibo Lin](http://yibolin.com/), "**Stronger Mixed-Size Placement Backbone Considering Second-Order Information**", IEEE/ACM International Conference on Computer-Aided Design (ICCAD), San Francisco, CA, Oct, 2023 ([preprint](https://yibolin.com/publications/papers/PLACE_ICCAD2023_Chen.pdf))

**Architecture**

![image-20241211185233352](./assets/image-20241211185233352.png)

![image-20241211185244415](./assets/image-20241211185244415.png)

##### flow


##### model

- ä¼˜åŒ–ç›®æ ‡

  ![image-20250323101317234](assets/image-20250323101317234.png)

  ![image-20250323101815867](assets/image-20250323101815867.png)








### GR_Tradictional_sequential   

#### [FastRoute1.0â€”2006]()

- roposed a simple way to construct **congestion driven Steiner tree** and an edge shifting technique to further refine it  

#### [fastroute 2.0-Monotonicâ€“2007]()

- monotonic routing to explore all shortest routing paths for two-pin connections.   

##### task

![image-20241114191327215](./assets/image-20241114191327215.png)

##### flow

**![image-20241114205659503](./assets/image-20241114205659503.png)**

![image-20241115160208134](./assets/image-20241115160208134.png)





#### [fastroute 3.0-virtual capacity-ICCAD-2008-]()



#### [fastroute 4.0-via min tree+3 bending-ASPDAC-2009-]()

![image-20241116121010565](./assets/image-20241116121010565.png)

![image-20241115160433890](./assets/image-20241115160433890.png)

![image-20241115160445784](./assets/image-20241115160445784.png)

![image-20241116105606149](./assets/image-20241116105606149.png)

![image-20241116121317660](./assets/image-20241116121317660.png)

![image-20241116121311506](./assets/image-20241116121311506.png)

**å±‚åˆ†é…**

![image-20241116124343911](./assets/image-20241116124343911.png)

?

![image-20241116125839541](./assets/image-20241116125839541.png)

![image-20241116125830996](./assets/image-20241116125830996.png)

#### [MaizeRouter-]()

- 2nd place of ISPD 2007 contest 2D GR
- 1st place of ISPD 2007 contest 3D GR



#### [FGR-3d-TCAD-2008-](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4526750)

- 1st place of ISPD 2007 contest 2D GR
- 3rd place of ISPD 2007 contest 3D GR
- FGR [6] used maze routing to directly rip up & reroute nets, based on the discrete Lagrangian cost framework.   



#### MGR

- MGR [8] used pattern routing and layer assignment to obtain a 3D initial solution, and then adopted 3D maze routing to rip up & reroute the nets in congestion areas.   





#### [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083)

- Congestion-Constrained Layer Assignment for Via Minimization in Global Routing
- CUGRâ€™s rely work
- ISPD07 contest åçš„ä¸€ä¸ªè·Ÿè¿›å·¥ä½œ
- ä¹Ÿæ²¡æåˆ° maze routing
- æ²¡å®šä¹‰ wire cost, åœ¨æ¯ä¸€å¯¹ GCell ä¹‹é—´ layer assignment, æ…¢ï¼Ÿ
- ç¬¬ä¸€æ¬¡ç”¨ DP?



##### background

- there are two main approaches  

  ![image-20250208202630352](assets/image-20250208202630352.png)

  - `3D`: route all nets directly on the multilayer solution space. Because this approach directly generates a multilayer global routing result, **it can take the via cost into account during construction**. However, this method may cost **too much CPU time** with a large problem size. (ç°åœ¨éƒ½ç”¨ GPU åšå¹¶è¡Œäº†ï¼Œè¿™ç§æ–¹æ³•å°±å˜å¤šäº†)

    1. such as 

       ![image-20250208201732440](assets/image-20250208201732440.png)

  - `2D + layer assigment`: The other approach is to first **compress** a multilayer grid graph into a one-layer grid graph, then use a **one-layer router** to solve the one-layer global routing problem, and finally perform **layer assignment** to assign each wire in the multilayer grid graph

    ![image-20250208202642473](assets/image-20250208202642473.png)

    The edges corresponding to **vias disappear** in the one-layer grid graph. The capacity of each edge in the one-layer grid graph is obtained by **accumulating** the corresponding edge capacities in the three-layer grid graph

    This approach can take advantage of many current full-fledged one-layer routers, e.g., [2]â€“[4], and use an affordable run time to generate an initial one-layer routing result. æœ¬æ–‡ä¸»è¦é’ˆå¯¹ layer assignment. æ³¨æ„ layer assignment æ˜¯å¯¹äºŒç»´çš„æ‰€æœ‰è¾¹è¿›è¡Œå±‚åˆ†é…ã€‚

- vias not only degrade the reliability and the performance of a design but also increase the manufacturing cost.  

- previous workâ€™s layer assignment use greedy heuristics [8] or time-consuming integer linear programming methods [9]  to minimize the via cost.  

- åƒè¿™ç§ä¸²è¡Œçš„è¿˜æ˜¯è¦è€ƒè™‘ net order, è¶Šæ—©å¸ƒçº¿çš„ net è¶Šä¸ä¼šæ‹¥å¡ï¼Œnet order å¾ˆé‡è¦



**task and contribution:**

- è¿™ç¯‡æ²¡æœ‰è€ƒè™‘ä¼˜å…ˆæ–¹å‘ï¼ˆTo simplify the presentation of our algorithm, we do not make any assumption about the preferred routing direction for each layer in the layer assignment problem.ï¼‰ä¸è¿‡ä¹Ÿè¯´æ˜äº†è¿™ä¸ªå·¥ä½œèƒ½å¤Ÿå¾ˆç®€å•å¼•ç”¨åˆ°è€ƒè™‘ä¼˜å…ˆæ–¹å‘çš„æƒ…å†µ
- follow ISPD07 contest, å‡è®¾ via çš„ capacity æ˜¯æ— é™çš„ï¼ˆCUGR ä¸­æ˜ç¡®äº†ä¸è¿›è¡Œè¿™ç§å‡è®¾ï¼‰
- based on a one-layer routing result
- minimize `via cost`, `WL` and `congestion overflow`
- propose a polynomial-time algorithm: first generate `net order` , then solves the layer assignment problem
- can improve 3 winner of ISPD07 contest



##### model  

- COngestion-constrained Layer Assignment (COLA)â€™s submodule

  - Net order generation

    1. The net order has a direct influence on the utilization of routing resources, so it is one of the key parts of COLA.   

    2. å¯¹ net è¿›è¡Œæ‰“åˆ†å†³å®š order

       ![image-20250208220017618](assets/image-20250208220017618.png)

       æ³¨æ„ï¼Œçº¿é•¿è¶ŠçŸ­ï¼Œåˆ†æ•°è¶Šé«˜ï¼Œnet è¶Šåº”è¯¥å…ˆå¸ƒçº¿ã€‚è§£é‡Šï¼š

       ![image-20250208221143998](assets/image-20250208221143998.png)

  - Eemove Cycles

    1.  Arbitrarily remove.

    2. ï¼ˆä¸ºä»€ä¹ˆæ˜ å°„åˆ°ç¬¬ä¸€å±‚ä¼šæœ‰ cyclesï¼Ÿåˆå§‹æ˜¯æ€ä¹ˆè¿èµ·æ¥çš„ï¼Ÿæ²¡è¯´ï¼ŸFLUTE ç®—æ³•æ˜¯ 08 å¹´æ‰å‡ºæ¥ï¼Œå¯èƒ½å½“æ—¶è¿˜æ²¡ç”¨ä¸Šï¼‰

       ![image-20250208222041475](assets/image-20250208222041475.png)

  - Single-net layer assignment  ï¼ˆSOLA+APECï¼‰

    **SOLA**(Singlenet Optimal Layer Assignment)  

    1. determines an optimal layer assignment result **without considering congestion constraints** for a given net  

    2. **dynamic programming** technique

    3. ä¸è€ƒè™‘æ‹¥å¡ï¼Œè¿™ä¸ªæ–¹æ³•èƒ½å¾—åˆ°æœ€å¥½è´¨é‡

    4. step:

       !!! note
           01: for tree in layer 1, **random** select a pin as root, then use DFS or DFS to get a **queue**, so get the edge **order**. It become a **DAG**
           
           ![image-20250208223956201](assets/image-20250208223956201.png)
           
           02: å®šä¹‰å›¾ 5(c)ä¸­, a çš„çˆ¶èŠ‚ç‚¹æ˜¯ p2ï¼Œå®šä¹‰ mvc(v, r)ï¼ˆminimum via costï¼‰
           
           ![image-20250209140741895](assets/image-20250209140741895.png)
           
           03: 
           
           â€‹	for pins who have not child, mvc:
           
           ![image-20250209143711603](assets/image-20250209143711603.png)
           
           â€‹	for pins who have child and not root:
           
           â€‹	è¿™ä¸ªå…¬å¼å…¶å®å°±æ˜¯ä¸ºäº†ç¡®å®šä¸‹æ¯ä¸ªç‚¹ä¸‹ä¸€æ­¥çš„ layer åœ¨å“ªé‡Œã€‚æ¯”å¦‚ç®—å‡ºæœ€å°æ˜¯ mvc(v, 1), é‚£ä¹ˆ e_(v, ch(e))å°±åœ¨ç¬¬ r å±‚
           
           ![image-20250209143753884](assets/image-20250209143753884.png)
           
           â€‹	for root:
           
           ![image-20250209145157487](assets/image-20250209145157487.png)
           
           - the difference is excluding r in âˆ†  
           
           - because mvc(v, r) does not depend on the value of r when v 
           
             is the root, we have mvc (v, 1) = mvc(v, 2) = Â· Â· Â· = mvc(v, k)
           
           

    **APEC**(Accurate and Predictable Examination for Congestion constraints)  

    1. can detect and prevent any **congestion** constraint violation in advance  

    2. prevention condition:

       ![image-20250209153339230](assets/image-20250209153339230.png)

       å¦‚æœå­˜åœ¨ä¸€ä¸ªåœ¨ layer1 ä¸Šå‹ç¼©çš„è¾¹ä¸æ»¡è¶³è¿™ä¸¤ä¸ª conditionï¼Œé‚£ä¹ˆè¿™æ¡è¾¹çš„ layer assignmentï¼ˆSOLAï¼‰ç»“æœå°±ä¸å¯èƒ½æ»¡è¶³ congesion

  - SOLA+APEC always finds a layer assignment result satisfying both **prevention conditions** for each net  

- COLA

  ![image-20250209153812734](assets/image-20250209153812734.png)

  

â€‹	

##### data

six-layer benchmarks from ISPDâ€™07





#### [GRIP-3d+IP-DAC-2009](https://dl.acm.org/doi/pdf/10.1145/1629911.1629999)

åŸºäºæ•´æ•°è§„åˆ’

3d: solve the 3D problem directly on the 3D routing grids,  

slow: Although theoretically the direct 3D technique should produce better solutions, in practice it is less successful in both solution quality and runtime than 2D routing with layer assignment  â€“citeâ€“> [Fastroute4.1]

slow: Although we see solutions with shorter wirelength generated by full-3D concurrent approach like GRIP [21], that solution quality is achieved by impractically long runtime   â€“citeâ€“> [Fastroute4.1]





#### [BFG~R-3d+Lagrangian-ISPD-2010--UMICH+IBM-](https://dl-acm-org-443.webvpn.scut.edu.cn/doi/10.1145/1735023.1735035)

- æœ‰ net order

##### background



##### contribution

1. a novel branch-free representation (BFR) for routed nets  
2. a trigonometric penalty function (TPF)  
3. dynamic adjustment of Lagrange multipliers (DALM)  
4. cyclic net locking (CNL)  
5. aggressive lower-bound estimates (ALBE) for A*-search, resulting in faster routing.  



##### flow

![image-20250328141308281](assets/image-20250328141308281.png)





#### [MGRâ€“ICCAD-2011](https://ieeexplore.ieee.org/abstract/document/6105336)

multi-level ï¼ˆcoarsened  and fine-gainedï¼‰



#### [FastRoute4.1-an efficient and high-quality global router-2012](https://home.engineering.iastate.edu/~cnchu/pubs/j52.pdf)

https://dl.acm.org/doi/abs/10.1155/2012/608362

##### background

FastRoute is a global routing tool for VLSI back-end design. It is based on sequential rip-up and re-route (RRR) and a lot of novel techniques. [FastRoute 1.0](http://home.engineering.iastate.edu/~cnchu/pubs/c36.pdf) first uses **FLUTE** to construct **congestion-driven Steiner trees**, which will later undergo the **edge shifting** process to optimize tree structure to reduce congestion. It then uses **pattern routing and maze routing** with **logistic function** based cost function to solve the congestion problem. [FastRoute 2.0](http://home.engineering.iastate.edu/~cnchu/pubs/c40.pdf) proposed **monotonic routing** and **multi-source multi-sink maze routing** techniques to enhance the capability to reduce congestion. [FastRoute 3.0](http://home.engineering.iastate.edu/~cnchu/pubs/c51.pdf) introduced the **virtual capacity** technique to adaptively change the capacity associated with each global edge to divert wire usage from highly congested regions to less congested regions. [FastRoute 4.0](http://home.engineering.iastate.edu/~cnchu/pubs/c52.pdf) proposed **via-aware Steiner tree**, **3-bend routing** and a **delicate layer assignment algorithm** to effectively reduce via count while maintaining outstanding congestion reduction capability. [FastRoute 4.1](http://home.engineering.iastate.edu/~cnchu/pubs/j52.pdf) simplifies the way the **virtual capacities** are updated and applies a single set of tuning parameters to all benchmark circuits.

##### model

![image-20241211103407310](./assets/image-20241211103407310.png)



##### flow

![image-20241211103347856](./assets/image-20241211103347856.png)





#### [NTHU Route 1.0- -TVLSI-2010-](https://ieeexplore.ieee.org/document/5703167)

![image-20241115155033412](./assets/image-20241115155033412.png)

#### [NTHU Route 2.0- -TCAD-2013](https://ieeexplore.ieee.org/document/6504553)

- 2D
- a history-based cost function.  

#### [NCTU GR 1.0-3D-congestion relaxed layer assignment- 2011-](https://ieeexplore.ieee.org/document/5703167)

- it improved the scheme to estimate the realtime congestion more accurately by using a history term that will gradually wear off as the number of iterations  increases if the overflow disappears.   

#### [NCTU GR 2.0-Multithreaded Collision Aware- CAD-2013-](https://ieeexplore.ieee.org/document/6504553)

[people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm](https://people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm)

[PengjuY/NCTU-GR2: This is a binary file of NCTUgr2, which is a global router](https://github.com/PengjuY/NCTU-GR2)

- net-level parallel method 
- RSMT-aware routing scheme  





#### [OGRE- new cost function- -2019- -](https://woset-workshop.github.io/PDFs/2019/a18.pdf)

- [Open source!](https://github.com/AUCOHL/OGRE)
- **LEF/DEF-based**
- 3D
- ç”¨çš„æ˜¯è€æ–¹æ³•ï¼Œä¸è¿‡è§£é‡Šçš„æŒºæ¸…æ¥šçš„
- components by a group of undergraduate students as a course project.



#### [SPRoute 1.0: A Scalable Parallel Negotiation-based Global Router-ICCAD-2019](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8942105)

- åŸºäº `net-level` å¤šçº¿ç¨‹çš„å¹¶è¡ŒåŠ é€Ÿ `è¿·å®«ç®—æ³•`
- `negotiation-based` rip-up and reroute two-phase maze routing
- resolves livelock issue(CPU)
- open source

- introduced a concept called `soft capacity` to reserve routing space for detailed routing and explored `several parallelization strategies` to speed up global routing. 
- æ˜¯ CPU ä¸Šçš„å¹¶è¡Œï¼Œè®²äº†æŒºå¤šå…³äºé”çš„é—®é¢˜ï¼Œæ²¡çœ‹æ‡‚ï¼Œè®©æˆ‘ä»¬çœ‹ 2.0 å§
- 2D





##### background

æ€»ä½“

![image-20241118140649906](./assets/image-20241118140649906.png)

In many global routers, maze routing is the most time-consuming stage.  

![image-20241118141048410](./assets/image-20241118141048410.png)

**challenge**

![image-20241118144548718](./assets/image-20241118144548718.png)

![image-20241118144701004](./assets/image-20241118144701004.png)

å› ä¸ºè¿™ä¸ªç°è±¡ï¼Œå¤šçº¿ç¨‹åè€Œæ…¢äº†

![image-20241118144924768](./assets/image-20241118144924768.png)

**åŸç†**

- Galois system  

  ![image-20241118150854386](./assets/image-20241118150854386.png)

- Net-level Parallelism  

- Fine-grain Parallelism  







##### data

ISPD 2008  contest





#### [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)

- ICCAD 2019 Contest First Place

- [open source!](https://github.com/cuhk-eda/cu-gr)

- 3d+å¤šçº¿ç¨‹+

- è¿™ä¸ªæ–‡ç« æ²¡æœ‰è®¨è®º prefer direction

- å¤šçº¿ç¨‹ä½“ç°åœ¨å“ªé‡Œï¼Ÿ

- will take more runtime than 2D initial routing  

- æ³¨æ„ï¼šè¿™ç§æ ¼å¼çš„ GR è¾“å‡ºå¯ä»¥é€‚é… Innovus

- A probability-based cost scheme   

- CUGR [9] used 3D pattern routing based on dynamic programming to obtain an initial routing, and used multi-level 3D maze routing for rip-up and rerouting to obtain a final global routing solution  

- time-complexity of 3D pattern routing is $\mathcal{O}(L^4|V|)$

  compare with [Trans-2008](# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083)), CUGR reduces the complexity to $\mathcal{O}(L^4|V|)$ by selecting the root carefully so that each vertex will have at most three preceding vertices instead of four.  ~~æ³¨æ„ï¼Œè¿™é‡Œè¯´ ç›¸æ¯” [Trans-2008](# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083))çš„ $\mathcal{O}(L^5|V|)$ ï¼Œå®ƒçš„å¤æ‚åº¦æ˜¯ $\mathcal{O}(L^4|V|)$ ï¼Œæ„Ÿè§‰æ˜¯æ”¾åœ¨äº† [Trans-2008](# [-Layer assignment+Via minization-Trans-2008-DP-NTHU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/4603083))è¿›è¡Œä¸è½¬å¼¯çš„ DP-based layer assignment æ–¹æ³•ä¸Šäº†ï¼Œå®é™…ä¸ŠæŒ‰ç…§æœ¬æ–‡è¯´çš„æ–¹æ³•ï¼Œç†è®ºä¸Šæ˜¯ $L * L^{2*3}|V|$ï¼Œå› ä¸º CUGR æ¯æ¬¡æ˜¯å¯¹ä¸€ä¸ª L pattern ä¸ºå•ä½è®¡ç®— `mvc`, æ—¶é—´å¤æ‚åº¦æ˜¯ $2*L*L$~~.ç¡®å®æ˜¯ $L^4$, CUGR å¯¹ä¸€ä¸ª L pattern åˆ†äº†ä¸¤éƒ¨åˆ†è®¡ç®— `mvc` æ²¡ä¸€éƒ¨åˆ†æ—¶é—´å¤æ‚åº¦æ˜¯ $L*2$



##### background

![image-20241122110742970](./assets/image-20241122110742970.png)

- A common strategy of doing 3D global routing, as adopted by NCTU-GR 2.0 [5], NTHU-Route 2.0 [6], NTUgr [7] and FastRoute 4.0 [8], is to **first compress the 3D grid graph into a 2D grid graph and perform 2D global routing**.   
- directly route the nets in a 3D grid graphï¼šFGR [10] , GRIP [11] , MGR [12]  
- Traditional pattern routing generates 2D topologies only, while **our** proposed 3D pattern routing directly generates 3D topologies without the need of an extra layer assignment stage
- ä½¿ç”¨ DR ç»“æœè¿›è¡Œå¤šè§’åº¦ metrics è¯„ä¼°ï¼š

![image-20241122113634633](./assets/image-20241122113634633.png)

##### task

- detailed-routability-driven  directly-3d multi thread GR



##### contibution

- probability-based cost scheme
  - minimizing the possibility of overflow after detailed routing
- `3D pattern routing` technique (2D pattern routing + layer assignment)(å‰é¢åˆè¯´ directly in the 3D space?)
  - without overflow even only L shape patten routing
  - pre-work [15] æ˜¯å…ˆåœ¨ 2d ä¸Šè¿›è¡Œ pattern routing, ç„¶åè¿›è¡Œ layer assignment, è¿™é‡Œæ˜¯ç›´æ¥åœ¨ 3d è¿›è¡Œ pattern routing. 3d pattern routing can avoid loss of accuracy caused by compressing 3D grid graph to 2D  
- `multi-level maze routing`:
  - coarsened level â€“> searches for a region with the **best routability**. **first** narrows the search space to a smaller region  
  - fine-grained level â€“> searches for a **lowest cost** solution within the region
- patching mechanism
  - further improve the detailed routability





##### flow

![image-20241122123825463](./assets/image-20241122123825463.png)



In `3D pattern routing` (`inital routing`), the nets are broken down into two-pin nets, and a `dynamic programming` based algorithm will route the two pin nets sequentially using Lshape patterns and `stacking vias` at the turns.  



In the `multi-level 3D maze routing` phase, the grid graph is `coarsened` to shrink the routing space, and maze routing is first performed in the coarsened space with an objective to find a routing region with the **highest routability**.   A `fine-grained maze routing` will then search for a lowest cost path within the region.  use its `patching` mechanism here.



##### model

- Gcell ä¹‹é—´çš„å®¹é‡ç­‰äº trackï¼Œä¸€èˆ¬ GR è¡¨å¾ via çš„å®¹é‡æ˜¯æ— é™çš„ï¼Œä½†æ˜¯åœ¨æœ¬æ–‡ä¸­ä¸æ˜¯

- **three base definition:**
  - resource = capacity - demand
  - è¿™ä¸‰ä¸ªå˜é‡åœ¨ GCell å’Œ wire_edge ä¸Šéƒ½æœ‰ç‰¹å¾ï¼Œä¹Ÿå°±æ˜¯è¯´æœ‰ 6 ä¸ªå€¼
  - resource èƒ½å¤Ÿç›´æ¥è¡¨ç¤ºæ‹¥ç¨‹åº¦
  - ![image-20241122130729921](./assets/image-20241122130729921.png)
  - ![image-20241122130736928](./assets/image-20241122130736928.png)



- **cost scheme**

  - ä¸»è¦åˆ†æˆ wire å’Œ via ä¸¤éƒ¨åˆ†ï¼š

    ![image-20241122130626631](./assets/image-20241122130626631.png)

  - wire cost:

    ![image-20241122130653693](./assets/image-20241122130653693.png)

    1. *`wl`* is wire lenght cost

    2. *`eo`* is expected overflow cost, where *`uoc`* is hyper parameter, The larger  *`d(u, v)`* is, the more likely it is to be congested. is accurate if the **DR** adopts the simplest strategy of picking a track **randomly** to route. However, most well designed detailed routers will do much better than random selection.  

    3. *`lg(u,v)`* is a variable to refine *`d(u, v)`*. â€œ+1â€ æ˜¯ä¸ºäº†å€¼åŸŸåœ¨ï¼ˆ0ï¼Œ1ï¼‰è¡¨ç¤ºæ¦‚ç‡ã€‚ *`slope`* is hyper parameter. When the resources are abundant, there is almost **no congestion cost**, but the cost will increase rapidly as the resources are being used up and will keep increasing almost **linearly** after all the resources are used  

       ![image-20241122130807532](./assets/image-20241122130807532.png)

  - via cost:

    1. thanks to our **3D pattern routing strategy**, a via cost scheme can be embedded to reflect the impact.  
    2. ![image-20241122130701652](./assets/image-20241122130701652.png)
    3. *`uvc`* is hyper parameter. 
    4. å…¬å¼ï¼ˆ5aï¼‰ä¸ºä»€ä¹ˆè¦â€œ+1â€

- Initial Routing / 3D Pattern Routing

  1. use `FLUTE` first (not congestion awared)

  2. use `edge shifting` (described in [FastRoute](#[FastRoute1.0â€”2006]())) to alleviate  congestion.

  3. **randomly** choose one node in net, use DFS to get a queue and then get a DAG

  4. ç±»ä¼¼ [15]ï¼ŒåŠ¨æ€è§„åˆ’é€‰æ‹© cost æœ€å°çš„ 3d L patternï¼Œæ¯ä¸ª L pattern æœ‰(2 * L * L)ç§å¯èƒ½

     ![image-20250209165125803](assets/image-20250209165125803.png)

     æœ€ååœ¨ root å¤„å¾—åˆ°æœ€ç»ˆçš„ç»“æœ

- Multi-level 3D Maze Routing  

  - maze route planing

    aims at finding a smaller but highly routable search space

    1. compress a block of G-cells (5x5 in our implementation), use avg to descripe `capacity, demand, resource`

    2. cost function:

       ![image-20250209172954350](assets/image-20250209172954350.png)

    3. å¾—åˆ°ç°è‰²ç²—ç½‘æ ¼ï¼š

       ![image-20250209173822187](assets/image-20250209173822187.png)

    4. ä¹‹åä¼šåœ¨è¿™å‡ ä¸ª BBox ä¸­åˆ†åˆ«è¿›è¡Œè®¡ç®— `cost scheme`ï¼Œå¾—åˆ°ä¸Šå›¾é»‘è‰²å®çº¿

  - fine-grained maze routing within guides

- Postprocessing / Guide Patching  

  - we can add new guides to improve detailed routability. adding new stand-alone guides to alleviate routing hot spots.  

  - three kind of patching:

    1. Pin Region Patching  

       - most effective  

       - the ideal way of improving pin accessibility is to identify those hard-to-access pins and assign more resources to them  

         ![image-20250209191227014](assets/image-20250209191227014.png)

       - Our global router will check the upper (or lower) two layers of a pin, which are vital for accessing the pin. use 3 Ã— 3 patching guides. 

       - æ²¡å†™åˆ¤æ–­ `hard-to-access pins  ` çš„å…·ä½“çš„æ–¹æ³•

    2. Long Segment Patching:  

       - a longer routing segment often means more wrong way wires and causing more congestion.  
       - If a guide is longer than a specified length I, weâ€™ll consider long segment patching.  

       ![image-20250209191725644](assets/image-20250209191725644.png)

       - if a G-cell with resource below a threshold T is encountered, a single G-cell route guide will be patched above or below it, depending on which of them has sufficient resource  

    3. Violation Patching:  

       - For G-cell with inevitable violations, patching will be used again to enable the detailed router to search with more flexibility.   

         ![image-20250209192310471](assets/image-20250209192310471.png)


##### data

iccad 2019 dataset

##### experiment



![image-20241122113716242](./assets/image-20241122113716242.png)

![image-20250209192916035](assets/image-20250209192916035.png)

- ä»–è‡ªå·±åˆæ¯”èµ›åæ”¹è¿›äº†

- ![image-20250209195431218](assets/image-20250209195431218.png)

- our algorithmâ€™s peak memory is close to the first place and is 1.83 times of that of the second place on average (ours is 8.22 GB on average and is **19.8 GB** for the biggest design)






#### [VGR-3D+via mini-ASPDAC-2024- -FZU+iEDA](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/document/10473939)

- a 3D global router with via minimization and multi-strategy ==rip-up and rerouting==  

- CPU-based

  



##### background

- ==Vias== are interconnections between different routing metal layers. A large number of vias can reduce manufacturing yield, cause circuit performance degradation, and increase layout area required for interconnections [1], [2]  In VLSI physical design, meeting the DFM (Design for Manufacturability) constraints is essential, and these constraints often include strict requirements regarding vias.  

- Most academic global routers use pattern routing to obtain initial solution quickly. However, the lack of candidate scheme for pattern routing results in significantly high overflow for the initial solution.  

- However, existing rip-up and rerouting techniques do not fully consider via minimization.  

- ä¸ºä»€ä¹ˆè¦ 3Dï¼Œ3D çš„ä¼˜åŠ¿ï¼š

  ![image-20250310112711168](assets/image-20250310112711168.png)

  



##### contribution

- a novel multi-strategy rip-up & rerouting framework  
- first leverages two proprietary routing techniques  
  - via-aware routing cost function  
  - 3D monotonic routing   
  - 3D 3-via-stack routing  
- an RSMT-aware expanded source 3D maze routing algorithm  



##### flow

![image-20250310140059564](assets/image-20250310140059564.png)



##### model

###### Modified Via-Aware Routing Cost Function

- previous works' via penalties are based on a constant cost function, or, the cost of via may decrease over time.  

- RUDY-based

  ![image-20250310150030680](assets/image-20250310150030680.png)

- CUGR:

  ![image-20250310150007361](assets/image-20250310150007361.png)

- Ours:

  ![image-20250310150038994](assets/image-20250310150038994.png)

###### Local Rip-up & Rerouting

![image-20250310150116571](assets/image-20250310150116571.png)

![image-20250310150130359](assets/image-20250310150130359.png)

###### Global Rip-Up & Rerouting

1. 3D 3-via-stack routing

   - focuses on adding as few vias as possible  

     ![image-20250310151014205](assets/image-20250310151014205.png)

   - A 3D 3-via-stack path consists of three parts:   

     - two 3D Lshape paths
     - a stack of vias  

   - The 3D 3-via-stack routing is faster than 3D maze routing and offers good congestion reduction. We use it before 3D maze routing to reduce the number of overflowed nets, resulting in lower total overflow and via counts  

2. RSMT-aware ESMR(expanded source 3D maze routing ).  

   - increases wire length as less as possible
   - After completing the 3D 3-via-stack routing algorithm, only a small number of nets have congestion, and we need to use 3D maze routing to process these nets  
   - ![image-20250310153555924](assets/image-20250310153555924.png)
   - ![image-20250310160008974](assets/image-20250310160008974.png)

##### experiment

1. Effectiveness of 3D Monotonic Routing and 3D 3-Via-Stack Routing  

   one using 3D monotonic routing, 3D 3-viastack routing and the RSMT-aware ESMR, and another using only the RSMT-aware ESMR  

   ![image-20250310161001286](assets/image-20250310161001286.png)

2. Effectiveness of RSMT-Aware ESMR  

   ![image-20250310161128720](assets/image-20250310161128720.png)

3. Comparison with the State-of-the-Art  

   ![image-20250310161315484](assets/image-20250310161315484.png)

   ![image-20250310161303747](assets/image-20250310161303747.png)

4. detailed results of all components of the â€˜DR Scoreâ€™  

   ![image-20250310161451514](assets/image-20250310161451514.png)

   This demonstrates that V-GR can find a routing scheme with fewer vias and less overflow while maintaining almost the same wire length.  

   

### GR_Concurrent

#### [-Multicommodity Flow-Trans-2001-](https://janders.eecg.utoronto.ca/1387/readings/global_routing.pdf)

- first Multicommodity Flow?







#### [BoxRouter 1.0- -DAC-2006-ILP- -](https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/1146909.1147009)

- 3rd place of ISPD 2007 contest 2D GR
- 2nd place of ISPD 2007 contest 3D GR
- integer linear programming (ILP)  based



##### background



##### contribution

- PreRouting step can capture the most ==congested== regions with reasonable accuracy
- key `BoxRouting` idea   
  - BoxRouter progressively expands the routing box and performs routing within each expanded box (BoxRouting), until the expanded box covers the whole circuit (all the wires are routed)  
- efficient progressive integer linear programming  ==(ILP)==   
  - In our ILP, only wires between two successive boxes are considered with L-shape patterns. Thus even with ILP, our runtime is still much faster than existing global routers [1] [2] [16]
  - without rip-up  



##### flow

![image-20250317113717747](assets/image-20250317113717747.png)



#### [sidewinder-scalable ILP-SLIP-2008-ILP- -]()

- åªæœ‰ 10^4^æ•°é‡çº§çš„ net æ•°æ®





##### background



##### contribution

- dynamically-updated congestion map  



##### flow





#### [BoxRouter 2.0- - -2008-ILP- -]()

- [OpenSource!](https://github.com/Apodead/BoxRouter)
  - ![image-20250317123459126](assets/image-20250317123459126.png)
  - github ä¸Šæœ‰ä¸¤ä¸ªç‰ˆæœ¬, è²Œä¼¼éƒ½ä¸æ˜¯ä½œè€…çš„
- æ˜¯ä¸€ä¸ª 2d çš„ GR
- concurrent: æ•´æ•°çº¿æ€§è§„åˆ’ï¼ˆILPï¼‰

![image-20241115155857782](./assets/image-20241115155857782.png)

##### background



##### contribution

- dynamic scaling for robust `negotiation-based` A* search
- topology-aware wire ripup 
  - which rips up some wires in the congested regions without changing the net topology.
- integer linear programming (ILP) for via/blockage-aware layer assignment



##### flow

![image-20250317113738643](assets/image-20250317113738643.png)

â€‹                               

#### [GRIP-combination opt-Trans-2009-DP- -NTU](https://jlinderoth.github.io/papers/Wu-Davoodi-Linderoth-10-PP.pdf)

- è¿™ä¸ªæœ‰ä¼šè®®å’ŒæœŸåˆŠä¸¤ä¸ªç‰ˆæœ¬
- GRIP [7] determined 3D routing candidate patterns for each net in advance, and then used ILP for optimal selection.   
- åŸºäºç»„åˆä¼˜åŒ–



#### [COALA-concurrent layer assignment -TCAD-2022-]()

- 2d

- capacity æ”¾åˆ°äº† gcell

  ![image-20250328171500477](assets/image-20250328171500477.png)

- M1 is congested and leaves not much routing resource  

- ![image-20250328174737057](assets/image-20250328174737057.png)

  ä»–çš„ concurrent æ˜¯ net ä¸æ˜¯ sequencial è¿›è¡Œå¸ƒçº¿äº†ï¼Œä½†å…¶å®è¿˜æ˜¯æœ‰è¿›è¡Œå¯å‘å¼ sequencial çš„éƒ¨åˆ†

  åŸæ–‡è¿˜è¯´ï¼š`The candidate segments in Sseg of the current layer are sorted according to three criteria and are sequentially assigned.  `




##### background

- Two-dimensional (2-D) global routing followed by layer assignment is a common and popular strategy to obtain a good tradeoff between runtime and routing performance.   

- State-of-the-art (SOTA) studies on layer assignment usually adopt `dynamic programming-based approaches` to `sequentially` find an optimal solution for each net in terms of overflow or/and the number of vias.  However, a fixed assignment ordering severely restricts the solution space, and the distributed overflows can hardly be resolved with any existing refinement approach  

- rip-up and rerouting  spends most of the runtime in the whole global routing process   

- existing layer assignment approaches suffer from two common drawbacks  

  1. First, most of the above works sequentially perform layer assignment for each net based on dynamic programming (DP)-based algorithms. In spite of the ==optimality== of a DP-based method that minimizes the overflow increment and the number of vias for each net, the ==assignment ordering== of all nets severely restricts the solution space, making the overall assignment result ==far from optimal==. 
  2. Second, the DP-based approaches cause difficulties in the assignment refinement process. For a tile with a large overflow, ==deciding or iteratively trying which segments should be ripped up and reassigned/shifted== critically determines the final solution quality and becomes another complicated optimization problem.  
  3. In addition, the resulting overflows are randomly scattered on segments, and thus the existing refinement techniques are only performed on each individual wire segment suffering from overflow, limiting the effectiveness in overflow reduction.  (æ²¡çœ‹æ‡‚)

- ![image-20250328164946356](assets/image-20250328164946356.png)

  This overflow can be resolved if the ordering of the blue net and the red net is reversed, while an optimal ordering can hardly be found by using simple heuristics adopted by the above existing works  

- there exist some studies proposing Lagrangian relaxation or integer programming-based approaches to consider the layer assignments of multiple nets  

- sequential layer assignment approaches suffer from limited solution quality  


##### contribution

![image-20250328165901489](assets/image-20250328165901489.png)

ä¸€å±‚ä¸€å±‚ assign

- capacity of a tile  



##### flow

![image-20250328173807513](assets/image-20250328173807513.png)

![image-20250328194952939](assets/image-20250328194952939.png)







##### model

###### æœ¬æ–‡å®šä¹‰çš„ capacity and demand(éƒ½åœ¨ GCell ä¸Š)

![image-20250328171752900](assets/image-20250328171752900.png)

![image-20250328172800671](assets/image-20250328172800671.png)

###### demand congestion map

ç”¨ 2d çš„ routing é¢„æµ‹ 3d demand

![image-20250328173211326](assets/image-20250328173211326.png)



###### Complete Segment Assignment

The complete segments are ==sorted== according to the following three criteria.  

1. Residual Parts of Fragmented Segmentsï¼šhighest priority  

2.   The Degree of Net Completeness  

   $Completeness = N_{assigned}/N_{total}$

3. Segment Length: assign the shorter segment prior to the longer one

   can result in fewer number of vias  

###### Fragmented Segment Assignment

1) Prediction Map Update for Fragmented Segments  

2) Fragmented Segment Ordering and Assignment:  

   A candidate segment can be fragmented and assigned for a subcolumn if the following two conditions are satisfied:  

   - its connected via to the lower layer lies in the subcolumn 
   -  its fragmented subpart (blue part) has to overlap the subcolumn with more than one tile.  
   - ![image-20250328201342596](assets/image-20250328201342596.png)
   - ![image-20250328203232933](assets/image-20250328203232933.png)

###### 3-D Endpoint Rerouting  

![image-20250328203521908](assets/image-20250328203521908.png)

After assigning wire segments for the topmost layer, some segments may still be left unassigned  because of an inaccurate 2-D capacity and demand model.  

four stepsï¼š

1. Redundant Via and Partially Fragmented Segment Removal
2. 3-D Multiendpoint Decomposition  
3. 3-D Net Ordering  
4. 3-D Endpoint Rerouting



###### OBSTACLE-AWARE STRATEGY  





##### data

ISPD18 å’Œ ISPD19



##### experiment

å¯¹æ¯”çš„æ¨¡å‹ CUGR



#### [-Lagrangian based- DAC-2023-FZU-ILP-](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10247969)

- integer linear programming   
- Lagrangian relaxation method  
- direction-aware weighted A*-algorithm 

##### background

- combine the advantages of the two classes of algorithms  ï¼ˆä¸²å¹¶è¡Œï¼‰
- `BoxRouter 2.0 [5] and Sidewinder [9]` propose a ==maximum routable== ==ILP model==, which routes as many nets as possible without congestion by ==using several routing patterns.==   Due to limited routing patterns for each net, the two routers may cause some nets ==disconnected==, requiring ==post-processing== to produce a legal final result.   `GRIP [6]` proposes an ==ILP formulation== that minimizes the total wire length and the number of vias, which ==includes many routing patterns== . For their ILP, the LP relaxation is ==restricted to a small number of routing patterns== and is solved by the `column generation method`, and then the obtained solution is optimized ==using a local improvement procedure to consider other patterns==.  



##### contricbution

- a novel `ILP based pathfinding model` which does not need to generate candidate routing patterns of nets prior
- We propose a `Lagrangian relaxation method` combined with a `gradient ascent method` to update the multipliers, in which `direction-aware weighted A*-algorithm` is used to quickly solve a subproblem  
- a multi-stage rip-up & rerouting algorithm to optimize the initial routing result, in which each stage uses different routing algorithms and cost functions



##### flow

![image-20250328105529319](assets/image-20250328105529319.png)

1. FLUTE   
2. Integer Linear Programming (ILP)   
3. Lagrangian relaxation method combining with a direction-aware weighted A* algorithm   
4. monotonic routing and maze routing  



##### model

![image-20250328114329898](assets/image-20250328114329898.png)

###### ILP Based Pathfinding Model

æ²¡çœ‹æ‡‚ `ILP Pathfinding model`

- an ILP based pathfinding model without considering routing patterns  

- ![image-20250328114337684](assets/image-20250328114337684.png)

  ![image-20250328114346493](assets/image-20250328114346493.png)

  ![image-20250328114353126](assets/image-20250328114353126.png)

![image-20250328114400547](assets/image-20250328114400547.png)

![image-20250328114411949](assets/image-20250328114411949.png)

![image-20250328114420408](assets/image-20250328114420408.png)

###### Lagrangian Relaxation Method and Initial Routing  

![image-20250328144717218](assets/image-20250328144717218.png)

![image-20250328144955900](assets/image-20250328144955900.png)

###### Direction-aware Weighted A*-Algorithm  

![image-20250328145457020](assets/image-20250328145457020.png)

##### Multi-stage Rip-up & Rerouting

![image-20250328160555252](assets/image-20250328160555252.png)

![image-20250328160637121](assets/image-20250328160637121.png)



##### data

ISPD18



##### experiment





#### [DGR-DAG Routing Forest+2D-DAC-2024-DP-CMU+NVIDA](https://dl-acm-org-443.webvpn.scut.edu.cn/doi/pdf/10.1145/3649329.3656530)

- [OpenSource!]()

- Directed Acyclic Graph (DAG)-based  

- 2D

- åŸºäº DP çš„ Layer assignment

- åªæ˜¯é€‰æ‹©äº†æ›´ä¼˜çš„ Tree? å¹¶ä¸”åªæ˜¯åœ¨è¿™éƒ¨åˆ†æ˜¯ concurrent çš„ï¼Ÿé€šè¿‡ç‰ºç‰²é¢å¤–çš„æ—¶é—´è·å–æ›´å¥½çš„ tree

  

##### backgroun

- sequential algorithms do not guarantee optimal solution among all nets because of its sequential heuristic. Moreover, its sequential heuristic falls short in addressing routing congestion from a global perspective, possibly leading to unnecessary iterations of rip-up and reroutes.   
- ==Combinatorial optimization techniques [4, 5]== could concurrently optimize multiple nets. But they are often ==too slow== for modern VLSI circuits  
- concurrent ç›¸æ¯” sequencial æ–¹æ³• åœ¨å¸ƒçº¿è´¨é‡çš„ä¼˜è¶Šæ€§
- ä»¥å¾€ GPU-accelerate å·¥ä½œå…¶å®æœ¬è´¨è¿˜æ˜¯ sequencial
- 1.Steiner tree ç›¸åŒæœ€çŸ­é•¿åº¦æœ‰å¤šé‡æ‹“æ‰‘





##### contribution

- `concurrent optimization`  for hundreds of thousands of nets  
- a routing DAG forest to represent the search space  
- a GPU-accelerated  differentiable algorithm for scalable and efficient search within the DAG forest.   
  - `Gumbel-Softmax` technique with ==temperature annealing== and ==top-p selection==  



##### flow

![image-20250310174115344](assets/image-20250310174115344.png)



##### model

routing DAG forest  

![image-20250310190910290](assets/image-20250310190910290.png)

![image-20250310192646124](assets/image-20250310192646124.png)

updated through `back-propagation`

1. \##### Routing DAG Forest

   - a mathematical structure to systematically describe the 2D pattern routing space for all the nets.   
   - In contrast to CUGR2 [2], (which addresses one net at a time and focuses on a single Steiner tree topology in each instance,) our routing DAG forest allows ==multiple DAGs for each net== and facilitates the coordination of DAG and DAG edge selection across all nets in a ==global view==.  
   - The construction of the DAG forest has a direct impact on the runtime and quality of DGR outcome  
   - ä½œä¸ºæœªæ¥çš„ä¸€ä¸ªæ–¹å‘ï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨å¿…è¦æ—¶ä¸ºæ‹¥æŒ¤åœ°åŒºçš„ç½‘ç»œå¼•å…¥æ–°çš„ DAG å’Œ DAG è¾¹ï¼Œæ¢ç´¢æ£®æ—çš„é€‚åº”æ€§æ‰©å±•

2. Pattern Routing

   - The dynamic programming-based layer assignment  

   - he objective of 2D pattern routing is to select the best routing DAGs (routing trees) and DAG edges (2-pin paths) for all the nets such that the total wire length, number of vias, and routing overflow are minimized

     ![image-20250310193043799](assets/image-20250310193043799.png)

     ![image-20250310193049521](assets/image-20250310193049521.png)

     ![image-20250310193100653](assets/image-20250310193100653.png)

3. Routing DAG Forest Construction  

   - Initially, multiple routing tree candidates are formulated for each net using `FLUTE`. Then, all L-shape pattern paths are enumerated for each 2-pin sub-net and incorporated into the pool as 2-pin path candidates. In the final step, each candidate will be associated with a probability, which is initialized ==randomly==.  
   - its ==fine-tuned version== by CUGR2, which ==moves Steiner points based on congestion==.  
   - Itâ€™s worth noting that this is not restricted to just these two techniques; alternative routing tree generation algorithms, such as `SALT [15]` and `TreeNet [16]`, can seamlessly integrate their resulting trees as additional candidates.   

4. Continuous Relaxation and Cost Calculation

   cost = 500 Ã— overflow_cost + 4 Ã— via_cost + 0.5 Ã— wirelength_cost  

   ![image-20250310202209692](assets/image-20250310202209692.png)

   ![image-20250310202234130](assets/image-20250310202234130.png)

5. Differentiable Optimization  

   ![image-20250310203121207](assets/image-20250310203121207.png)

   - gumbel_softmax function   

     - ![image-20250310204941750](assets/image-20250310204941750.png)

       ![image-20250310204950851](assets/image-20250310204950851.png)

       1. Gumbel noise (ğ‘”ğ‘–)  

          å¦‚æœåªæ˜¯ä½¿ç”¨ç®€å•çš„ softmax æ¯”å¦‚ï¼Œ softmax deterministically samples a probability distribution. This ==deterministic== nature can inadvertently lead to ==local optima==, especially when the probabilities have ==a bad initialization==. ![image-20250310205049767](assets/image-20250310205049767.png)

          Gumbel åˆ†å¸ƒ ![image-20250310204727025](assets/image-20250310204727025.png) ![image-20250310204734834](assets/image-20250310204734834.png)

       2. temperature (ğ‘¡)  

          temperature annealing. It ensures that the final probabilities associated with routing tree candidates closely approximate either ==0 or 1==  

6. Deriving Discrete Selection  

   top-p sampling [18]  ï¼ˆä»€ä¹ˆä¸œè¥¿ï¼Ÿï¼‰



##### data

Synthetic data is utilized for this experiment since the ISPDâ€™18 and ISPDâ€™19 benchmarks are too large for ILP  

![image-20250310212008063](assets/image-20250310212008063.png)



##### experiment

1. \##### ä¸ ILP æ–¹æ³•çš„å¯¹æ¯”

   è§ä¸Šå›¾ï¼ˆdata ä¸­ï¼‰

2. compare result with CUGR2

   ![image-20250310212843028](assets/image-20250310212843028.png)

   shows a superior routing quality on all testcases   

3. compare result with other 

   ![image-20250310213413575](assets/image-20250310213413575.png)

4. cost function 

   ![image-20250310213752149](assets/image-20250310213752149.png)

   We can see that the selection of ğ‘“ influences the result, especially overflow, significantly, and sigmoid is the best choice, which outperforms CUGR2  

   ![image-20250310214059794](assets/image-20250310214059794.png)

   DGR has slightly more runtime overhead than CUGR2 when the number of nets is less than one million, when the design complexity continues increasing, ==DGR becomes more efficient than CUGR2==  

   The memory result is given in Figure 5b, which shows that both CPU and GPU memory overhead is almost ==linear== with the number of nets.  

### GR_Adv_RL

#### [-DRL method-2019-DRL-](https://arxiv.org/pdf/1906.08809)

- first DRL related work?
- RL framework: `DQN` 
- proves its overall performance is better than the sequential Aâˆ— algorithm.   
- This method falls short of practical benchmarks that can involve over 100,000 nets [26] 
- 3D 
- have not use real world design



##### background

- Existing solutions typically consist of `greedy algorithms` and `hard-coded heuristics`.   
- As such, existing approaches suffer from a `lack of model flexibility` and `non-optimum solutions`
- current solutions rely primarily on ==heuristically driven== greedy methods  



##### contribution

- è¯¥ç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸åŒå¤§å°å’Œçº¦æŸçš„å‚æ•°åŒ–å…¨å±€è·¯ç”±é—®é¢˜é›†ä¸­ï¼Œä»è€Œèƒ½å¤Ÿè¯„ä¼°ä¸åŒçš„è·¯ç”±ç®—æ³•ï¼Œå¹¶ä¸ºæœªæ¥çš„æ•°æ®é©±åŠ¨è·¯ç”±æ–¹æ³•ç”Ÿæˆè®­ç»ƒæ•°æ®é›†ã€‚
- ==the first== attempt to formulate and solve global routing as a deep reinforcement learning problem.   
- It is noted however that our approach, similar to previous approaches, ==does not guarantee global optimum==  
- RL for a ==closed loop== global routing solution  





##### flow

![image-20241114192055104](./assets/image-20241114192055104.png)

A* is executed first in order to provide `burn-in memory` for the DQN solver  

using A* as burn-in for DRL allows DRL to converge much faster  

##### model

example:

â€‹	from A to B

â€‹	read means over flow

![image-20241114192638647](./assets/image-20241114192638647.png)

Bold edges have zero capacity  

![image-20241114193438871](./assets/image-20241114193438871.png)



**state**:

- (pos_x/y/z, distance_x/y/z, å‘¨å›´çš„ capacity,  )è¿™ç§ç¼–ç æ–¹æ¡ˆå¯ä»¥è¢«è§†ä¸ºå½“å‰çŠ¶æ€ã€å¯¼èˆªå’Œæœ¬åœ°å®¹é‡ä¿¡æ¯çš„æ··åˆ

**action**

ä¸Šä¸‹å·¦å³å‰å

**reward**

![image-20241114200225347](./assets/image-20241114200225347.png)

![image-20241114200512353](./assets/image-20241114200512353.png)



##### experiment

###### env

- python



###### RESULT

å‚æ•°é€‰æ‹©ä¹Ÿè®¸å¯ä»¥å€Ÿé‰´ä¸€ä¸‹å¤§æ¦‚é‡çº§

![image-20250424174857561](assets/image-20250424174857561.png)



#### [Alpha PD Router-MCTS-MLCAD-2019- -Canada Ucalgary Gandhi](https://ieeexplore.ieee.org/document/9142109)

- A Reinforcement Learning-Based Framework for Solving Physical Design Routing Problem in the Absence of Large Test Sets
- ç›¸å…³ç¡•å£«è®ºæ–‡ï¼š[Reinforcement Learning-Based Framework to Generate Routing Solutions and Correct Violations in VLSI Physical Design](https://ucalgary.scholaris.ca/server/api/core/bitstreams/870e141b-ac3f-4125-8b8a-f5f125bbcc52/content#page=102.20)
- based on a two-player collaborative game model  
- The proposed model has the potential to be used as a framework to develop RL based routing techniques untethered by the scarce availability of large routing data samples or designer expertise.  
- ==two-player collaborative== game rather than a multiplayer game problem  
- inspired by `Alpha-Go Zero`



##### background

- the lack of a large number of test cases has been a significant hindrance to obtaining high-quality results, the only design benchmark test sets that are available to academics are the ISPD 2018 and ISPD 2019 benchmarks which in total have 27 circuits [21] [22]  



##### contribution

- Development of a reinforcement model for routing  and RRR
- Designing a collaborative game-theory model  



##### flow



##### model

###### two-player

two players have different strategies and reward    

-  `Cleaner` 

  - which detects design rule violations, selects the best net to rip to fix the violation and rips it  
  - ![image-20250424125223907](assets/image-20250424125223907.png)
  - ![image-20250424125230654](assets/image-20250424125230654.png)
  - The Cleaner rips all the possible net candidates ==one by one== and sends them to be re-routed by the Router.   (é‚£å°±æ…¢äº†)
  - With each re-route, the Router issues a reward to inform Cleaner how good its job was from the Routerâ€™s perspective. Cleaner aims to maximize these rewards by ripping the nets that make the Routerâ€™s job easier.   

-  `Router` 

  - who performs routing. Router employs a path search algorithm such as A-star  

  - is responsible for re-routing the ripped nets without producing any new violations  

  - The solution from the Cleaner is given to the Router. This solution is a partially routed circuit. 

    ![image-20250424125149440](assets/image-20250424125149440.png)

  - The move prediction in Router is optimized by the feedback from the MCTS algorithm to the neural network (NNET) architecture.   

If no violations exists and all the nets are routed, both Router and Cleaner win and a design rule violation free solution is produced.   

###### Min-max Game Framework

è¿™ä¸ªæ˜¯ä»€ä¹ˆï¼Ÿä¸æ¸…æ¥š[34-36]

this formulation allows us to cast the routing problem into a potentially tractable two-player game rather than a huge multiplayer game where the players count equals the number of nets (e.g. millions).  



###### experiment

![image-20250424130402737](assets/image-20250424130402737.png)

#### [-quasi-Newton method  -arxiv-2021-Double DQN-JP](https://arxiv.org/pdf/2010.09465)

- accelerate the training of deep Q-networks  by introducing a second order Nesterovâ€™s accelerated quasi-Newton method
- è¿™ç¯‡å¯ä»¥è¯´æ˜¯ä¸€ä¸ªäºŒé˜¶ä¼˜åŒ–å™¨åœ¨GRä¸Šçš„åº”ç”¨
- åŸºäº[arxiv-2019]()é‚£ç¯‡



##### background

- why DRL: As the state and action space of the problem increases, the estimation of the state-action value can be slow and time consuming and hence estimated as a function approximation.   These function approximations can be represented as a non-convex, non-linear unconstrained optimization problem and can be solved using deep neural networks (known as deep Q-networks).  
- Using ==second order curvature information== have shown to improve the performance and convergence speed for non convex optimization problems   
  - Adam, RMSprop éƒ½æ˜¯ä¸€é˜¶çš„
  - BFGS  æ˜¯ä¸€é˜¶çš„
  - Nesterovâ€™s accelerated quasi-Newton (NAQ) method [5] was shown to accelerate the BFGS method using the Nesterovâ€™s accelerated gradient term.  
- Why RL: Conventional routing automation tools are usually based on analytical and path search algorithms which are NP complete. Hence a machine learning approach would be more suitable for this kind of automation problem.  Studies that propose AI techniques such as machine learning, deep learning, genetic algorithms deal with only prediction of routability, short violations, pin-access violations, etc. Moreover, the nonavailability of large labelled training datasets for a supervised learning model is another challenge.  





#### [-Steiner point-ISPD-2022-Monte Carlo-NYMCTU-]()

- è¿™ç¯‡æ„Ÿè§‰æ²¡æœ‰åœ¨GRä¸Šçš„åº”ç”¨åœºæ™¯

- OARSMT(Obstacle-Avoiding Rectilinear Steiner Tree)

  The input of the OARSMT problem is a set of pins and a set of obstacles on a routing plane. The objective of the OARSMT problem is to find a minimum-length Steiner tree  that connects all the pins following the grids of the routing plane while not crossing any obstacle  

- an OARSMT algorithm represented by an agent can be automatically developed and continually improved by itself  

- basicline: RL framework:`[13]`  (policy-based ), trained by Monte Carlo tree search (MCTS) [14] + UCT formula [15]

- state-of-the-art OARSMT algorithm [7], [8]  

- our developed OARSMT router can be viewed as a policy neural network that can keep on ==evolving== by applying itself to more unseen layouts, as opposed to a conventional OARSMT algorithm built with ==fixed rules predetermined by humans.==  

- Curriculum learning [16]: the convergence of the agent can be speeded up and the quality of selected Steiner points can be improved  

- Sequence version: for a layout with n pins, the policy neural network needs to be inferenced for ==n-2 times== sequentially to obtain all ==n-2 Steiner points.== In our framework, once the initial sequential agent is trained  



##### background

- Recent related works on OARSMT [2-11] can be classified into the following four types of methods:   
  1. ==spanning-graph-based== method [2-5], which builds a routing tree based on a spanning graph containing all pins and corners of obstacles;   
  2. ==Steiner point-based== method [6-8], which focuses on selecting proper Steiner points
  3. ==lookup-table-based== method [9], which extends the lookup-table method for rectilinear Steiner tree to further handle obstacles    
  4. ==exact-algorithm-based== method [10,11], which applies the concept of `GeoSteiner` [12] and further reduce the numbers of full Steiner trees and obstacles to be handled
- a layout with n pins needs at most n-2 Steiner points  



##### flow

this work focus on first step, step 2 use [8]

- two-stage process  
  1. selecting an optimal set of Steiner points, which is still NP-complete  
  2. constructing the actual routing tree by finding an obstacle-avoiding rectilinear minimum spanning tree (OARMST) connecting all the pins and selected Steiner points, which can be done in ==polynomial time== as shown in [6-8]  
     - The job of the agent here is to find an optimal set of Steiner points, which is done by iteratively selecting the best next Steiner point based on the current state, i.e., the layout of the pins, obstacles and already selected Steiner points. 



##### model

###### state

$H \times V \times 3$ binary array in grid graph

- whether the vertex is a pin  
- a selected Steiner point 
- covered by an obstacle   

The input of our policy agent

###### action

add a Steiner point at a vertex  



###### reward



###### MCTS

![image-20250424101448483](assets/image-20250424101448483.png)

![image-20250424101517025](assets/image-20250424101517025.png)





##### data

15x15 and 30x30 grids,  



##### experiment





#### [- -WCMC-2023-DRL-FuZhouU-Genggeng Liu](https://onlinelibrary.wiley.com/doi/epdf/10.1155/2023/6593938)

- most of the existing methods are heuristic algorithms, which cannot conjointly optimize the subproblems of global routing, resulting in congestion and overflow  
- DRL å’Œ RL çš„åŒºåˆ«ï¼šRL often faces the problem of the excessive number of states when dealing with high-dimensional spaces. With the development of deep learning, the Deep Reinforcement Learning (DRL) algorithm is developed by combining artificial neural networks with RL [10], which makes it possible for RL to solve the policy decision in a high-dimensional space   



##### background

- this paper takes the overflow as the main design goal and optimizes the wire length and congestion based on the overflow as 0.  
- `Serial routing` usually sorts nets in a specific order and routes them one by one; ==this method is fast==ï¼ˆç›¸å¯¹å¹¶è¡Œç»„åˆä¼˜åŒ–çš„æ–¹æ³•ï¼Ÿï¼‰. However, there is an unfair phenomenon: the routing difficulty of the earlier nets has sufficient routing resources (meaning that the capacity of each edge in the routing area is large), while most of the later nets have tight routing resources, so the serial routing method usually rips up part of the nets and reroutes them  
- The `parallel method` routes multiple nets at the same time [21], solving the unfairness of routing resources in a serial method, but it is ==often very time-consuming and even impossible to solve==, mainly based on the commodity flow model [22] and ==integer linear programming== model [23]  



##### contribution

- use DDQN instead of DQN
- an action reduction method  
- a concurrent training method   
  - solve the unfair resource allocation problem  
- a new reward function  



##### model



è¾“å…¥ stateï¼ša 15-bit code is used; the starting point, the ending point, and the agentâ€™s position are all represented by a 3-bit code; and a 6-bit code represents the edge capacities in six directions  

è¾“å‡º actionï¼šaction-value of 6 directions. ä½†æ˜¯ç”±äºæ¯å±‚æœ‰ä¼˜å…ˆæ–¹å‘ï¼Œæ‰€ä»¥å®é™…ä¸Šæœ€å¤š 4 ä¸ªã€‚éœ€è¦åœ¨ä»£ç†é€‰æ‹©åŠ¨ä½œæ—¶ï¼Œé¦–å…ˆæ¶ˆé™¤æ— æ³•æ‰§è¡Œçš„åŠ¨ä½œï¼Œä»¥é˜²æ­¢ä»£ç†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰§è¡Œå†—ä½™åŠ¨ä½œï¼Œå­˜å‚¨å†—ä½™ç»éªŒï¼Œç„¶åå­¦ä¹ å†—ä½™ä¿¡æ¯ã€‚



reward:

![image-20250224230102150](assets/image-20250224230102150.png)

If ed is higher than ec/2, a reward r < 0  is given; otherwise, a reward  r â‰¥ 0 will be given.  ï¼ˆä»–å…¬å¼æ˜¯ä¸æ˜¯é”™äº†ï¼Ÿï¼‰







uses a heuristic algorithm to search for the path in advance and burn it into the experience replay buffer  ï¼ˆç±»ä¼¼é¢„è®­ç»ƒï¼‰convergence speedup

![image-20250224224528028](assets/image-20250224224528028.png)







#### [-DRL+segment based-ISEDA-2023-DRL+GNN-PEK](https://ieeexplore.ieee.org/abstract/document/10218371)

- DRL(GAT)
- segment-based feature extraction  
- pattern routing  enhance



**enhance:**

- 3d?
- åŠ ä¸Š GCELL ä¹‹é—´çš„è¿æ¥ï¼Ÿ
- åƒ InstantGR åšä¸€äº›æ°´å¹³å‚ç›´åˆ†å±‚çš„æ“ä½œï¼Ÿ
- capacity æ”¾è¾¹ä¸Š







##### background

- many traditional global routing methods lack learning ability.  
- more and more problems in physical design are searching for automated solutions based on machine learning. One popular application is to adopt machine learning to help early prediction  



##### contribution

- congestion-aware reinforcement learning model  
- Integrating pattern routing with reinforcement learning  
- Proposing a net segment mode  





##### flow

![image-20250221235557954](assets/image-20250221235557954.png)



**model:**

- GNN feature
  - Node embedding.  
  - Pin number.
  - Fly line number.  
  - Capacity value
  - Bounding box number.   
  - Position correlation.  



- DRL(A3C)
  - We set the policy network as a fully connected layer with 200 neurons and the value network as a fully connected layer with 100 neurons.
  - Feature  of net segments
    - Net density value
    - Congestion prediction value
    - Capacity ratio value



##### data

ISPD18 benchmark  



##### experiment





**question:**

- åŸæ–‡æ²¡è¯´ prediction model çš„ label æ˜¯ä»€ä¹ˆ
- RL æ€ä¹ˆåšå¹¶è¡Œï¼Ÿå…·ä½“æ˜¯æ€ä¹ˆæ ·çš„ï¼Œä¸ç†Ÿ



#### [- -APCCAS-2024-DRL(DDQN)-CYCU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10808325)

- DRL-based A* search algorithm
- æ²¡æœ‰ pattern routing çš„ç¯èŠ‚
- å°±æ˜¯ 19 å¹´é‚£ä¸€ç¯‡ï¼ŒæŠŠ DQN æ”¹æˆ DDQN
- ä¿—æ–‡



##### background

- aim to find better solutions to minimize total wire length (WL) and edge overflow (OF)  
- current solutions mainly rely on heuristic-driven greedy methods, which primarily address situations with strict constraints on the problems to be solved, such as sequential network routing after network sorting [2].   
- The A* algorithm is based on heuristic search, using a heuristic function to estimate the minimum cost from the current node to the target node. It can be used to find the shortest path from the starting point to the target pin.   



#### [RL Ripper-RRR-GLSVLSI-2023- -Canada Ucalgary Gandhi]()

- In this work[8], an RL agent to rip up nets was trained. The benchmark circuits used in this work were taken from the International Conference on Computer-aided Design [33]. However, only training results were provided, highlighting a gap in the literature regarding the scale of benchmarks and the specific problems addressed in proof-of-concept scenarios.  --cite--> [RL Ripper 2.0]()



#### [RL Ripper 2.0-RRR&VIOs Opt-Trans(TODAES)-2024- -Canada Ucalgary Gandhi]()

- incorporates a self-learning model called `RL-Ripper`  

- [previous work]( https://doi.org/10.1145/3583781.3590312  ) 

- compared to the state-of-the-art global router `CUGR`  

- Key point: reduce short violations  

- can be replicated for newer technologies  

- ç”¨äº†å¤§ç”µè·¯

- æ²¡å¼€æº, å¯å¤ªå¯æƒœäº†

- æ„Ÿè§‰åªèƒ½ç®—ä¸€ä¸ªCUGRçš„ä¼˜åŒ–

- RL model:`A2C` and `DQN`, 

  - æœ‰ä¸€ä¸ªå‘ç°ï¼šå¤æ‚çš„å¤§ç”µè·¯è¦ç”¨DQN![image-20250424193153789](assets/image-20250424193153789.png)
  - <img src="assets/image-20250424195605026.png" alt="image-20250424195605026" style="zoom: 67%;" /><img src="assets/image-20250424195614246.png" alt="image-20250424195614246" style="zoom:67%;" />
  - åŸºäº`OpenAI Gym`åº“

  

##### background

- Why RL: heuristic solutions are not adaptable to the ever-changing fabrication demands, and the experience and creativity of designers can limit their effectiveness.   Reinforcement learning (RL) is an effective method to tackle sequential optimization problems due to its ability to adapt and learn through `trial and error`.   
- for net with overflow, the most generic RRR method is to rip all nets with short violations and reroute them. However, this heuristic is not the most efficient way since short violations can highly depend on the respective net routes and the order in which they are ripped and rerouted.  
  - After the first iteration of sequential routing, all the nets causing violations are ripped and re-routed. This can result in several RRR iterations. Furthermore, ripping all the nets can be unnecessary if a netâ€™s route is already optimized. Hence, an intelligent ripping algorithm that pairs well with the order of nets and helps to reduce overall RRR cost is needed.  



##### contribution

- RL-Ripper Framework  
  - a self-learning Ripper agent that relies ==solely on net features==  
  - eliminating the need for externally labeled data  
  
- Evaluation on Large-scale Academic Benchmarks  
  - ä»¥å‰çš„RLGRç¡®å®éƒ½æ˜¯å®éªŒæ€§è´¨çš„å°ç”µè·¯
  
- Pervasive AI Framework
  - fosters collaboration between traditional physical design algorithms (typically coded in `C++`) and machine learning algorithms developed in `Python`.  
  
  - enabling real-time feature extraction without the overhead associated with file read-write operations, such as pickle data exchange
  
  - åŸºäº`Gym`  çš„`ZMQ client`  interface  
  
    ![image-20250424194943213](assets/image-20250424194943213.png)





##### flow

![image-20250424185400749](assets/image-20250424185400749.png)

(1) We set the number of total training episodes as N , and the current episode, n, is initialized to 0. 

(2) We obtain initial routing, using the pattern routing generated by CUGR [24]. 

(3) We save the routes under the name `route-Orig`.

(4) We calculate the number of violations from the routed nets and store the results as `cur_V`  

(5), nets that are ==predicted== to have routing violations due to congestion are sorted in a particular sequence. We will elaborate on this sequence in Section 3.2.

(6), we select the top net in the ordered list of nets with violations `xi`, where i indexes the nets with violations.

(7), the RL engine generated ==one of the two possible actions== `Rip` or `NotRip` based on the features of the nets  

(8), the Net `xi` goes through RRR. 

(9), the total number of nets with violations is recalculated (`new_V`). 

(10), an `â€œifâ€` condition is processed to examine if the action a is `Rip`  

(11), if the action is a `Rip` action, the net is ripped and re-routed. Based on the new route, a reward is calculated based on `Algorithm 1`.

(12), if the action is `NotRip`, the net is still ripped and re-routed. The reward is recalculated based on the `NotRip` action from `Algorithm 1`. 

(13), we set the routing of xi to that of the initial routing of `route-Orig`. 

(14), the weights of the neural networks are updated. 

(15), the condition is checked to see if all the nets are considered 

(16), to process the next net. 

(17), Otherwise, the flow goes to the next `episode`



##### model

###### Stateï¼š five net feature:

1. HPWL
2. VIOs 
   - calculated by CUGR's pattern routing
3. VIAs
   - calculated by CUGR's pattern routing
4. \#Pins
5. WL
   - calculated by CUGR's pattern routing

###### Action

- `Rip`
- `NotRip`  



###### Reward

- based on the number of violations resolved by ripping and re-routing nets  

![image-20250424194258453](assets/image-20250424194258453.png)

##### data

ISPD'18

- S-set: fewer than 100k cell, (design 1-5)
- L-set: otherwise

![image-20250424195239651](assets/image-20250424195239651.png)



##### experiment

![image-20250424195528062](assets/image-20250424195528062.png)

!!! note
    å…¨éƒ½åªæ˜¯3æ¬¡è¿­ä»£ï¼Ÿå¤šä¸€äº›å¯èƒ½æ›´èƒ½è®©äººä¿¡æœ



ä¸»è¦å·¥ä½œï¼š

![image-20250424200750987](assets/image-20250424200750987.png)

!!! note
    è¿™é‡Œçš„violationæŒ‡çš„æ˜¯overflowå—ï¼Ÿ

æ•ˆæœæ˜æ˜¾ï¼

![image-20250424200718389](assets/image-20250424200718389.png)

å¯è§†åŒ–:

<img src="assets/image-20250424202040169.png" alt="image-20250424202040169" style="zoom:50%;" /><img src="assets/image-20250424202103782.png" alt="image-20250424202103782" style="zoom:50%;" />

Detailed Routing.

![image-20250424201637529](assets/image-20250424201637529.png)

![image-20250424201916241](assets/image-20250424201916241.png)

![image-20250424202124557](assets/image-20250424202124557.png)

### GR_Adv_Gen

#### [-generative-arXiv-2019-CNN-](https://arxiv.org/pdf/1706.08948)

- first CNN

#### [-only CNN-DAC-2020-CNN(VAE)-](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=9218598)

- no experiment!
- åªç”¨ CNN åˆ†ç±»ç»“æœä¸ä¼šå¥½å§
- ä¸çŸ¥é“æ˜¯ä»€ä¹ˆç±»å‹çš„æ–‡ç« ï¼Œåªç”¨äº†ä¸¤é¡µ
- evaluates its router on parts of the nets from a public benchmark layout and achieves 96.8% of routability  
- it seems that the router can only route two- and three-pin nets, which may have some limitations for application.   



##### background

- is approach treats the global routing problem as an **image processing** problem and solves it with a deep learning system  

![image-20241114161657070](./assets/image-20241114161657070.png)

##### data

ISPDâ€™98 ibm01 64x64 circuit  

##### model

![image-20241114162111775](./assets/image-20241114162111775.png)



#### [PRNet- -NeurIPS-2022- -SJTU+Noahâ€™s Ark]()

- PRNet can generate each route in `one-shot` but **cannot guarantee connectivity** which requires considerable ` post-processing` for failed routes 

- HubRouter æ˜¯ä¸¤é˜¶æ®µæ¡†æ¶ï¼ŒPRNet æ˜¯ç«¯åˆ°ç«¯æ¡†æ¶ã€‚ 

- the shortest RST like Fig. 1f generated by HubRouter [8] is not practically usable  --cite--> NeuralSteiner  

  ![image-20250324192922713](assets/image-20250324192922713.png)




#### [HubRouter-generative model-NeurIPS-2023-GAN+RL-SJTU]()

- [open source!](https://github.com/Thinklab-SJTU/EDA-AI/tree/main/HubRouter)
- [a chinese interpretation](https://picrew.github.io/2024/03/10/HubRouter/)
- a global routing solver that includes a two-phase learning framework
- HubRouter æ˜¯ä¸¤é˜¶æ®µæ¡†æ¶ï¼ŒPRNet æ˜¯ç«¯åˆ°ç«¯æ¡†æ¶ã€‚
- å¯¹æ¯” PRNet ç”Ÿæˆæ¨¡å‹ï¼ŒPRNet åœ¨ CGAN ä¸­ä½¿ç”¨åŒå‘æ˜ å°„å°†è¿æ¥çº¦æŸæ³¨å…¥è®­ç»ƒç›®æ ‡ï¼Œå°†å‡†ç¡®ç‡æé«˜äº† 10%ï¼Œä½†åœ¨å¤æ‚æƒ…å†µä¸‹å‡ ä¹æ— æ•ˆã€‚
- clipping all images to the same scale 64 Ã— 64  



##### background

![image-20250210234157942](assets/image-20250210234157942.png)

- å…¨å±€å¸ƒçº¿(Global Routing - GR)æ˜¯ VLSI è®¾è®¡ä¸­æœ€å¤æ‚ä¸”æœ€è€—æ—¶çš„ç»„åˆé—®é¢˜ä¹‹ä¸€ã€‚GR ç›®æ ‡æ˜¯æ€»çº¿é•¿æœ€å°ï¼ŒåŒæ—¶é¿å…æ‹¥å¡(Congestion)ï¼Œæ˜¯ä¸ª NP é—®é¢˜ã€‚

  ä¼ ç»Ÿé‡‡ç”¨å¯å‘å¼ç®—æ³•ï¼Œå¤šæ ·æ€§å’Œè§„æ¨¡é—®é¢˜å¯¹ä¼ ç»Ÿç®—æ³•æœ‰äº†æŒ‘æˆ˜ï¼Œæœºå™¨å­¦ä¹ (ML)å·²ç»ç”¨äºå…¨å±€å¸ƒçº¿ï¼Œåœ¨èŠ¯ç‰‡è®¾è®¡ä¸­ä»é€»è¾‘åˆæˆåˆ°å¸ƒå±€

- æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning - DRL )å’Œç”Ÿæˆå¼æ¨¡å‹(Generative model)å·²ç»è¢«ç”¨æ¥è§£å†³å…¨å±€å¸ƒçº¿ã€‚é—®é¢˜åœ¨äºï¼Œ**DRL å¾ˆå—çŠ¶æ€ç©ºé—´(State Space)å½±å“ï¼Œéšç€ç½‘æ ¼ç©ºé—´å¢å¤§ï¼Œéœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´ç”Ÿæˆ**ã€‚However, DRL methods suffer from large state space and often need to spend enormous time on generating routes as the scale of grids increases on the test instance, i.e., the netlist, which is practically intimidating for real-world global routing  

- ç›¸åï¼Œç”Ÿæˆå¼æ¨¡å‹æœ‰ **ä¸€æ¬¡æ€§ç”Ÿæˆèƒ½åŠ›**ï¼Œåœ¨è®¡ç®—ä¸Šæ›´å®¹æ˜“å¤„ç†ã€‚

- ç”Ÿæˆå¼æ–¹æ³•åœ¨è®­ç»ƒæ—¶å€™è€ƒè™‘è¿é€šæ€§é™åˆ¶ï¼Œç¡®ä¿å¸ƒçº¿æ»¡è¶³ç”µè·¯è¿é€šæ€§è¦æ±‚ã€‚ä½†æ˜¯é—®é¢˜åœ¨äºï¼Œå¦‚æœåˆå§‹ç”Ÿæˆè·¯å¾„ä¸æ»¡è¶³è¿é€šæ€§è¦æ±‚æ—¶å€™ï¼Œåå¤„ç†é˜¶æ®µä¼šå˜æˆä¸€ç§ç©·ä¸¾æœç´¢è¿‡ç¨‹ã€‚

- ![image-20250210231714841](assets/image-20250210231714841.png)

- å›¾ä¸€è¿™é‡Œä¸Šå›¾è¡¨ç¤ºåŸå§‹å¸ƒçº¿ï¼Œä¸‹å›¾è¡¨ç¤ºç®—æ³•ç”Ÿæˆçš„å¸ƒçº¿ï¼Œç”Ÿæˆå¸ƒçº¿æ²¡æœ‰æ­£ç¡®è¿æ¥æ‰€æœ‰åº”è¯¥è¿æ¥çš„ç‚¹(pin)ï¼Œå¯¹äºè¿™æ ·çš„æƒ…å†µï¼Œå¹³å‡è¿é€šç‡å¾ˆä½ï¼Œä½äº 20%ï¼Œæ„å‘³ç€è¶…è¿‡ 80%çš„ç”Ÿæˆå¸ƒçº¿éœ€è¦ç»è¿‡è€—æ—¶çš„åå¤„ç†æ‰èƒ½è¾¾åˆ°è¦æ±‚ã€‚æ˜¾è‘—çš„ç¼ºç‚¹ã€‚å…¶å®å°±å’Œ [CNN-based](# [-only CNN-DAC-2020-CNN(VAE)-](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp =&arnumber = 9218598))è¿™ç¯‡ä¸€æ ·

- ![image-20250210233812834](assets/image-20250210233812834.png)



##### contribution

-  ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œå®šä¹‰äº†ä¸€ä¸ªæ–°çš„æ¦‚å¿µï¼Œå« `hub`ã€‚å°† pin - pin é—®é¢˜ --> hub - pin é—®é¢˜ ã€‚

-  æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤é˜¶æ®µå…¨å±€å¸ƒçº¿æ–¹æ³• --> HubRouter

   - generation phaseï¼ˆç”Ÿæˆé˜¶æ®µï¼‰

     `hubs`, `routes`, and `stripe masks` are together generated under a multi-task framework by generative models  

     å¯ä»¥åœ¨å¤šä¸ªæ¡†æ¶ä¸‹ç”Ÿæˆï¼Œæ¯”å¦‚ GAN (Generative Adversarial Nets) , VAE (Variational Auto-Encoder) , DPM (Diffusion Probabilistic Models) ã€‚è™½ç„¶ hub æ˜¯ç”Ÿæˆé˜¶æ®µçš„ä¸»è¦è¾“å‡ºï¼Œä½†ä¸ºäº†æå‡ç”Ÿæˆè´¨é‡å’Œå‡†ç¡®æ€§ï¼Œå‘ç°ç”Ÿæˆé™„åŠ ä¿¡æ¯æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚æ¯”å¦‚æ„ŸçŸ¥å’Œæ©ç (`local perception` and `stripe masks`)ï¼Œèƒ½å¤Ÿå»é™¤å™ªå£°ç‚¹ã€‚å¼•å…¥ `å¤šä»»åŠ¡å­¦ä¹ `ï¼Œå¸ƒçº¿å’Œæ©ç ä¸€èµ·ç”Ÿæˆï¼Œæé«˜ hub ç”Ÿæˆè´¨é‡

   - pin-hub-connection phaseï¼ˆhub å’Œ pin è¿æ¥é˜¶æ®µï¼‰

     å°†è¿æ¥è§†ä¸º `æœ€å°æ–¯å¦çº³æ ‘(RSMT)` é—®é¢˜ï¼Œä½¿ç”¨ `actor-critic ` æ¨¡å‹ç½‘ç»œç­–ç•¥ã€‚

     is hub generate correcttly, reconstruction time complexity can be reduced to **O(n log n)**  

- SOTA generative global routing models  



**model:**

![image-20250210234537382](assets/image-20250210234537382.png)

- Hub

  ![image-20250212194312475](assets/image-20250212194312475.png)

  - (virtual) key point in the route  
  - transferring the pin-pin connection problem to the hub-pin connection problem
  - æ–¯å¦çº³ç‚¹(Rectilinear Steiner Point --> RSP)æ˜¯æœç´¢å…¨å±€æœ€å°æ€»è·ç¦»ï¼Œä½†æ˜¯ hub æ˜¯æ¥ç¡®å®šè·¯å¾„ã€‚RSPs are special cases of hubs  
  - RSP æ˜¯ Hub çš„ç‰¹ä¾‹ï¼ŒHub å¯ä»¥éšæ„ç”Ÿæˆä¸åŒå½¢çŠ¶çš„è·¯å¾„(ä¸ä»…æ˜¯æœ€çŸ­çš„)
  - è¿™é‡Œçš„ `c` å’Œ `x` åˆ†åˆ«ä»£è¡¨æ¡ä»¶å›¾åƒå’Œè¾“å…¥å›¾åƒã€‚æ¡ä»¶å›¾åƒå¯èƒ½åŒ…æ‹¬å¼•è„šä½ç½®ã€å·²ç»æå–çš„ä¸­å¿ƒç‚¹ä»¥åŠæ¡å¸¦æ©æ¨¡ï¼ˆstripe maskï¼‰ã€‚æ¡å¸¦æ©æ¨¡æ˜¯ç”¨æ¥æŒ‡ç¤ºå¸ƒçº¿åŒºåŸŸçš„ä¸€ç§æ–¹å¼ï¼Œå®ƒå¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å“ªäº›åŒºåŸŸå¯ä»¥ç”¨äºå¸ƒçº¿

##### flow

![image-20250212201906601](assets/image-20250212201906601.png)

- hub ç”Ÿæˆé˜¶æ®µ

  - Hub ç”Ÿæˆå¯ä»¥è¡¨ç¤ºä¸ºå›¾åƒåˆ°å›¾åƒçš„ `multi-task learning framework`   ä»»åŠ¡, address the impact of sensitive **noise** points with stripe `mask learning`  

  - `é™„å½• B ` ä»‹ç»äº†å°† GANï¼ŒVAEï¼ŒEAN çº³å…¥åˆ°ç”Ÿæˆæ¡†æ¶

  - åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ¨¡å‹æ—¨åœ¨é€¼è¿‘æ¡ä»¶åˆ†å¸ƒ `pÎ¸(x|z, c)` ä½¿å…¶æ¥è¿‘å…ˆéªŒåˆ†å¸ƒ `p(x|c)`ã€‚ç»™å®šæ¡ä»¶ `c` å’Œä»å…ˆéªŒåˆ†å¸ƒ `pz(z)` ä¸­é‡‡æ ·å¾—åˆ°çš„æ½œåœ¨å˜é‡ `z`ï¼ˆé€šå¸¸å‡è®¾ä¸º **é«˜æ–¯åˆ†å¸ƒ**ï¼‰ï¼Œæ¨¡å‹ä¼šç”Ÿæˆä¸€äº›â€œä¸­å¿ƒç‚¹ï¼ˆhubsï¼‰â€. è¿™é‡Œçš„ `c` å’Œ `x` åˆ†åˆ«ä»£è¡¨æ¡ä»¶å›¾åƒå’Œè¾“å…¥å›¾åƒã€‚z is a latent variable from a prior distribution   

  - The main objective of hub generation is to minimize the difference between probability distributions  `p(x|c) ` and `pÎ¸(x|z, c)`

  - a noise hub, especially the outermost one, can largely harm the wirelength of routing. Use `stripe mask` to focus on bad cases for hub generation  

    ![image-20250212202848907](assets/image-20250212202848907.png)

    

- hub å’Œ pin è¿æ¥é˜¶æ®µ

  - æ¨¡å‹è¿æ¥ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ **ä¸­å¿ƒç‚¹**ï¼Œä»¥è·å¾—æœ€ç»ˆçš„å¸ƒçº¿è·¯ç”±ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¢«è§†ä¸ºæ„å»ºçŸ©å½¢ç¨³å®šæœ€å°ç”Ÿæˆæ ‘ï¼ˆRectilinear Steiner Minimum Treeï¼ŒRSMTï¼‰çš„ä¸€éƒ¨åˆ†ã€‚ä¸ºäº†å®Œæˆå¸ƒçº¿ï¼Œæ¨¡å‹éµå¾ªäº†ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼ŒRLï¼‰çš„ç®—æ³• `REST`ã€‚
  - åœ¨ä¸¤é˜¶æ®µçš„è¿‡ç¨‹ä¸­ï¼Œä½œè€…è¿˜æå‡ºäº†ä¸€ä¸ª `å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶` æ¥æé«˜ç”Ÿæˆä¸­å¿ƒç‚¹çš„è´¨é‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„ `æ¡å¸¦æ©æ¨¡å­¦ä¹ æ–¹æ³•`ï¼Œæ—¨åœ¨å‡è½»å™ªå£°ç‚¹æ¡ˆä¾‹å¯èƒ½é€ æˆçš„è´Ÿé¢å½±å“ã€‚ç®—æ³•çš„å…·ä½“ç»†èŠ‚åœ¨ `é™„å½• B ` ä¸­ç»™å‡ºã€‚





#### [Neural Steiner-AI for Steiner-NeurIPS-2024-Chinese Academy of Sciences-CNN]()

##### background

- the yielded routing paths by the existing approaches often ==suffer from considerable overflow,== thus greatly hindering their application in practice.   
- two advantgages:
  - learning scheme to ensures the connectivity  
  - can effectively scale to large nets and transfer to unseen chip designs   
- Due to the complex and irregular distribution of congestion, the construction of escape graph becomes complicated, while the ==Hanan grid is ineffective at circumventing congestion==  
- `FLUTE` is unaware of congestion  
- `CUGR-2` applies the construction of `augmented graphs` to build candidate paths for netsâ€™ RSTs, adjusting the position of certain Steiner points to circumvent potential congestion  
- ä¸»è¦æ˜¯å’Œ HubRouter åšå¯¹æ¯”
- ![image-20250324210830618](assets/image-20250324210830618.png)



##### contribution

1. `Neural Steiner` can effectively scale to ==large== nets
2. transfer to unseen chip designs without any modifications or fine-tuning without any modifications or fine-tuning  
3. achieves up to a 99.8% ==reduction in overflow== while ==speeding up== the generation  and maintaining a slight ==wirelength loss within only 1.8%==.  
4. ==the first== learning-based approach capable of optimizing both wirelength and overflow and effectively addressing the routing problem of large-scale nets  
5. Moreover, NeuralSteiner can generate overflow-avoiding routes for nets with more than 1000 pins  



##### flow

![image-20250324192220953](assets/image-20250324192220953.png)

1. Parallel Routing Tasks Construction

   - divides the numerous nets in the design into a set of mutually conflicting routing tasks.   

   - ä¹Ÿå°±æ˜¯ä¸é‡å çš„ net åˆ† batchï¼Œ ä¸€ä¸ª batch å†…çš„å¸ƒçº¿ä»»åŠ¡ç”¨ t è¡¨ç¤º
   - Nets within a task t can be batched together and fed into the neural network for `prediction` and `post-processing`,  è¿™ä¸ªç½‘ç»œæ˜¯é’ˆå¯¹ batch çš„

2. Candidate point prediction phase  

   - image segmentation task  
   - we simplify the learning target in RST construction and select Steiner points and corner points in RST as candidate points to learn  
   - ![image-20250401112743014](assets/image-20250401112743014.png)
   - due to the fixed geometric structures, CNN is inherently limited to local receptive fields that face ==difficulties in capturing long-range correlations.== Thus, we introduce the `recurrent crisscross attention mechanism (RCCA)` to aggregate features from all pixels on the feature map  

3. Overflow-  avoiding RST construction phase:  

   - net augmented graph (NAG)   

     1. first merge the predicted candidate point map and pin map  
     2. ![image-20250324201453180](assets/image-20250324201453180.png)
     3. è¯·æ³¨æ„ï¼Œåœ¨ HubRouter [8] ä¸­ï¼Œå¼•å…¥äº†æ¡å¸¦æ©ç ä½œä¸ºä¸€ç§æ»¤æ³¢å™¨ï¼Œç”¨äºå»é™¤å™ªå£°ä¸­å¿ƒç‚¹ï¼Œä»¥é™åˆ¶ç±»ä¼¼äºå“ˆå—ç½‘æ ¼çš„è§£ç©ºé—´ï¼Œä»è€Œç¡®ä¿çº¿é•¿åº¦å°½å¯èƒ½çŸ­ã€‚ç„¶è€Œï¼Œå¦‚å›¾ 1e æ‰€ç¤ºï¼Œåœ¨ HubRouter ä¸­æ·»åŠ æ¡å¸¦æ©ç é™åˆ¶äº†å…¶ç”Ÿæˆé¿å¼€æ‹¥å¡åŒºåŸŸçš„ RST çš„èƒ½åŠ›ã€‚ç›¸åï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œ ==ä¿ç•™äº†æ¨¡å‹é¢„æµ‹çš„æ‰€æœ‰å€™é€‰ç‚¹==ï¼Œå¹¶åŸºäºå®ƒä»¬æ„å»ºäº† `NAG`

   - RST construction

     ![image-20250324203801098](assets/image-20250324203801098.png)

   - Since this method ==may generate additional detours==, we use a ==simple== algorithm to detect potential feasible path reuse to shorten the wirelength.  

##### data

- use `CUGR` to perform routing on public benchmarks: `ISPD'07 contest`   

- adopt the `logistic function` in CUGR to calculate the overflow value using resource r(u, v)  

  ![image-20250324194434306](assets/image-20250324194434306.png)

- mark the Steiner points and corner points in the RSTs constructed by CUGR as candidate points and generate the label candidate point map for every net.   

- we maintain `three` maps of every net at the original scale of its bounding box. This preserves the precise spatial and overflow information and does not exclude any large-scale nets.  three map æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ

- we limit the netsâ€™ Half-perimeter wirelength (HPWL) in the training set to ==HPW L â‰¤ 128==  



##### experiment

1. Loss:

   ![image-20250324200141321](assets/image-20250324200141321.png)

   ![image-20250324200724626](assets/image-20250324200724626.png)

   ![image-20250324200716473](assets/image-20250324200716473.png)

   ![image-20250324200818753](assets/image-20250324200818753.png)

2. ![image-20250324205051612](assets/image-20250324205051612.png)

3. ![image-20250324205105330](assets/image-20250324205105330.png)

4. ![image-20250324205218340](assets/image-20250324205218340.png)

5. ![image-20250324205435186](assets/image-20250324205435186.png)

6. ![image-20250324205522516](assets/image-20250324205522516.png)

7. ![image-20250324205627094](assets/image-20250324205627094.png)

8. ![image-20250324205634710](assets/image-20250324205634710.png)



### GR_Adv_Sequential

- GPU-accelerate
- these approaches rely on â€œparallelizing " traditional sequential algorithms in GPUs. 
- the quality of the routing result is ==still limited== by the traditional sequential-based algorithms  





#### [han-GPU+netlevel parallelism-ICCAD-2011- -]()



#### [A global router on GPU architecture- -ICCAD-2013- -]()



#### [VFGR-Fat via congestion modeling-ASP DAC-2014--THU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=6742945)

- net-level and region-level parallelization  
- æœ‰ç‚¹åå·¥ä¸š





#### [SPRoute 2.0- detailed routability driven-ASP DAC-2022-](https://ieeexplore.ieee.org/abstract/document/9712557)

- [OpenSource!](https://github.com/asyncvlsi/SPRoute/tree/master)
- 2D
- å¯ä»¥å°† guide æ–‡ä»¶è¾“å…¥åˆ° innovus?
- `soft capacity`   The soft capacity is downsized from the hard capacity (number of available tracks), using the pin density and RUDY value of the region.   
- `batch` for ==deterministic== net-level parallelization strategy  
- `bulk-synchronously` maze-routes  
- baseline FLUTE, [FastRoute 4.0](# [fastroute 4.0-via min tree+3 bending-ASPDAC-2009-]()) for pattern routing, [CUGR](# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr))



##### background

- In terms of parallelization, maze routing is widely used in global routing and ==is the most time-consuming stage== on hardto-route benchmarks.   



##### contribution

- `soft capacity` to reserve space for detailed routability. 
- parallelize maze routing in a `deterministic bulk synchronous approach`
- design a `scheduler` for the deterministic parallel  execution model  



##### flow

![image-20250225114628773](assets/image-20250225114628773.png)



##### model

###### soft capacity

![image-20250225120300741](assets/image-20250225120300741.png)

![image-20250225120328607](assets/image-20250225120328607.png)

![image-20250225120309420](assets/image-20250225120309420.png)

Different layers have different parameters for the ratio function since they are influenced by the congestion in different scales  



###### bulk synchronous deterministic approach

å°±æ˜¯åˆ† batchï¼Œall threads execute one batch of nets at a time  

åœ¨æ‰¹å¤„ç†å¼€å§‹æ—¶ï¼Œæ¯ä¸ªçº¿ç¨‹ä»æ‰¹å¤„ç†ä¸­è·å–ä¸€ä¸ªç½‘ç»œï¼Œè¯»å–å…¨å±€å›¾çš„ä½¿ç”¨æƒ…å†µï¼Œå¹¶åœ¨å…¶çº¿ç¨‹å±€éƒ¨å›¾ä¸­æ‰§è¡Œæ’•è£‚å’Œé‡æ–°è·¯ç”±ã€‚

![image-20250225163426630](assets/image-20250225163426630.png)

è¿˜æ˜¯çœ‹ä¸å¤ªæ‡‚



##### data

ICCAD19 contest



##### experiment





#### [FastGR-GPU pattern routing+ multi thread mazeâ€“DATE-2022-PKU+CUHK+HNAL](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9774606)

- GPU-accelerated
- accelerated the 3D pattern routing algorithm of [CUGR](# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)) for initial routing by both `net-level` and `path-level` parallelization on GPU



##### background

- The literature has extensively explored shortest path searching with GPU [11], [12]. However, most studies only consider the most basic single-source shortest path problem and assume only to find one path on a large graph. This is impractical for routing since we need to route millions of nets subjecting to various objectives and constraints like wirelength, number of vias, and design rules  

- ![image-20250403191259460](assets/image-20250403191259460.png)

  Fig. 1 shows that it is PATTERN dominated on average since the number of nets which pattern routing stage needs to process is much more than the maze routing stage  




##### contribution

- a novel GPU-accelerated `pattern routing algorithm`
- a high-performance task `graph scheduler` to distribute CPU and GPU tasks for workload balancing and efficiency



##### flow

![image-20250403193046048](assets/image-20250403193046048.png)



##### model

1. task graph scheduler==(æ²¡çœ‹æ‡‚ï¼ï¼ï¼ï¼ï¼ï¼ï¼)==

   - æ˜¯ç”¨æ¥æŒ‡å¯¼è¿·å®«å¸ƒçº¿å¹¶è¡Œçš„ï¼Œç”¨äº†`taskflow`

   - two-stage task graph scheduler:
     1. construct the task graph from the conflicted relationship between each pair of tasks  
     2. determine the execution order for each conflict edge 

2. Pattern routing stage: Task graph generation  

3. GPU friendly pattern routing

   ![image-20250403200448178](assets/image-20250403200448178.png)

   - we apply each block to process one single multi-pin net  
   - ![image-20250403200934314](assets/image-20250403200934314.png)

##### data

ICCAD2019 benchmarks  

##### experiment

1. RTX 2080 GPU.  

2. we choose six different strategies only applied to the rip-up and reroute iterations to show the effect of net ordering  

3. ![image-20250403204637280](assets/image-20250403204637280.png)

4. ä¸åŒnet order çš„å®éªŒç»“æœï¼š

   ![image-20250403204815611](assets/image-20250403204815611.png)

5. ![image-20250403204747224](assets/image-20250403204747224.png)



#### [Gamer- -ICCAD/Trans-2021/2023- -CUHK-]()

- GPU-accelerated

- accelerated the two-level maze routing of [CUGR](# [CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK](https://github.com/cuhk-eda/cu-gr)) for rip-up and reroute by updating vertical and horizontal routing costs alternatively on GPU  

- to accelerate the `multisourceâ€“multidestination shortest path problem` for VLSI routing  

  !!! note
      ä»€ä¹ˆæ˜¯å¤šæºå¤šæ±‡æœ€çŸ­è·¯å¾„é—®é¢˜ï¼Ÿ
      
      ![image-20250403210333648](assets/image-20250403210333648.png)

- integrating `GAMER` into the state-of-the-art academic global router `CUGR` 


##### background

- Maze routing is usually the most time-consuming step in `global routing` and `detailed routing`
- Many of them adopt the `negotiation-based rip-up and reroute` method introduced in [3]. Hard-to-route nets are ripped-up and rerouted many times with incrementally changing history cost until getting a feasible solution.   
- One way to do this is to separate nets by their bounding boxes and create a task pool. Each thread will search for a net in the `task pool` whose bounding box does not overlap with any other nets being routed at the moment and perform maze routing [6]. However, if the bounding boxes are too big, the level of parallelism for this method is low  
- The approach described in `[7]` attempts to solve this problem by allowing nets with overlapping bounding boxes to be routed together, and fix any possible overflows afterward by rerouting  (è¿™ç¯‡ä¹Ÿè®¸å¯ä»¥çœ‹çœ‹)
- `SPRoute [8]` does not forbid routing in the same region if and only if the region has abundant routing resources.   
- `NCTU-GR 2.0 [9]` also allows nets with overlapping bounding boxes to be routed simultaneously, but they adopt a more sophisticated technique to avoid the racing situation  
- However, some extra efforts are needed to resolve `data racing`, which may lead to `unbalanced workloads` and routing performance degradation. Besides, as technology evolves over time, graphics processing units (==GPUs==) are standing out, and can provide better solution to parallelism. There are relatively fewer attempts to load maze routing onto GPUs.  





##### contribution

1. decomposes the shortest path search into `alternating vertical and horizontal sweep operations`,  
2. two parallel algorithms are proposed to accelerate a sweep operation ==from O(n2) to O(log2 n)== on a grid graph of n Ã— n.   





##### flow



##### model

1. SWEEP Operation

   ![image-20250403215236451](assets/image-20250403215236451.png)

2. Parallelization With Conditional Partial Sum  

   !!! note
       divide-and-conquer method:
       
       ![image-20250403215647910](assets/image-20250403215647910.png)



#### GGR-pattern and maze gpu accelerated-ICCAD-2022

- [Open source!](https://github.com/cuhk-eda/Xplace/tree/main/cpp_to_py/gpugr)

- ç¬¬ä¸€ä¸ªpattern routingå’Œmaze routingéƒ½æ˜¯GPU-accelerateçš„
- The solution space of pattern routing is intentionally ==restricted== to shorten running time by only allowing certain routing topologies such as ==L-shape, Z-shape and 3-bend routing==
- ç”¨çš„`FLUTE`



##### background

- Routability-driven placement relies on global routing for accurate routability estimation,  and faster global routing can significantly improve both the running time and the quality of routability-driven placement.   ä»–æŠŠåº”ç”¨åœºæ™¯æ˜ç¡®äº†ï¼Œæ˜¯ç»™placementç”¨çš„ã€‚å¼€æºå·¥ç¨‹ä¸­ä¹Ÿæ˜¯è¿™ä¹ˆæ”¾çš„ï¼Œæ”¾åˆ°`Xpalce`ä¸­
- Compared to multi-threading with CPU, GPU has more cores and is potentially a good platform for fast global routing.  
- ![image-20241114231041875](./assets/image-20241114231041875.png)
- The computations of the ==DP== framework can be performed very efficiently, but the ==most time-consuming part== comes from computing the minimum costs connecting two points using 3D L/Z-shape routing





##### contribution

![image-20250401105951278](assets/image-20250401105951278.png)





##### flow

![image-20241114230008749](./assets/image-20241114230008749.png)





##### model

- An efficient way to calculate the total cost of a long wire segment is to use `prefix sum`.
- Parallel L-Shape Routing  
  - ![image-20250401123216904](assets/image-20250401123216904.png)
  - Our L-shape routing for a single 2-pin connection can be divided into ==5 steps== as shown by the 5 arrows in Fig. 3  
  - Every step can be done sequentially in ==ğ‘‚(ğ¿) time==  





##### data



##### experiment

- a The global routing quality is evaluated using an academic detailed router Dr. CU[8]  



#### [CUGR 2.0-DAG-based-DAC-2023- -CUHK](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10247702)

- [open source! ](https://github.com/cuhk-eda/cu-gr-2)

##### background

- many of the aforementioned global routers is that most of them rely heavily on **time-consuming path search algorithms** like maze routing to resolve overflows. These approaches are not efficient enough even with parallilization and may cause lots of unnecessary detours  



##### contribution

- a ==DAG-based== generalized pattern routing algorithm
- a new ==dynamic programming-based== algorithm to calculate the routing cost time complexity from $\mathcal{O}(L^4|V|)$ to $\mathcal{O}(L^2|V|)$
- a DAG ==augmentation algorithm== that enables the creation of alternative paths in a routing DAG.   can even shift or create Steiner points. over 99% nets can be successfully routed ==without the need of maze routing==
- a new sparse graph ==maze routing algorithm== creation of alternative paths in a  routing DAG





##### flow

1. RSMT 

   ![image-20250210142956411](assets/image-20250210142956411.png)

2. DFS and ` Routing DAG` with L pattern

   æ³¨æ„å¤šäº†èŠ‚ç‚¹ g, f, i, h, ç°åœ¨æ¯æ¡éƒ½æ˜¯ç›´çº¿

   ![image-20250210143037337](assets/image-20250210143037337.png)

   `Routing DAG` with other patternsï¼Œä½†æ˜¯åœ¨è¿™é‡Œæ²¡ç”¨åšåˆå§‹å¸ƒçº¿ï¼Œåˆå§‹åªç”¨äº† L-shapeã€‚æ–‡ç« ä¹Ÿå°±è¿™é‡Œæäº†ä¸€ä¸‹ï¼Œåé¢éƒ½å’Œè¿™ä¸ªæ— å…³ï¼Œå¾—å»æºç ä»”ç»†çœ‹çœ‹ã€‚

   ![image-20250210143529434](assets/image-20250210143529434.png)

3. Dynamic Programming-based DAG routing(L-shape + Layer assignment)

   æ²¡è¯´æ€ä¹ˆèˆå¼ƒçš„ï¼Ÿ

4. DAG-based pattern routing with **augmentation**  

5. sparse graph **maze** routing algorithm





##### model

- cost 

  - Dynamic Programming-based  

    ![image-20250210203428984](assets/image-20250210203428984.png)

  - DAG Augmentation for Congestion  

    ![image-20250210203818643](assets/image-20250210203818643.png)

    1. create alternative paths   

       ![image-20250210204123847](assets/image-20250210204123847.png)

    2. Steiner point movement

       å…·ä½“æ€ä¹ˆç§»åŠ¨çš„æ–‡ç« ä¹Ÿæ²¡è¯´



##### experiment

- compare with CUGR [12] and SPRoute 2.0 [13]  

  ![image-20250210211951988](assets/image-20250210211951988.png)

  ![image-20250210212311337](assets/image-20250210212311337.png)

  

  only one thread  for run time

- ![image-20250210212636193](assets/image-20250210212636193.png)

- Effectiveness of  steiner point augmentation  

- ![image-20250210212920933](assets/image-20250210212920933.png)

- run time compare with GPU-accelerated GR

  - compare with FastGR [14] and GAMER [15]  

  - GPU çš„å¥½åä¹Ÿæœ‰å…³ç³»å§ã€‚æœ¬å®éªŒç”¨çš„ RTX 3090  

  - slightly faster than FastGR for initial routing 

    ![image-20250210213728850](assets/image-20250210213728850.png)

  - around 5.2Ã— as fast as GAMER

    ![image-20250210215926150](assets/image-20250210215926150.png)





#### [InstantGR-Scalable GPU Parallelization-ICCAD-2024-CUHK](https://shijulin.github.io/files/1239_Final_Manuscript.pdf)

- [open source! ](https://github.com/cuhk-eda/InstantGR)
- second place of ISPD25 contest
- GPU Parallelization  
- parallel algorithm is mainly based on the DAG-based global routing algorithm in [CUGR2](# [CUGR2.0 EDGE- -DAC-2023-](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10247702)).  åº”è¯¥æ˜¯ 3D pattern routing DP çš„éƒ¨åˆ†å’Œ maze routing çš„éƒ¨åˆ†
- parallel while do initial routing  and RRR
- æé«˜äº†å¹¶è¡Œåº¦ï¼Œä½†æ˜¯è¿˜æ˜¯æœ‰ä¸²è¡Œçš„éƒ¨åˆ†
- ä¹Ÿç”¨äº† FLUTE
- ä¸€å®šè¦ä»¥ net ä¸ºå•å…ƒå—ï¼Ÿæ˜¯ä¸ºäº†ç”¨ DP





##### background

-  GPU memory is limited  
   - This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization  
   - large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored  
-  nets in a batch can be routed in parallel



##### task

- parallelism for large-scale
- partitioned  design





##### contribution

- a new method for `net-level batch generation`. based on 3D fine-grained overlap checking and explores more parallelism by increasing the number of nets per batch
- `node-level` parallel routing approach. achieves much higher parallelism compared to traditional net-level parallel routing.





##### flow

- In initial routing, we construct a basic `routing DAG` to perform **L-shape pattern routing**.  



**key points**

specific explanation show in [routing2](../routing/routing2.md)

- NET-LEVEL PARALLELISM  

  - simultaneous routing of a `batch` of nets that do not â€œ`overlap`â€  

  - [2, 3, 14, 19, 20, 22, 26]  19 å¹´å¼€å§‹çš„ï¼Œcugr2 å’Œ fastgr éƒ½ç”¨äº†

  - **Typical** Batch Generation Algorithm  

    used in [2, 3, 14, 19, 20]  

    ![image-20250212100127751](assets/image-20250212100127751.png)

    `R-trees ` æ˜¯å®ç° `line 4` çš„å¸¸ç”¨åšæ³•

    `pessimistically approximates`  significantly lowers the degree of parallelism  

  - define and graph model

    ![image-20250212111440550](assets/image-20250212111440550.png)

    ![image-20250212100930831](assets/image-20250212100930831.png)

    ä»¥ `segment` ä¸ºå•ä½ï¼ŒåŒæ—¶åˆ†å¼€äº†æ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå‡è®¾å…¨éƒ¨ä¸º L-shapeï¼ŒåŒæ—¶å¯¹äºä¸åœ¨ä¸€æ¡çº¿ä¸Šçš„ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œæœ‰ä¸¤ä¸ª L

    These four nets will be divided into just `one batch` based on our exact representation of routing graphs for overlap checking, while into `four batches` by the traditional bounding box-based pessimistic approximation  

    via model:

    ![image-20250212110626674](assets/image-20250212110626674.png)

    

    ![image-20250212104214378](assets/image-20250212104214378.png)

    via ç”¨ä¸€ä¸ªåå­—è¡¨ç¤º

  - Overlap Checking Algorithms  

    1. ä»¥æ°´å¹³å­å›¾è¿›è¡Œå±•ç¤ºï¼Œå‚ç›´åŒç†

    2. ä»¥æ°´å¹³ segment ä¸ºå•ä½è¿›è¡Œ checking

    3. é¦–å…ˆåˆ¤æ–­æ˜¯ä¸æ˜¯ y åæ ‡ç›¸ç­‰ï¼šgroup the segments with the same ğ‘¦  

    4. tradictional algorithm:

       This is a classical computational geometry problem that can be efficiently solved by `segment trees` [1] in ğ‘‚(logğ‘›) time for both operations,   

       ![image-20250212114550426](assets/image-20250212114550426.png)

    5. new algorithm motivation:

       ![image-20250212114611742](assets/image-20250212114611742.png)

       segments are very short

    6. new algorithm: `Point Exhaustion`

       simply use a Boolean array to record whether each point in [1, ğ‘›] is covered by some segment ğ‘  âˆˆ ğ‘†. We mark every point ğ‘¥ âˆˆ [ğ‘™, ğ‘Ÿ] when a segment [ğ‘™, ğ‘Ÿ] is inserted, and check every point ğ‘¥ âˆˆ [ğ‘™ğ‘, ğ‘Ÿğ‘] for overlap query of a segment [ğ‘™ğ‘, ğ‘Ÿğ‘].   

       further improve the efficiency of this point exhaustion by using bit arrays  

    7. another improvement: `representative point exhaustion  `

       - allowing a little bit of overlap.   
       - it only checks the two end points of a query segment. ??ä»€ä¹ˆæ„æ€  
       - covering most overlap scenarios in practice.   
       - The only scenario that this algorithm fails to find the overlap of two overlapping segments is when the query segment [ğ‘™ğ‘, ğ‘Ÿğ‘] contains the overlapping segment [ğ‘™, ğ‘Ÿ], [ğ‘™, ğ‘Ÿ] âŠ‚ [ğ‘™ğ‘, ğ‘Ÿğ‘]  

       

- NODE-LEVEL PARALLELISM

  ![image-20250212142040816](assets/image-20250212142040816.png)

  - è¿˜æ˜¯ä»¥ net ä¸ºå•ä½åˆ†åˆ°ä¸åŒçš„ batchï¼Ÿ

  - routing nodes of the same depth in parallel  

    ![image-20250212143816082](assets/image-20250212143816082.png)

    Suppose we have 4 nets, Net A, B, C and D in our grid graph. Since nets with overlap cannot be routed together, Net A and B are distributed to batch 0, as shown in Figure 7a, and nets C and D are distributed to batch 1.  

    ![image-20250212143140834](assets/image-20250212143140834.png)

##### experiment

- 4 NVIDIA A800 GPUs and 8 CPU threads.

-   compare different overlap checking methods  

    ![image-20250212145328644](assets/image-20250212145328644.png)

    The number of nets per batch is limited to 1000  

- compare 2 largest benchmark

  ![image-20250212154458440](assets/image-20250212154458440.png)

- compare with Top-3 Global Routers of ISPD2024 Contest   

  ![image-20250212161238221](assets/image-20250212161238221.png)

- Runtime (s) of DAG-Based Augmented Routing with and without Node-Level Parallelism  

  ![image-20250212161314333](assets/image-20250212161314333.png)

  acceleration é‚£ä¸€è¡Œå¥½åƒæ˜¯åŠ é€Ÿå€ç‡æ‰å¯¹




#### [HeLEM-GR-Heterogeneous+Linearized Exponential Multiplier Method-ICCAD-2024- -PEK]()

- first place of ISPD25 contest
- not open source 2025/2/6
- 2D routing algorithm  



background



##### contribution:

- `LEM`(linearized exponential multiplier) method for ==2D routing problem== to minimize wirelength and overflow. This LEM framework is ==general to integrate any routing kernels.==  
- `batched routing kernels`  including ==L shape and 3-bend routing== for GPU parallelization.  
- `sweep operations`  for GPU-accelerated layer assignment.



##### flow

![image-20250225103529314](assets/image-20250225103529314.png)

- preparation  
  - run on CPU
  - use FLUTE
  - use ` SPRoute 2.0`  to compact 3D graph to 2D graph  
- 2D routing  
  - run on GPU
- layer assignment
  - run on GPU



### RSMT

#### [Hannan grid- - -1966- -]()

- has proven that an optimal RSMT can always be constructed on the Hanan grid  



#### [GeoSteiner- - -1998- -]()

- [GeoSteiner Homepage](http://geosteiner.com/), ä¸€ç›´æœ‰æ›´æ–°ï¼Œ5.xç‰ˆæœ¬è²Œä¼¼æ¯”FLUTEæ›´å¥½äº†ã€‚97å¹´æåˆ°ç°åœ¨ï¼ˆ2025ï¼‰ã€‚4.0ç‰ˆæœ¬æ˜¯å•†ç”¨çš„ã€‚

- an efficient optimal algorithm that ==enumerates== all possible full Steiner tree to form an RSMT
- It is proven that an optimal RSMT can always be found by combining full Steiner trees only, which are Steiner trees with a special structure.   
- The running time of GeoSteiner inevitably goes to exponential



#### [-Multilayer Obstacle Avoiding+Spanning Graphs-Trans-2008- -](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=6930811)




#### [FLUTE- - -2008- -]()

- [OpenSource!](https://home.engineering.iastate.edu/~cnchu/flute.html)
- The runtime complexity of FLUTE with fixed accuracy is O(n log n) for a net of degree n  
- FLUTE is an RSMT construction algorithm adopting a look-up table approach, which is both fast and optimal for low-degree nets. However, FLUTE is unaware of routing **congestion**.  

![image-20241116114652698](./assets/image-20241116114652698.png)

ä¸‹é¢æ˜¯ä¸€ç³»åˆ— FLUTE å’ŒåŸºäº FLUTE çš„æ”¹è¿›

![image-20241116114634422](./assets/image-20241116114634422.png)

##### background

- RSMT problem is NP-complete [1].  
- Most signal nets in VLSI circuits have a low degree. Therefore, in VLSI applications, rather than having a low runtime complexity, it is more important for RSMT algorithms to be simple so that they can be efficient for small nets.   
- Hanan [16] pointed out that an optimal RSMT can always be constructed based on the Hanan grid.  
- åŸºæœ¬å®šä¹‰

  ![image-20250227114157112](assets/image-20250227114157112.png)

  x, y, s, h, v

  `position sequence`: s1, s2, s3, s4 = 3142

  ![image-20250227111722382](assets/image-20250227111722382.png)

  ![image-20250227111733809](assets/image-20250227111733809.png)

  wirelength vectors are: (1, 2, 1, 1, 1, 2), (1, 1, 1, 1, 2, 3), and (1, 2, 1, 1, 1, 1)  
- POWV and POST for net(degree < 9)

  - For each group, the optimal wirelength of any net can be found based on a few vectors called potentially optimal ==wirelength vectors== ==(POWVs)==.  
  - We also store one corresponding Steiner tree, which we called potentially optimal ==Steiner tree== ==(POST)== associated with each POWV. 



##### contribution

- We show that the set of all ==degree-n nets can be partitioned into n! groups== according to the relative positions  of their pins.   



##### model

1. \##### åˆ¶è¡¨æšä¸¾åŒ–ç®€ï¼š

- Note that, although the number of the possible Steiner trees is huge, the number of the possible wirelength vectors is much less. And we notice that not all the wirelength vectors have the potential to produce the optimal wirelength
- Most vectors are redundant because they have a larger or equal value than that of another vector in all coefficients.  For example, we can ignore the wirelength vector (1, 2, 1, 1, 1, 2) because the wirelength produced by the vector (1, 2, 1, 1, 1, 1) is always v3 less.  
- We called a vector that can potentially produce the optimal wirelength (i.e., cannot be ignored) a ==POWV==  
- for every low-degree net, there are only a few POWVs. For example, for all degree-3 nets, the only optimal wirelength vector is (1, 1, 1, 1), which corresponds to the half-perimeter wirelength (HPWL).   

###### group the nets which can share the same set of POWVs

- å¦‚æœæ¯ä¸€ç§ POST å¯¹åº”ä¸€äº› POSTsï¼Œä¼šæœ‰å¤ªå¤šç§å¯èƒ½ï¼Œæµªè´¹ç©ºé—´

- å®šä¹‰ï¼štopologically equivalent

  ![image-20250227113943777](assets/image-20250227113943777.png)

  have the same `position sequence`

- Theorem 1: the set of all degree-n nets can be divided into ==n!== groups according to the position sequence such that all nets in each ==group== share the same set of POWVs. (9!= 362,880)

  

2. \##### LUT generateion

- å¦‚æœä½¿ç”¨éå†çš„æ–¹æ³•ï¼Œæ…¢ã€‚Even for degree 5, we need to enumerate a Hanan grid consisting of 40 edgesï¼ˆ$4 \times 5 \times 2$ï¼‰ for each of the 120 groups(5!)

- `boundary-compaction technique` for efficient:

  By compacting the four boundaries in a different order, a set of different Steiner trees with different wirelength vectors can be generated

  - ![image-20250227120546770](assets/image-20250227120546770.png)

  - è¾¹ç•Œå‹ç¼©æŠ€æœ¯é€šè¿‡å‹ç¼©å››ä¸ªè¾¹ç•Œä¸­çš„ä¸€ä¸ªæ¥å‡å°ç½‘æ ¼å¤§å°ï¼Œå³ï¼Œå°†è¾¹ç•Œä¸Šçš„æ‰€æœ‰å¼•è„šç§»åˆ°ä¸è¯¥è¾¹ç•Œç›¸é‚»çš„ç½‘æ ¼çº¿ä¸Šã€‚

    ![image-20250227121330548](assets/image-20250227121330548.png)
  
  - ![image-20250311104321293](assets/image-20250311104321293.png)
  
  - è¿˜æ˜¯æ²¡çœ‹æ‡‚ 0.0
  
  - ç»“æœï¼šnumber of POWVS in a Group:
  
    ![image-20250311103853312](assets/image-20250311103853312.png)

3. REDUCTION OF LOOKUP TABLE SIZE  

   - The POST associated with each POWV should have up to seven Steiner nodes and 9 + 7 - 1 = 15 branches. If 1 byte is used to store each branch in a POST, the POST storage requirement for degree 9 will be 155.9 MB  

   - ![image-20250311105345845](assets/image-20250311105345845.png)

   - ![image-20250311105433321](assets/image-20250311105433321.png)

   - Groups are equivalent for two reasons  

     - First:

       ![image-20250311110049688](assets/image-20250311110049688.png) Therefore, up to 2^4^ = 16 different groups can share a set of POWVs and POSTs  (the number of equivalent groups may be less than 16 because pins can be shared by adjacent boundaries, and therefore, not all combinations exist).   

     - Second, if two nets are symmetrical horizontally, vertically, or diagonally, the POWVs and POSTs of one group can be transformed to those of the other.   

   - The total table size is only 9.00 MB in the end  

4. SPEEDUP OF MINIMUM-WIRELENGTH COMPUTATION  

   - Since entries in POWVs are typically small integers and addition is computationally much less expensive than multiplication, it is more efficient to add the edge length several times instead of using multiplication (åŠ æ³•æ¯”ä¹˜æ³•å¥½)
   - Many of them differ from others in only one or two entries. Hence, some POWVs can be efficiently evaluated by adding or subtracting some terms from some other previously computed POWVs.   

5. NET BREAKING  

   - Nets with a degree ==higher than D (D ä¸€èˆ¬ç­‰äº 9)== are broken into several subnets with a degree ranging from 2 to D to which the table lookup estimation can be applied  
   - ==four heuristics== are applied to collectively determine a score for each way of breaking.   
   - In this technique, a scheme is also introduced to allow users to control the ==tradeoff between accuracy and runtime==  
   - ![image-20250311112531953](assets/image-20250311112531953.png)
   - ![image-20250311112540051](assets/image-20250311112540051.png)
   - ![image-20250311112848743](assets/image-20250311112848743.png)
   - ![image-20250311121152650](assets/image-20250311121152650.png)



##### data

![image-20250311120818694](assets/image-20250311120818694.png)



##### experiment

1. æ¨¡å‹å¯¹æ¯” 

   GeoSteiner ä½œä¸ºæ ‡å‡†

   ![image-20250311120900286](assets/image-20250311120900286.png)

2. ä¸åŒåº¦çš„å›¾å¯¹æ¯”

   ![image-20250311120937527](assets/image-20250311120937527.png)

3. runtime

   ![image-20250311121011023](assets/image-20250311121011023.png)

   The runtime is increasing at a rate much slower than A(log A+1)/2 because most nets have a low degree  

   because the redundant edge removal and the local refinement techniques described at the end of Section VI-B cannot be used, the error is increased.  

4. æ›´å¤§çš„ degree

   ![image-20250311121624728](assets/image-20250311121624728.png)



#### [-obstacle avoiding+parallel -ICCAD-09- -CUHK-](https://www.cse.cuhk.edu.hk/~fyyoung/paper/iccad09_geosteiner.pdf)





#### [-Obstacle avoiding-Science Direct-2013- -CUHK](https://www.sciencedirect.com/science/article/pii/S0167926013000424)





#### [REST-attention mechanism-ICCAD-2021-RL(AC)-CUHK](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=9586209)

- [OpenSource!](https://github.com/cuhk-eda/REST)
- [github ä¸Šæœ‰ä¸ªç›¸å…³çš„å¤ç°](https://github.com/fugjgjguhih/Solving-VLSI-DRL/tree/40b6c6324927a8ef875558ab6d229a3545a451e6)
- the first successful attempt to solve this problem using a machine learning approach  



##### background

- machine learning based approaches have shown several advantages over the traditional heuristics, e.g., shorter time for development, superior quality and speed for small to middle size instances.  
- previous ML-based combinatorial problem (TSP) work: RNN-based pointer network [6] --> RL-based work [8] --> multi-hand atttention+[8] work [9]



##### model

###### Rectilinear Edge Sequence (RES)

- designed for bridge the gap between machine learning output and RSMT structure.  

- ![image-20250227170745540](assets/image-20250227170745540.png)

- res = ((2; 1); (2; 4); (3; 4))  ,(vi, hi)åˆ†åˆ«è¡¨ç¤ºåœ¨ç‚¹ vi ä¸Šåšå‚çº¿ï¼Œåœ¨ hi ä¸Šåšæ°´å¹³çº¿

- overlapping edges indicated by an RES are merged automatically, with Steiner points created

- åŸæ–‡è¯æ˜äº† res ä¸€å®šå¯ä»¥æ‰¾åˆ°æœ€ä¼˜çš„ RSMT

- **Good Properties of RES**  

  - Fixed Length Sequence: Determining the number of pairs to output is non-trivial for a neural network model. Fortunately, this will not be a problem with RES, since the length of the RES for any set of n points is always n - 1  

  - The evaluation process is often the bottleneck of reinforcement learning, as it usually requires lots of computations or even simulations. The RES can be evaluated in linear time by finding the length of the horizontal and vertical segments over each point.   

    ![image-20250227173421461](assets/image-20250227173421461.png)

    ![image-20250227174218023](assets/image-20250227174218023.png)



###### AC model

![image-20250227174340598](assets/image-20250227174340598.png)

- è¾“å…¥æ˜¯ n ä¸ªèŠ‚ç‚¹çš„(x, y)åæ ‡

##### experiment

![image-20250324185340529](assets/image-20250324185340529.png)

- å¥½åƒæ²¡ä»€ä¹ˆæå‡





#### [-GPU-Accelerated-ICCAD-2022--PEK](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10069158)

- first GPU-accelerated RSMT generation algorithm  



##### background

- Rectilinear Steiner minimum tree (RSMT) generation is a fundamental component in the VLSI design automation flow. Due to its extensive usage in circuit design iterations at early design stages like ==synthesis, placement, and routing==, the performance of RSMT generation is critical for a reasonable design turnaround time.   

- previous work are CPU-based

- åœ¨ GPU ä¸ŠåŠ é€Ÿ RSMT ç”Ÿæˆæ˜¯ä¸€é¡¹é‡è¦ä½†æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦åŸå› åœ¨äºå…¶å¤æ‚çš„ã€éå¹³å‡¡(non-trivial)çš„åˆ†æ²»(divide-and-conquer)è®¡ç®—æ¨¡å¼ä¸é€’å½’æ“ä½œã€‚

- NP-completeness of RSMT generation --cite--> [1]

- the current most efficient and widely-adopted heuristic is FLUTE [9], 

- Although most of the nets in a typical circuit design have only a small degree (â‰¤ 9), larger nets are exponentially harder to solve

  ![image-20250225234107526](assets/image-20250225234107526.png)

- RSMT algorithms, such as FLUTE, are based on a ==divide-and-conquer== strategy with deep recursions, which are impossible to be executed on GPU threads with very limited stack memory

- The sizes of nets in a circuit netlist are ==highly uneven==, from 2-pin nets to nets with 40 pins or more, which leads to an extremely ==imbalanced workload== and harms the parallelism.   

- åŸºäºæ±‰å—ç½‘æ ¼ï¼š

  ![image-20250226223050705](assets/image-20250226223050705.png)

  - æ¯ä¸ªç‚¹ä¸‰ä¸ªç‰¹å¾ï¼š(x, y)åæ ‡(sort according to y coordinate)ï¼Œæ’åº s(sort according to x coordinate)

- R-MST does not insert any Steiner points and can be efficiently constructed in ğ‘‚ (ğ‘› logğ‘›) time for a net with ğ‘› pins [4], but at the cost of up to 50% worse result than RSMT [5]  

- ![image-20250226234011393](assets/image-20250226234011393.png)







##### contribution

- propose a `levelized task decomposition strategy`
  - ensures a balanced workload and enables high-performance data parallelism  
- a algorithmic transforms  
  - eliminate the recursion patterns of FLUTE  
- GPU-efficient kernels   





##### flow

![image-20250226234755100](assets/image-20250226234755100.png)

- break and merge stages work in an `iterative` way rather than the `recursive` mode in FLUTE  
- There is no extensive data copy between CPU and GPU during the inner algorithm loops which ensures minimal overhead of CPU-GPU communication  


#### [-Obstacle avoiding-ISCAS-2024--SYSU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10558430)



#### [A_Simple_Fast_and_GPU-friendly_Steiner-Tree_Heuristic](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=9835675)





#### [NN Steiner-Mixed Neural-AAAI-2024-California-]()

- [OpenSource!](https://github.com/ABKGroup/NN-Steiner)
- we develop NN-Steiner1, a mixed neural-algorithmic framework that leverages the ideas behind Aroraâ€™s PTAS for RSMT (Arora 1998). The costly `DP step` is replaced by a single NN component that outputs a learned embedding of the solutions to the DP subproblems.   
- solving ==large-scale== RSMT problemsã€‚è¿™ç¯‡åŸç†çœ‹å¾ˆéš¾çœ‹ï¼Œä¹Ÿæ¯”è¾ƒåRSMTç®—æ³•åœ¨å¤šPointä¸Šçš„å®ç°ï¼Œåœ¨GRä¸Šçš„åº”ç”¨åœºæ™¯æ„Ÿè§‰å€’æ˜¯ä¸å¤§





##### background

- there has been a surge in use of NNs to help tackle `combinatorial optimization  problems`  

- `REST (Liu, Chen, and Young 2021)` achieved the first NN-based approach for RSMT by finding so-called rectilinear edge sequences using `RL`.  (Chen et al. 2022) designed an RL framework to find obstacleavoiding Steiner minimum trees.   Significant challenges in ==neural combinatorial optimization== (NCO) remain. NNs are often used in an `ad-hoc manner` with limited theoretical understanding of the resulting framework. It is also often not known if machine-learning pipelines have the capacity to solve a given combinatorial optimization problem, or how network-architecture design could leverage problem structure to design more effective and efficient neural models.  

  !!! note
      åœ¨ç¥ç»ç½‘ç»œå’Œæœºå™¨å­¦ä¹ é¢†åŸŸï¼Œ**"ad-hoc manner"ï¼ˆä¸´æ—¶æ€§/ç‰¹å®šåœºæ™¯æ€§æ–¹å¼ï¼‰** é€šå¸¸æŒ‡ä¸€ç§ **ç¼ºä¹ç³»ç»Ÿæ€§ç†è®ºæŒ‡å¯¼ã€ä¾èµ–ç»éªŒæˆ–ç›´è§‰çš„è®¾è®¡å’Œè°ƒæ•´æ–¹æ³•**
      
      ç¥ç»ç½‘ç»œçš„è®¾è®¡å’Œä¼˜åŒ–å¾€å¾€ä¾èµ–å®éªŒç»“æœè€Œéæ•°å­¦è¯æ˜ï¼ˆä¾‹å¦‚ï¼Œæ— æ³•ä¸¥æ ¼è¯æ˜æŸç½‘ç»œç»“æ„å¯¹ç»„åˆä¼˜åŒ–é—®é¢˜çš„æ”¶æ•›æ€§ï¼‰ã€‚
      
      - ä¾‹å¦‚ï¼šTransformer çš„æ³¨æ„åŠ›æœºåˆ¶æœ€åˆæ˜¯å¯å‘å¼è®¾è®¡ï¼Œåç»­æ‰é€æ¸æœ‰ç†è®ºåˆ†æå…¶è¡¨è¾¾èƒ½åŠ›ã€‚
      
       **ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œå¸¸è¢«æ‰¹è¯„ä¸º "ad-hoc"ï¼Ÿ**
      
      **å†å²åŸå› **ï¼š
      
      - **é»‘ç®±æ€§è´¨**ï¼šç¥ç»ç½‘ç»œçš„å‡½æ•°é€¼è¿‘èƒ½åŠ›å¼ºå¤§ï¼Œä½†å†…éƒ¨å·¥ä½œæœºåˆ¶éš¾ä»¥è§£é‡Šã€‚
      - **å·¥ç¨‹å®è·µä¼˜å…ˆ**ï¼šæ·±åº¦å­¦ä¹ çš„å‘å±•é•¿æœŸç”±å®éªŒç»“æœæ¨åŠ¨ï¼ˆå¦‚ImageNetç«èµ›ï¼‰ï¼Œç†è®ºæ»åäºåº”ç”¨ã€‚
      - **çµæ´»æ€§ä¸ä»£ä»·**ï¼šç¥ç»ç½‘ç»œçš„é€šç”¨æ€§ä½¿å…¶èƒ½é€‚åº”å¤šç§ä»»åŠ¡ï¼Œä½†è¿™ä¹Ÿå¯¼è‡´è®¾è®¡æ—¶ç¼ºä¹ä¸¥æ ¼çº¦æŸã€‚
      
      **å…¸å‹æ¡ˆä¾‹**ï¼š
      
      - **ResNet çš„è·³è·ƒè¿æ¥**ï¼šæœ€åˆæ˜¯å®éªŒå‘ç°â€œæ·±åº¦å¢åŠ å¯¼è‡´è®­ç»ƒè¯¯å·®ä¸Šå‡â€åæå‡ºçš„è§£å†³æ–¹æ¡ˆï¼Œåç»­æ‰æœ‰ç†è®ºåˆ†æå…¶æ¢¯åº¦ä¼ æ’­æ€§è´¨ã€‚
      - **æ¿€æ´»å‡½æ•°é€‰æ‹©**ï¼šReLU çš„æ™®åŠæºäºå®éªŒä¸­å‘ç°å…¶è®­ç»ƒæ•ˆç‡ä¼˜äºSigmoidï¼Œè€Œéå…ˆéªŒç†è®ºæ¨å¯¼ã€‚

- Aroraâ€™s PTAS  1998

  



##### contribution

- the first neural architecture of `bounded size` that has capacity to approximately solve the RSMT problem  
- leads to better practical performance than existing SOTA methods for ==large instances==  
- one of the first NCO(neural combinatorial optimization) frameworks to use algorithmic alignment to ==remove dependence on problem size==. 
  - Training on large instances is prohibitively expensive: for supervised learning this requires computation of exact solutions to large instances, and for RL and unsupervised learning, training becomes exponentially more challenging as size increases. Thus, size generalization is essential for performance on large instances  
- pinå¯ä»¥æ‹“å±•åˆ°å¤šç»´ï¼ˆä¸åªæ˜¯2,3ç»´ç©ºé—´ï¼‰, è¿˜å¯ä»¥ä¸ç”¨ç›´çº¿ï¼ˆæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰



##### flow



##### model



##### data



##### experiment

![image-20250422230008874](assets/image-20250422230008874.png)

![image-20250422230039422](assets/image-20250422230039422.png)

#### [-Delay Driven-Trans-2024- - ](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10756606)



### DR outdated

#### [TritonRoute- - - -ILP-]()







#### [DRCU]()

- academic DR  



### DR adv





## Adv-Node

#### -Multi Row Standard Cell Layout Synthesis with Enhanced Scalability-ISEDA-2025--PEK

##### background

- Multi-row standard cells are widely adopted in advanced technology nodes, especially for complicated and large cells like multi-bit flip-flops(MBFFs).   

  ![image-20250614213428550](assets/image-20250614213428550.png)

- In advanced technology nodes, standard cell libraries have expanded to include a larger variety and number of cells, which makes manual design more time-consuming.   

- the height of standard cells in advanced nodes has been steadily reduced  

  ![image-20250614210915175](assets/image-20250614210915175.png)

- multi-row standard cells typically contain a higher number of transistors  

- ![image-20250614211754985](assets/image-20250614211754985.png)

- ç›¸å…³å·¥ä½œæ¯”è¾ƒå°‘ï¼Œä¹‹å‰è§£å†³è¿™ä¸ªé—®é¢˜ä½¿ç”¨çš„åŸºäºone-rowçš„ç®—æ³•ç„¶åé€šè¿‡æŠ˜å ç­‰æ–¹å¼å˜æˆmulti-row, éš¾ä»¥è·å¾—å…¨å±€æœ€ä¼˜è§£






## Circuit Representation

#### [NetlistGNN-GNN Congestion-NIPS-2022-GNN-Ark]()

- [OpenSource!](https://github.com/PKUterran/NetlistGNN)
- can be a post-placement congestion predictor, also for some other task, not like LHNNã€‚ä¹Ÿåšäº†Net WLé¢„æµ‹çš„å®éªŒ
- è¿™ç¯‡æ–‡ç« çš„ geometrical ä¿¡æ¯ä¹Ÿæ˜¯ç”¨GNNå®ç°çš„
- è²Œä¼¼æ¨ç†å¾ˆå¿«ï¼Œå¯ä»¥çœ‹çœ‹
- å¼ºè°ƒäº†è¿™æ˜¯ä¸€ä¸ªgeneralçš„Circuit Representaionçš„å·¥ä½œ
- ä»–çš„å…¬å¼å†™çš„å¾ˆå¥½çœ‹ï¼Œå¯ä»¥å€Ÿé‰´ä¸€ä¸‹



##### background

- the two most informative ones: the netlist and the design layout; handling each information source independently is sub-optimal  

- categorize  into `topological methods`[4, 5, 6]   and `geometrical methods.`   [7, 8, 9]  

  topological methods only consider the topological information in netlists and cannot effectively perceive geometrical structure introduced ==after the placement== stage, so their performance on circuits after placement is greatly stifled.   

  the geometrical models heavily rely on geometrical information and neglect the topology underlying the netlists, so they cannot handle circuits in stages earlier than global placement where geometry is not available.   

  

##### contribution

- `Circuit Graph`: a heterogeneous graph  with a linear time consumption to the scale of the design  
- `Circuit GNN`:  



##### flow

![image-20250921000705159](assets/image-20250921000705159.png)



##### model

graphï¼š

![image-20250921000724862](assets/image-20250921000724862.png)

!!! note
    shift-windowçš„çº¿æ€§å¤æ‚åº¦å®ç°ï¼

##### data

Congestion Prediction  [ISPD2011  Contest](http://www.ispd.cc/contests/11/ispd2011_contest.html )

Net Wirelength Prediction  [DAC2012  contest](http://archive.sigda.org/dac2012/contest/dac2012_contest.html  )



##### experiment

![image-20250921001533660](assets/image-20250921001533660.png)

![image-20250921001953449](assets/image-20250921001953449.png)

!!! warning
    
    ä½†æ˜¯æ²¡æœ‰è¯´è¿™äº›å¯¹æ¯”æ¨¡å‹æ˜¯æ€ä¹ˆè®¾è®¡çš„



## Floorplan



#### [IncreDFlip-dataflow driven Macro filp-ISEDA-2025-SJTU-]()

- a methodology that leverages dataflow information to narrow the search space and utilizes dataflow decomposition from the synthesized netlist to guide flipping decisions.  

##### background

- ä¼ ç»Ÿmacroéƒ½æ˜¯ç”¨æ‰‹æ‘†çš„, macro è¶Šæ¥è¶Šå¤š
- Typically, mixed-size placers [2], [8], [9] or macro placers [10], [7], [11] consider flipping as one among several co-optimization strategies during placement which will lead to sub-optimal placement outcomes.   



##### contribution

- a ==dataflow-driven== flipping approach to reduce the ==search space== and ==time complexity==

##### flow



##### model



##### data



##### experiment





## toread

#### [Algorithms_and_data_structures_for_fast_and_good_VLSI_routing](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=6241546)



#### ä¸€å †å…³äº RSMT çš„è®ºæ–‡

#### DR ISPD contest: TritonRoute, Dr. CU, DRAPS, RDTA

TritonRoute [15] adopted integer linear programming (ILP) for parallel intralayer routing. DRAPS [18] developed an A*-interval-based path search algorithm to handle complicated design rules. Dr. CU [16], [17], [21] proposed an optimal correct-by-construction path search algorithm and a two-level sparse data structure for runtime and memory efficiency. RDTA [19] developed an analytical approach to solve the track assignment problem following the global routing guides.   

#### DR Pin Acess: A multithreaded initial detailed routing algorithm considering global routing guides

#### [SALT- -TCAD-2020- -CUHK](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=8624460)

#### [Timing-Driven Routing-ICCAD-2023-USTC](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10323981)

#### [TIMING-ICCAD-2024_Guo](..\..\..\Download\TIMING_ICCAD2024_Guo.pdf)

#### [GPU-Accelerated_Static_Timing_Analysis](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=9256516)



#### [An Optimization-aware Pre-Routing Timing Prediction Framework Based on Multi-modal Learning](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10909720)



#### [-Chip Placement-arxiv-2020-GNN+RL-Google](https://arxiv.org/pdf/2004.10746)

#### [-DRL ROSMT-Trans-2023-DRL-FZU+PEK](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10816669)



#### [-Adaptive Route Guides-ASP DAC-2024-XU](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=10473934)



#### [-Asynchronous RL+Knowledge Transfer-Trans-2023-RL-PEK](https://ieeexplore-ieee-org-443.webvpn.scut.edu.cn/stamp/stamp.jsp?tp=&arnumber=9557780)

##### background

- ä¸²è¡Œå¸ƒçº¿ä¸‹çš„ net order å¯¹å¸ƒçº¿æ”¶æ•›ç»“æœå½±å“å¾ˆå¤§ï¼Œå°¤å…¶åœ¨å…ˆè¿›å·¥è‰ºèŠ‚ç‚¹ä¸‹ï¼Œè®¾è®¡è§„åˆ™æ„ˆåŠ å¤æ‚ä¸”å¸ƒçº¿è§„æ¨¡åºå¤§ï¼Œåˆ°æ—¶ net order çš„å½±å“æ›´å¤§

- ä»¥å¾€çš„å·¥ä½œå¾€å¾€ä½¿ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•å¯¹ç‰¹å®šçš„ benchmark è¿›è¡Œä¼˜åŒ–

- ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºç®€å•çš„ ==å¯å‘å¼è§„åˆ™==ï¼ˆå¦‚ç½‘ç»œè¦†ç›–åŒºåŸŸå¤§å°ã€å¼•è„šæ•°é‡ç­‰ï¼‰ç¡®å®šå¸ƒçº¿é¡ºåºï¼Œæ¯”å¦‚ï¼šthe number of pins in a net; 2) the number of DRC violations caused by a net [23]; 3) the region size covered by a net [17]; and 4) the distance from a certain point [24] ã€‚ä½†ç”±äºä¸åŒè®¾è®¡å·®å¼‚å¤§ï¼Œè¿™ç±»å›ºå®šç­–ç•¥éš¾ä»¥é€šç”¨åŒ–ï¼Œå¯¼è‡´å¸ƒçº¿è´¨é‡ï¼ˆå¦‚ DRC è¿è§„ã€ç»•çº¿é•¿åº¦ç­‰ï¼‰ä¸ç¨³å®šã€‚ç°æœ‰æ–¹æ³•åœ¨åº”å¯¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–è®¾è®¡æ—¶ç¼ºä¹çµæ´»æ€§ï¼Œå› æ­¤äºŸéœ€ä¸€ç§è‡ªåŠ¨åŒ–ã€å¯æ³›åŒ–çš„ç½‘ç»œé¡ºåºä¼˜åŒ–æ–¹æ¡ˆã€‚

- DRC

  ![image-20250316151037763](assets/image-20250316151037763.png)

- In this work, we adopt Dr.CU as the target detailed routing framework for studying, while the methodology can work on other routers as well.   

- ![image-20250316151304676](assets/image-20250316151304676.png)

- ![image-20250316152913499](assets/image-20250316152913499.png)

  Although the wirelength does not change much, the order affects both via count and the number of `DRC violations`.  

- `Dr.CU` sorts nets by the routing region sizes (half-perimeter of the bounding box) of each net in descent order. In other words, ==nets covering large routing regions are routed first.==  However, we observe that the routing region sizes of different nets can be very similar, leading to random orders between these nets, and eventually causing high variations in the final violations.   For example, Fig. 3 shows that 5293 nets have the same routing region size, accounting for 14.4 % of the total number of nets in benchmark ispd18_test3.   Therefore, there is a potential to improve the routing performance by developing an ordering strategy considering more features  

  ![image-20250316153631925](assets/image-20250316153631925.png)

- RL: One of the main obstacles in using supervised ML-based techniques for solving routing problems, especially the net ordering problems, is the lack of golden labeled datasets to learn.   

- metricsï¼š

  - the total wirelength of all nets;  
  - the number of the total used vias  
  - the number of DRC violations.  

##### contribution

1. **å¼‚æ­¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶**ï¼š
   - æå‡ºåŸºäº **A3Cï¼ˆå¼‚æ­¥ä¼˜åŠ¿æ¼”å‘˜-è¯„è®ºå®¶ï¼‰** çš„å¼‚æ­¥ RL æ¡†æ¶ï¼Œæ”¯æŒå¤šæ™ºèƒ½ä½“å¹¶è¡Œè®­ç»ƒï¼ŒåŠ é€Ÿç­–ç•¥æœç´¢ã€‚ 
   - **çŠ¶æ€ç‰¹å¾**ï¼šå®šä¹‰ 7 ç»´ç½‘ç»œçº§ç‰¹å¾ï¼ˆå¦‚å¸ƒçº¿åŒºåŸŸå°ºå¯¸ã€ç›¸é‚»ç½‘ç»œé‡å åº¦ã€å†å²é‡å¸ƒæ¬¡æ•°ç­‰ï¼‰ï¼Œè¾“å…¥ç­–ç•¥ç½‘ç»œç”Ÿæˆæ’åºè¯„åˆ†ã€‚
   - **å¥–åŠ±æœºåˆ¶**ï¼šç»“åˆæ€»æˆæœ¬ï¼ˆçº¿é•¿ã€é€šå­”æ•°ã€DRC è¿è§„ï¼‰ä¸åŸºçº¿ç­–ç•¥ï¼Œå¼•å…¥ **ä¸åŒ¹é…æƒ©ç½šé¡¹**ï¼Œå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ ä¼˜äºé»˜è®¤å¯å‘å¼ç­–ç•¥çš„æ’åºç­–ç•¥ã€‚
2. **åŸºäºç­–ç•¥è’¸é¦çš„è¿ç§»å­¦ä¹ ç®—æ³•**ï¼š
   - é€šè¿‡ **å°åŒºåŸŸå‰ªè£**ï¼ˆä»ç›®æ ‡è®¾è®¡æˆªå–çº¦ 500 ä¸ªç½‘ç»œçš„å¯†é›†å­åŒºåŸŸï¼‰è¿›è¡Œå¾®è°ƒï¼Œé¿å…å…¨è®¾è®¡è®­ç»ƒçš„é«˜å¼€é”€ã€‚ 
   - åˆ©ç”¨æ•™å¸ˆç½‘ç»œï¼ˆå·²é¢„è®­ç»ƒçš„é€šç”¨ç­–ç•¥ï¼‰æŒ‡å¯¼å­¦ç”Ÿç½‘ç»œï¼ˆé’ˆå¯¹ç›®æ ‡è®¾è®¡çš„å®šåˆ¶ç­–ç•¥ï¼‰ï¼Œæœ€å°åŒ–ä¸¤è€…ç­–ç•¥åˆ†å¸ƒçš„ KL æ•£åº¦ï¼Œå®ç°é«˜æ•ˆçŸ¥è¯†è¿ç§»ã€‚ 
3. **æ¨¡å‹æ— å…³çš„çµæ´»æ¶æ„**ï¼š
   - ç½‘ç»œç»“æ„ **è§£è€¦è®¾è®¡è§„æ¨¡**ï¼Œé€šè¿‡ç‹¬ç«‹ç¼–ç æ¯ä¸ªç½‘ç»œçš„å±€éƒ¨ç‰¹å¾å†æ‹¼æ¥ï¼Œæ”¯æŒä¸åŒè®¾è®¡é—´ç­–ç•¥å…±äº«ï¼Œé¿å…è¾“å…¥å°ºå¯¸çº¦æŸã€‚



##### model

###### enviroment

`Dr. Cu`

æ¯ä¸€ä¸ª step å°±è¦è·‘ä¸€æ¬¡ `Dr.Cu`ï¼Œè®­ç»ƒä¸æ˜¯å¾ˆæ…¢ï¼Ÿ

è€Œä¸”ä»€ä¹ˆæ—¶å€™ episode ç»“æŸï¼Ÿ

###### state

is the collective representation of features for ==all nets==.

 ![image-20250316155614349](assets/image-20250316155614349.png)

`Cost` å…·ä½“æ˜¯æŒ‡ä»€ä¹ˆï¼Ÿ

state å¾ˆå¤§å•Š

###### action

An action a is a real number vector. Each number is defined as an ordering score of a net.  

`ä¹‹å‰åšçš„éƒ½æ˜¯å¾ˆå°‘ä¸ªçš„action`

###### reward

![image-20250316161153277](assets/image-20250316161153277.png)

![image-20250316161214905](assets/image-20250316161214905.png)

å¯ä»¥ä½¿ç”¨ `Dr.Cu` çš„ net order è¿›è¡Œåˆå§‹çš„æ’åºï¼Œè€Œä¸æ˜¯ä»éšæœºå¼€å§‹ï¼Œæé«˜æ¨¡å‹æ”¶æ•›é€Ÿåº¦ã€‚å°¤å…¶æ˜¯è¿™ä¸ªéš¾æ”¶æ•›çš„ä»»åŠ¡ï¼Œå¾ˆé‡è¦

![image-20250316165056621](assets/image-20250316165056621.png)

![image-20250316165214850](assets/image-20250316165214850.png)

it will speed up the training, but not limit the exploration space to the heuristic ordering strategy used in `Dr.CU`.   

###### A3C

![image-20250316163725745](assets/image-20250316163725745.png)

![image-20250316163407987](assets/image-20250316163407987.png)

Intuitively, the policy network tells us the ordering scores of the nets and the value network evaluates the scores in the sense of future rewards  

![image-20250316163738250](assets/image-20250316163738250.png)

è¾“å‡ºçš„ä¸æ˜¯ä¸€ä¸ªå…·ä½“çš„ actionï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†å¸ƒã€‚ We pick the action by sampling from this normal distribution p.   

![image-20250316164147810](assets/image-20250316164147810.png)

è¿™æ ·æœ‰ä»€ä¹ˆæ•ˆæœï¼Ÿï¼šï¼ˆæ²¡ç†è§£ï¼‰

![image-20250316164738691](assets/image-20250316164738691.png)

###### TRANSFER LEARNING ALGORITHM  

- Our task is to mine the knowledge from the pretrained policy and adapt to a target design to improve the performance  
- If we can customize the policy for each design with low overhead, there is an opportunity to improve the performance further.  
- To reduce the overhead of customization, we fine-tune the well-trained policy from the previous section using a ==small region clipped==  





#### [DieRouter+- FPGA Die Routing-DP-ShanDong-]()

##### background

- ![image-20250614235302025](assets/image-20250614235302025.png)
- å¤§å‹æ•°å­—è®¾è®¡å¾€å¾€éœ€è¦ä½¿ç”¨å¤šå—`FPGAï¼ˆMFSï¼‰`è¿›è¡ŒåŸå‹éªŒè¯
- `2.5D FPGA` integrates ==multiple dies== and offers significantly higher capacity than a traditional ==single-die== FPGA  
- Super Long Lines (SLLs)  
- Time-Division Multiplexing (TDM)  å¤šè·¯åˆ†æ—¶å¤ç”¨ï¼Œæ˜¯ä¸€ç§ä¸²å¹¶-å¹¶ä¸²è½¬æ¢IP. ç¼“è§£FPGAçš„å¤–éƒ¨Pinä¸å¤Ÿé—®é¢˜ã€‚è¿™ä¸ªIPå¯ä»¥è°ƒèŠ‚ç­‰æ•ˆPinä¸ªæ•°ï¼ŒRatioè¶Šå¤§ï¼Œå»¶æ—¶è¶Šå¤§ã€‚



##### contribution

- a simpler yet more effective initial routing method based on `shortest path trees`
- a `Second-Order Cone Programming formulation` of an extended relaxed TDM assignment problem to compute ==optimal continuous TDM ratios==
- a `scheduler-driven Dynamic Programming (DP)`- based legalization technique that adaptively schedules state evaluations



##### flow

![image-20250615112501557](assets/image-20250615112501557.png)





##### data

2023 EDA Elite Design Challenge  







## ç»¼è¿°

### ML4PR

[Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview](https://blog.csdn.net/SP_FA/article/details/134063224)

![image-20241101173512416](./assets/image-20241101173512416.png)

æ”¾ç½®å’Œå¸ƒçº¿æ˜¯ä¸¤ä¸ªä¸å¯æˆ–ç¼ºä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ NP-hard é—®é¢˜

æœºå™¨å­¦ä¹ å‡­å€Ÿå…¶æ•°æ®é©±åŠ¨çš„æ€§è´¨æ˜¾ç¤ºå‡ºäº†å¹¿é˜”çš„å‰æ™¯ï¼Œå®ƒå¯ä»¥å‡å°‘å¯¹çŸ¥è¯†å’Œå…ˆéªŒçš„ä¾èµ–ï¼Œå¹¶ä¸”é€šè¿‡å…¶å…ˆè¿›çš„è®¡ç®—èŒƒå¼å…·æœ‰æ›´å¤§çš„å¯æ‰©å±•æ€§ (ä¾‹å¦‚ GPU åŠ é€Ÿçš„æ·±åº¦ç½‘ç»œ)



**æŒ‘æˆ˜:**

placement:

- åœ¨è·¯ç”±å®Œæˆä¹‹å‰ï¼Œæ— æ³•è¯„ä¼°è¯¸å¦‚å¯è¾¾æ€§ä¹‹ç±»çš„æ”¾ç½®ç›®æ ‡ï¼›å› æ­¤ï¼Œåœ¨ä¼˜åŒ–å¾ªç¯ä¸­å¯èƒ½éœ€è¦èŠ±è´¹æ•°å°æ—¶æ‰èƒ½è·å¾—åé¦ˆï¼Œè¿™å¯¹äºè¿›è¡Œæ•°åƒæ¬¡æŸ¥è¯¢æ¥è¯´æ˜¯è´Ÿæ‹…ä¸èµ·çš„
- ç°ä»£çš„æ”¾ç½®å™¨éœ€è¦åœ¨å‡ ä¸ªå°æ—¶å†…å¤„ç†æ•°ä¸‡ä¸ªå®å’Œæ•°ç™¾ä¸‡ä¸ªæ ‡å‡†å•å…ƒã€‚è¿™ç§å¯æ‰©å±•æ€§çš„è¦æ±‚ä»ç„¶è¶…å‡ºäº†ç°æœ‰ ML æ–¹æ³•çš„èƒ½åŠ›

routing:

- åœ¨å…¬å¹³çš„æ¯”è¾ƒä¸‹ï¼Œç°æœ‰æŠ€æœ¯å¾ˆéš¾åœ¨æ•ˆç‡å’Œæ±‚è§£è´¨é‡ä¸Šç³»ç»Ÿåœ°ä¼˜äºç»å…¸å¸ƒçº¿ç®—æ³•
- å¤§å¤šæ•°åŸºäºå­¦ä¹ çš„æŠ€æœ¯åœ¨å…·æœ‰æ•°åƒä¸ªç½‘ç»œçš„å°å‹ç”µè·¯ä¸Šå·¥ä½œå¾—å¾ˆå¥½ï¼Œè€Œå®é™…çš„å¸ƒçº¿å¼•æ“éœ€è¦åœ¨è¶…å¤§å‹ 3D ç½‘æ ¼å›¾ ( > 1000 Ã— 1000 Ã— 10 ) (> 1000 Ã— 1000 Ã— 10)(> 1000Ã—1000Ã—10) ä¸Šæœ‰æ•ˆåœ°å¤„ç†æ•°ç™¾ä¸‡ä¸ªç½‘ç»œå¹¶äº§ç”Ÿé«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆ





ç›¸å…³å·¥ä½œ

- placement

  - ![image-20241101175552665](./assets/image-20241101175552665.png)
  - ![image-20241101175600184](./assets/image-20241101175600184.png)
  - ![image-20241101175612168](./assets/image-20241101175612168.png)

- Routing

  - ![image-20241101175915691](./assets/image-20241101175915691.png)

    ![image-20241101175922593](./assets/image-20241101175922593.png)

    ![image-20241101175934137](./assets/image-20241101175934137.png)

  - ![image-20241101180007732](./assets/image-20241101180007732.png)

  - ![image-20241101180029509](./assets/image-20241101180029509.png)

### è¶…å¤§è§„æ¨¡é›†æˆç”µè·¯å¸ƒçº¿ç®—æ³•ç»¼è¿°  

[è¶…å¤§è§„æ¨¡é›†æˆç”µè·¯å¸ƒçº¿ç®—æ³•ç»¼è¿°](https://www.sciengine.com/MNEIM/doi/10.19816/j.cnki.10-1594/TN.2021.02.086)

##### background

![image-20241116095906162](./assets/image-20241116095906162.png)

![image-20241116095924293](./assets/image-20241116095924293.png)

![image-20241116095932126](./assets/image-20241116095932126.png)

å¸ƒçº¿ç›¸å…³è¯¦ç»†çœ‹ routing2.md, è¯¦ç»†å¸ƒçº¿ã€é¢å‘å¯åˆ¶é€ æ€§è®¾è®¡çš„å¸ƒçº¿ç®—æ³• è¿˜æ²¡è®°å½•

### EDA+GNN

è¯¦ç»†çœ‹ [A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks](.\notebak\EDA+GNN.md)



## å‚è€ƒ

1. [AI æŠ€æœ¯å¸¦ç»™ EDA çš„æœºé‡å’ŒæŒ‘æˆ˜](AIæŠ€æœ¯å¸¦ç»™EDAçš„æœºé‡å’ŒæŒ‘æˆ˜-Yibo Lin.pdf)
1. [Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview]([[è¯»è®ºæ–‡\] Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview_toward machine learning....lake-CSDNåšå®¢](https://blog.csdn.net/SP_FA/article/details/134063224))
1. [ã€é˜…è¯»ã€‘A Comprehensive Survey on Electronic Design Automation and Graph Neural Networksâ€”â€”EDA+GNN ç»¼è¿°ç¿»è¯‘_ppaml-CSDN åšå®¢](https://blog.csdn.net/sxf1061700625/article/details/127865492)





## bak

[CongestionNet-Congestion Prediction-IFIP-2019-GNN]()



[-placement Congestion prediction-arXiv-2021-GNN]()



![image-20241101171055570](./assets/image-20241101171055570.png)

è¾“å…¥ï¼šç½‘è¡¨

è¾“å‡ºï¼šcongestion at placement stage







[EDA-ML: Graph Representation LearningFramework for Digital IC Design Automation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10528675)

å¾·é›·å¡å°”å¤§å­¦ç”µæ°”ä¸è®¡ç®—æœºå·¥ç¨‹ç³» Pratik Shrestha å’Œ Ioannis Savidis

##### background

VLSI : traditional methodologies -> ML, Graph representation learning  ability to capture complex relationships in graph-structured data  

GNNï¼š

![image-20241116142013379](./assets/image-20241116142013379.png)

![image-20241116142052562](./assets/image-20241116142052562.png)

##### task

![image-20241116143449696](./assets/image-20241116143449696.png)

##### flow

![image-20241116144708326](./assets/image-20241116144708326.png)

##### data

![image-20241116155309167](./assets/image-20241116155309167.png)

![image-20241116143927933](./assets/image-20241116143927933.png)

![image-20241116155354597](./assets/image-20241116155354597.png)

**æ¨¡å‹**

![image-20241116155947525](./assets/image-20241116155947525.png)

![image-20241116155857412](./assets/image-20241116155857412.png)

**å®éªŒ**

![image-20241116160529100](./assets/image-20241116160529100.png)